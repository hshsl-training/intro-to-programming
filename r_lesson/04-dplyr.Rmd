---
title: Data Wrangling and Analyses with Tidyverse
source: Rmd
---

```{r, echo=FALSE, eval=TRUE, purl=FALSE, warning=FALSE, message=FALSE}
## silently read in CSV file from FigShare

library(readr)
variants <- read_csv("https://ndownloader.figshare.com/files/14632895")
```


::: {.callout-note appearance="minimal"}

## Objectives

- Describe what the **`dplyr`** package in R is used for.
- Apply common **`dplyr`** functions to manipulate data in R.
- Employ the `pipe` operator to link together a sequence of functions.
- Employ the `mutate()` function to apply other chosen functions to existing columns and create new columns of data.
- Employ the ‘split-apply-combine’ concept to split the data into groups, apply analysis to each group, and combine the results.

:::

::: {.callout-note appearance="minimal"}

## Questions

- How can I manipulate data frames without repeating myself?

:::

Bracket subsetting is handy, but it can be cumbersome and difficult to read, especially for complicated operations.

Luckily, the [**`dplyr`**](https://cran.r-project.org/package=dplyr) package provides a number of very useful functions for manipulating data frames
in a way that will reduce repetition, reduce the probability of making
errors, and probably even save you some typing. As an added bonus, you might
even find the `dplyr` grammar easier to read.

Here we're going to cover some of the most commonly used functions as well as using
pipes (`%>%`) to combine them:

1. `glimpse()`
2. `select()`
3. `filter()`
4. `group_by()`
5. `summarize()`
6. `mutate()`
7. `pivot_longer` and `pivot_wider`

Packages in R are sets of additional functions that let you do more
stuff in R. The functions we've been using, like `str()`, come built into R;
packages give you access to more functions. You need to install a package and
then load it to be able to use it.

```{r, eval=FALSE, purl=FALSE}
install.packages("dplyr") ## installs dplyr package
install.packages("tidyr") ## installs tidyr package
install.packages("ggplot2") ## installs ggplot2 package
install.packages("readr") ## install readr package
```

You only need to install a package once per computer, but you need to load it
every time you open a new R session and want to use that package.

```{r, message=FALSE, purl=FALSE}
library("dplyr")          ## loads in dplyr package to use
library("tidyr")          ## loads in tidyr package to use
library("ggplot2")          ## loads in ggplot2 package to use
library("readr")          ## load in readr package to use
```

You only need to install a package once per computer, but you need to load it with the `library()` function
every time you open a new R session and want to use that package.


## What is **`dplyr`**?

The package `dplyr` provides easy
tools for the most common data manipulation tasks. This package is also included in the [`tidyverse` package](https://www.tidyverse.org/), which is a collection of eight different core packages (`dplyr`, `ggplot2`, `tibble`, `tidyr`, `readr`, `purrr`, `stringr`, and `forcats`) and many others that have been added over the years. It is built to work directly with data frames. 


## Taking a quick look at data frames

Similar to `str()`, which comes built into R, `glimpse()` is a `dplyr` function that (as the name suggests) gives a glimpse of the data frame.



```{r, echo=FALSE, eval=TRUE, purl=FALSE}
glimpse(variants)
```

In the above output, we can already gather some information about `variants`, such as the number of rows and columns, column names, type of vector in the columns, and the first few entries of each column. Although what we see is similar to outputs of `str()`, this method gives a cleaner visual output.

## `select`()

To select columns of a data frame, use `select()`. The first argument to this function is the data frame (`variants`), and the subsequent arguments are the columns to keep.

```{r, echo=TRUE, eval=TRUE, purl=FALSE}
select(variants, sample_id, REF, ALT, DP)
```

To select all columns *except* certain ones, put a "-" in front of
the variable to exclude it.

```{r, echo=TRUE, eval=TRUE, purl=FALSE}
select(variants, -CHROM)
```

`dplyr` also provides useful functions to select columns based on their names. For instance, `ends_with()` allows you to select columns that ends with specific letters. For instance, if you wanted to select columns that end with the letter "B":

```{r}
select(variants, ends_with("B"))
```

::: {.callout-tip}

Check out the help documentation for `select()` and see what other helper functions are available.

:::


### The `pipe %>%`

We can make our task easier by using a special operator called the pipe. Pipes let you take the output of one function and send it directly to the next, which is
useful when you need to do many things to the same data set. This helps you avoid messy and hard to read nested expressions, or needing to create many intermediate objects. 

Pipes in R look like
`%>%` and are made available via the `magrittr` package, which is installed as
part of `dplyr`. If you use RStudio, you can type the pipe with
<kbd>Ctrl</kbd> + <kbd>Shift</kbd> + <kbd>M</kbd> if you're using a PC,
or <kbd>Cmd</kbd> + <kbd>Shift</kbd> + <kbd>M</kbd> if you're using a Mac.

The first required argument of most `dplyr` functions is the data frame you will be performing the function on. Therefore, an expression using the pipe will usually start with a data frame. So let's try rewriting our select statement to use the pipe.

```{r, echo=TRUE, eval=TRUE, purl=FALSE}
variants %>% 
  select(sample_id, REF, ALT, DP)
```

Notice that when you use the pipe RStudio will be able to helpfully autocomplete column names for you, which is a good way to reduce typing and avoid errors.


::: {.callout-tip appearance="minimal"}

## Exercise

Create a table that contains all the columns with the letter "i" and column "POS",
without columns "Indiv" and "FILTER".
Hint: look at for a function called `contains()`, which can be found in the help documentation for ends with we just covered (`?ends_with`). Note that contains() is not case sensistive.

:::: {.callout-warning collapse="True" appearance="minimal}

## Solution

```{r}
# First, we select "POS" and all columns with letter "i". This will contain columns Indiv and FILTER. 
variants_subset <- select(variants, POS, contains("i"))
# Next, we remove columns Indiv and FILTER
variants_result <- select(variants_subset, -Indiv, -FILTER)
variants_result
```

::::

We can also get to `variants_result` in one line of code:

:::: {.callout-warning collapse="True" appearance="minimal}

## Alternative solution

```{r}
variants_result <- select(variants, POS, contains("i"), -Indiv, -FILTER)
variants_result
```

::::

:::

## `filter()`

`select()` lets you choose columns. To choose rows, use `filter()`:

```{r, echo=TRUE, eval=TRUE, purl=FALSE}

variants %>% 
  filter(sample_id == "SRR2584863")
```

`filter()` will keep all the rows that match the conditions that are provided.
Here are a few examples:

```{r}
# rows for which the reference genome has T or G
variants %>% 
  filter(REF %in% c("T", "G"))

# rows that have TRUE in the column INDEL
variants %>% 
  filter(INDEL)

# rows that don't have missing data in the IDV column
variants %>% 
  filter(!is.na(IDV))
```

We have a column titled "QUAL". This is a Phred-scaled confidence
score that a polymorphism exists at this position given the sequencing
data. Lower QUAL scores indicate low probability of a polymorphism
existing at that site. `filter()` can be useful for selecting mutations that
have a QUAL score above a certain threshold:

```{r}
# rows with QUAL values greater than or equal to 100
variants %>% 
  filter(QUAL >= 100)
```

`filter()` allows you to combine multiple conditions. You can separate them using a `,` as arguments to the function, they will be combined using the `&` (AND) logical operator. If you need to use the `|` (OR) logical operator, you can specify it explicitly:

```{r}
# this is equivalent to:
#   filter(variants, sample_id == "SRR2584863" & QUAL >= 100)
variants %>% 
  filter(sample_id == "SRR2584863", QUAL >= 100)

# using `|` logical operator
variants %>% 
  filter(sample_id == "SRR2584863", (MQ >= 50 | QUAL >= 100))
```

::: {.callout-tip}

## Exercise

Select all the mutations that occurred between the positions 1e6 (one million)
and 2e6 (inclusive) that have a QUAL greater than 200, and exclude INDEL mutations.
Hint: to flip logical values such as TRUE to a FALSE, we can use to negation symbol
"!". (eg. !TRUE == FALSE).

:::: {.callout-caution collapse="true" icon="false"}

## Solution

```{r}
filter(variants, POS >= 1e6 & POS <= 2e6, QUAL > 200, !INDEL)
```

::::

:::

Because of the pipe it's easy to combine different actions like selecting and filtering without the need to create intermediate objects or write messy nested code.

```{r, echo=TRUE, eval=TRUE, purl=FALSE}
variants %>%
  filter(sample_id == "SRR2584863") %>%
  select(REF, ALT, DP)
```

In the above code, we use the pipe to send the `variants` data set first through
`filter()`, to keep rows where `sample_id` matches a particular sample, and then through `select()` to
keep only the `REF`, `ALT`, and `DP` columns. Since `%>%` takes
the object on its left and passes it as the first argument to the function on
its right, we don't need to explicitly include the data frame as an argument
to the `filter()` and `select()` functions any more.

Some may find it helpful to read the pipe like the word "then". For instance,
in the above example, we took the data frame `variants`, *then* we `filter`ed
for rows where `sample_id` was SRR2584863, *then* we `select`ed the `REF`, `ALT`, and `DP` columns, *then* we showed only the first six rows.
The **`dplyr`** functions by themselves are somewhat simple,
but by combining them into linear workflows with the pipe, we can accomplish
more complex manipulations of data frames.

If we want to create a new object with this smaller version of the data we
can do so by assigning it a new name:

```{r, purl=FALSE}
SRR2584863_variants <- variants %>%
  filter(sample_id == "SRR2584863") %>%
  select(REF, ALT, DP)
```

This new object includes all of the data from this sample. Let's look at just
the first six rows to confirm it's what we want:

```{r, purl=FALSE}
head(SRR2584863_variants)
```

Similar to `head()` and `tail()` functions, we can also look at the first or last six rows using tidyverse function `slice()`. Slice is a more versatile function that allows users to specify a range to view:

```{r}
SRR2584863_variants %>% slice(1:6)
```

```{r}
SRR2584863_variants %>% slice(10:25)
```

::: {.callout-tip}

## Exercise: Pipe and filter

Starting with the `variants` data frame, use pipes to subset the data
to include only observations from SRR2584863 sample,
where the filtered depth (DP) is at least 10.
Showing only 5th through 11th rows of columns `REF`, `ALT`, and `POS`.

:::: {.callout-caution collapse="true" icon="false"}

## Solution

```{r}
 variants %>%
 filter(sample_id == "SRR2584863" & DP >= 10) %>%
 slice(5:11) %>%
 select(sample_id, DP, REF, ALT, POS)
```

::::

:::

## `mutate()`

Frequently you'll want to create new columns based on the values in existing
columns, for example to do unit conversions or find the ratio of values in two
columns. For this we'll use the `dplyr` function `mutate()`.

For example, we can convert the polymorphism confidence value QUAL to a
probability value according to the formula:

Probability = 1- 10 ^ -(QUAL/10)

We can use `mutate` to add a column (`POLPROB`) to our `variants` data frame that shows
the probability of a polymorphism at that site given the data.

```{r, purl=FALSE}
variants %>%
  mutate(POLPROB = 1 - (10 ^ -(QUAL/10)))
```

::: {.callout-tip}

## Exercise

There are a lot of columns in our data set, so let's just look at the
`sample_id`, `POS`, `QUAL`, and `POLPROB` columns for now. Add a
line to the above code to only show those columns.

:::: {.callout-caution collapse="true" icon="false"}

## Solution

```{r}
variants %>%
 mutate(POLPROB = 1 - 10 ^ -(QUAL/10)) %>%
 select(sample_id, POS, QUAL, POLPROB)
```

::::

:::

## `group_by()` and `summarize()` 

Many data analysis tasks can be approached using the "split-apply-combine"
paradigm: split the data into groups, apply some analysis to each group, and
then combine the results. `dplyr` makes this very easy through the use of the
`group_by()` function, which splits the data into groups.


```{r}
variants %>%
  group_by(sample_id)
```

You might notice that nothing appears to have changed. `group_by()` is often used together with other functions, like `summarize()`. When the data is grouped, `summarize()` can be used to collapse each group into a single-row summary. `summarize()` does this by applying an aggregating
or summary function to each group.

It can be a bit tricky at first, but we can imagine physically splitting the data
frame by groups and applying a certain function to summarize the data.

```{r eval=FALSE}
knitr::include_graphics("fig/split_apply_combine.png")
```
^[The figure was adapted from the Software Carpentry lesson, [R for Reproducible Scientific Analysis](https://swcarpentry.github.io/r-novice-gapminder/13-dplyr/)]


We can also apply many other functions to individual columns to get other
summary statistics. For example,we can use built-in functions like `mean()`,
`median()`, `min()`, and `max()`. These are called "built-in functions" because
they come with R and don't require that you install any additional packages.
By default, all **R functions operating on vectors that contains missing data will return NA**.
It's a way to make sure that users know they have missing data, and make a
conscious decision on how to deal with it. When dealing with simple statistics
like the mean, the easiest way to ignore `NA` (the missing data) is
to use `na.rm = TRUE` (`rm` stands for remove).

So to view the mean filtered depth (`DP`) for each sample:

```{r, purl=FALSE, message=FALSE}
variants %>%
  group_by(sample_id) %>%
  summarize(mean_DP = mean(DP))
```

This will create a new column called mean_DP (note the similarity in syntax to `mutate()`)

We can produce multiple summary columns in the same function call, by separating each with commas.

So to view the mean, median, maximum, and minimum filtered depth (`DP`) for each sample:

```{r, purl=FALSE, message=FALSE}
variants %>%
  group_by(sample_id) %>%
  summarize(
    mean_DP = mean(DP),
    median_DP = median(DP),
    min_DP = min(DP),
    max_DP = max(DP))
```


We could use `group_by()` and `summarize()` to find the number of mutations detected in each sample.

```{r, purl=FALSE, message=FALSE}
variants %>%
  group_by(sample_id) %>%
  summarize(n=n())
```

## `count()`

Since counting or tallying values is a common use case for `group_by()`, an alternative function was created `count()`:

```{r, purl=FALSE, message=FALSE}
variants %>%
  count(sample_id)
```

`count()` works similarly to the base R function we looked at in the last section `table()`, but it outputs the data as a tibble.

::: {.callout-tip}

## Exercise

- How many mutations are INDELs?

:::: {.callout-caution collapse="true" icon="false"}

## Solution

```{r}
variants %>%
  count(INDEL)
```

::::

:::

## Reshaping data frames

It can sometimes be useful to transform the "long" tidy format, into the wide format. This transformation can be done with the `pivot_wider()` function provided by the `tidyr` package (also part of the `tidyverse`).

`pivot_wider()` takes a data frame as the first argument, and two arguments: the column name that will become the columns  and the column name that will become the cells in the wide data.

```{r}
variants_wide <- variants %>%
  group_by(sample_id, CHROM) %>%
  summarize(mean_DP = mean(DP)) %>%
  pivot_wider(names_from = sample_id, values_from = mean_DP)
variants_wide
```

The opposite operation of `pivot_wider()` is taken care by `pivot_longer()`. We specify the names of the new columns, and here add `-CHROM` as this column shouldn't be affected by the reshaping:

```{r}
variants_wide %>%
  pivot_longer(-CHROM, names_to = "sample_id", values_to = "mean_DP")
```

## Resources

- [Handy dplyr cheatsheet](https://raw.githubusercontent.com/rstudio/cheatsheets/main/data-transformation.pdf)

- [Much of this lesson was copied or adapted from Jeff Hollister's materials](https://github.com/USEPA/workshops/blob/main/r/2015/introR/rmd_posts/2015-01-14-03-Clean.Rmd)

:::{.callout-note appearance="minimal"}
## Key points

- Use the `dplyr` package to manipulate data frames.
- Use `glimpse()` to quickly look at your data frame.
- Use `select()` to choose variables from a data frame.
- Use `filter()` to choose data based on values.
- Use `mutate()` to create new variables.
- Use `group_by()` and `summarize()` to work with subsets of data.

:::

