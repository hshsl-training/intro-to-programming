[
  {
    "objectID": "shell_lesson/07-organization.html",
    "href": "shell_lesson/07-organization.html",
    "title": "Project Organization",
    "section": "",
    "text": "Objectives\n\n\n\n\nCreate a file system for a bioinformatics project.\nExplain what types of files should go in your docs, data, and results directories.\nUse the history command and a text editor like nano to document your work on your project."
  },
  {
    "objectID": "shell_lesson/07-organization.html#getting-your-project-started",
    "href": "shell_lesson/07-organization.html#getting-your-project-started",
    "title": "Project Organization",
    "section": "Getting your project started",
    "text": "Getting your project started\nProject organization is one of the most important parts of a sequencing project, and yet is often overlooked amidst the excitement of getting a first look at new data. Of course, while it’s best to get yourself organized before you even begin your analyses, it’s never too late to start, either.\nYou should approach your sequencing project similarly to how you do a biological experiment and this ideally begins with experimental design. We’re going to assume that you’ve already designed a beautiful sequencing experiment to address your biological question, collected appropriate samples, and that you have enough statistical power to answer the questions you’re interested in asking. These steps are all incredibly important, but beyond the scope of our course. For all of those steps (collecting specimens, extracting DNA, prepping your samples) you’ve likely kept a lab notebook that details how and why you did each step. However, the process of documentation doesn’t stop at the sequencer!\nGenomics projects can quickly accumulate hundreds of files across tens of folders. Every computational analysis you perform over the course of your project is going to create many files, which can especially become a problem when you’ll inevitably want to run some of those analyses again. For instance, you might have made significant headway into your project, but then have to remember the PCR conditions you used to create your sequencing library months prior.\nOther questions might arise along the way:\n\nWhat were your best alignment results?\nWhich folder were they in: Analysis1, AnalysisRedone, or AnalysisRedone2?\nWhich quality cutoff did you use?\nWhat version of a given program did you implement your analysis in?\n\nGood documentation is key to avoiding this issue, and luckily enough, recording your computational experiments is even easier than recording lab data. Copy/Paste will become your best friend, sensible file names will make your analysis understandable by you and your collaborators, and writing the methods section for your next paper will be easy! Remember that in any given project of yours, it’s worthwhile to consider a future version of yourself as an entirely separate collaborator. The better your documenation is, the more this ‘collaborator’ will feel indebted to you!\nWith this in mind, let’s have a look at the best practices for documenting your genomics project. Your future self will thank you.\nIn this exercise we will setup a file system for the project we will be working on during this workshop.\nWe will start by creating a directory that we can use for the rest of the workshop. First navigate to your home directory. Then confirm that you are in the correct directory using the pwd command.\n$ cd\n$ pwd\nYou should see the output:\n/home/&lt;your username here&gt; \n\n\n\n\n\n\nTip\n\n\n\nIf you aren’t in your home directory, the easiest way to get there is to enter the command cd, which always returns you to home.\n\n\n\n\n\n\n\n\nExercise\n\n\n\nUse the mkdir command to make the following directories:\n\nmy_project\nmy_project/docs\nmy_project/data\nmy_project/results\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n$ mkdir my_project\n$ mkdir my_project/docs\n$ mkdir my_project/data\n$ mkdir my_project/results\n\n\n\n\n\nUse ls -R to verify that you have created these directories. The -R option for ls stands for recursive. This option causes ls to return the contents of each subdirectory within the directory iteratively.\n$ ls -R my_project\nYou should see the following output:\nmy_project/:\ndata  docs  results\n\nmy_project/data\nmy_project/docs\nmy_project/results"
  },
  {
    "objectID": "shell_lesson/07-organization.html#organizing-your-files",
    "href": "shell_lesson/07-organization.html#organizing-your-files",
    "title": "Project Organization",
    "section": "Organizing your files",
    "text": "Organizing your files\nBefore beginning any analysis, it’s important to save a copy of your raw data. The raw data should never be changed. Regardless of how sure you are that you want to carry out a particular data cleaning step, there’s always the chance that you’ll change your mind later or that there will be an error in carrying out the data cleaning and you’ll need to go back a step in the process. Having a raw copy of your data that you never modify guarantees that you will always be able to start over if something goes wrong with your analysis. When starting any analysis, you can make a copy of your raw data file and do your manipulations on that file, rather than the raw version. We learned in a previous episode how to prevent overwriting our raw data files by setting restrictive file permissions.\nYou can store any results that are generated from your analysis in the results folder. This guarantees that you won’t confuse results file and data files in six months or two years when you are looking back through your files in preparation for publishing your study.\nThe docs folder is the place to store any written analysis of your results, notes about how your analyses were carried out, and documents related to your eventual publication."
  },
  {
    "objectID": "shell_lesson/07-organization.html#documenting-your-activity-on-the-project",
    "href": "shell_lesson/07-organization.html#documenting-your-activity-on-the-project",
    "title": "Project Organization",
    "section": "Documenting your activity on the project",
    "text": "Documenting your activity on the project\nWhen carrying out wet-lab analyses, most scientists work from a written protocol and keep a hard copy of written notes in their lab notebook, including any things they did differently from the written protocol. This detailed record-keeping process is just as important when doing computational analyses. Luckily, it’s even easier to record the steps you’ve carried out computational than it is when working at the bench.\nThe history command is a convenient way to document all the commands you have used while analyzing and manipulating your project files. Let’s document the work we have done on our project so far.\nView the commands that you have used so far during this session using history:\n$ history\nThe history likely contains many more commands than you have used for the current project. Let’s view the last several commands that focus on just what we need for this project.\nView the last n lines of your history (where n = approximately the last few lines you think relevant). For our example, we will use the last 7:\n$ history | tail -n 7\n\n\n\n\n\n\nExercise\n\n\n\nUsing your knowledge of the shell, use the append redirect &gt;&gt; to create a file called my_project_log_XXXX_XX_XX.sh (Use the four-digit year, two-digit month, and two digit day, e.g. my_project_log_2023-10-05.sh)\n\n\n\n\n\n\nSolution\n\n\n\n\n\n$ history | tail -n 7 &gt;&gt; my_project_log_2023-10-05.sh\nNote we used the last 7 lines as an example, the number of lines may vary.\n\n\n\n\n\nYou may have noticed that your history contains the history command itself. To remove this redundancy from our log, let’s use the nano text editor to fix the file:\n$ nano my_project_log_2023-10-05.sh\n(Remember to replace the 2023-10-05 with the actual date.)\nFrom the nano screen, you can use your cursor to navigate, type, and delete any redundant lines.\n\n\n\n\n\n\nNavigating in Nano\n\n\n\n\n\nAlthough nano is useful, it can be frustrating to edit documents, as you can’t use your mouse to navigate to the part of the document you would like to edit. Here are some useful keyboard shortcuts for moving around within a text document in nano. You can find more information by typing Ctrl+G within nano.\n\n\n\n\n\n\n\nkey\naction\n\n\n\n\nCtrl+Space OR Ctrl+→\nto move forward one word\n\n\nAlt+Space OR Esc+Space OR Ctrl+←\nto move back one word\n\n\nCtrl+A\nto move to the beginning of the current line\n\n\nCtrl+E\nto move to the end of the current line\n\n\nCtrl+W\nto search\n\n\n\n\n\n\nAdd a date line and comment to the line where you have created the directory. Recall that any text on a line after a # is ignored by bash when evaluating the text as code. For example:\n# 2023-10-05 \n# Created sample directories for the Unix workshop\nNext, remove any lines of the history that are not relevant by navigating to those lines and using your delete key. Save your file and close nano.\nYour file should look something like this:\n# 2023-10-05 \n# Created sample directories for the Unix workshop\n\nmkdir my_project\nmkdir my_project/docs\nmkdir my_project/data\nmkdir my_project/results\nIf you keep this file up to date, you can use it to re-do your work on your project if something happens to your results files. To demonstrate how this works, first delete your my_project directory and all of its subdirectories. Look at your directory contents to verify the directory is gone.\n$ rm -r my_project\n$ ls\nshell_data  my_project_2023-10-05.sh\nThen run your workshop log file as a bash script. You should see the my_project directory and all of its subdirectories reappear.\n$ bash my_project_log_2023-10-05.sh\n$ ls\nshell_data  my_project\nmy_project_log_2023-10-05.sh\nIt’s important that we keep our workshop log file outside of our my_project directory if we want to use it to recreate our work. It’s also important for us to keep it up to date by regularly updating with the commands that we used to generate our results files.\nCongratulations! You’ve finished your introduction to using the shell for genomics projects. You now know how to navigate your file system, create, copy, move, and remove files and directories, and automate repetitive tasks using scripts and wildcards. With this solid foundation, you’re ready to move on to apply all of these new skills to carrying out more sophisticated bioinformatics analysis work. Don’t worry if everything doesn’t feel perfectly comfortable yet. Practice makes perfect! Get in the habit of applying your new skills to your real work whenever you can."
  },
  {
    "objectID": "shell_lesson/07-organization.html#references",
    "href": "shell_lesson/07-organization.html#references",
    "title": "Project Organization",
    "section": "References",
    "text": "References\nA Quick Guide to Organizing Computational Biology Projects\n\n\n\n\n\n\nKey Points\n\n\n\n\nSpend the time to organize your file system when you start a new project. Your future self will thank you!\nAlways save a write-protected copy of your raw data."
  },
  {
    "objectID": "shell_lesson/05-redirection.html",
    "href": "shell_lesson/05-redirection.html",
    "title": "Redirection",
    "section": "",
    "text": "Objectives\n\n\n\n\nEmploy the grep command to search for information within files.\nPrint the results of a command to a file.\nConstruct command pipelines with two or more stages.\nUse for loops to run the same command for several input files."
  },
  {
    "objectID": "shell_lesson/05-redirection.html#searching-files",
    "href": "shell_lesson/05-redirection.html#searching-files",
    "title": "Redirection",
    "section": "Searching files",
    "text": "Searching files\nWe discussed in a previous episode how to search within a file using less. We can also search within files without even opening them, using grep. grep is a command-line utility for searching plain-text files for lines matching a specific set of characters (sometimes called a string) or a particular pattern (which can be specified using something called regular expressions). We’re not going to work with regular expressions in this lesson, and are instead going to specify the strings we are searching for. Let’s give it a try!\n\n\n\n\n\n\nNucleotide abbreviations\n\n\n\nThe four nucleotides that appear in DNA are abbreviated A, C, T and G. Unknown nucleotides are represented with the letter N. An N appearing in a sequencing file represents a position where the sequencing machine was not able to confidently determine the nucleotide in that position. You can think of an N as being aNy nucleotide at that position in the DNA sequence.\n\n\nWe’ll search for strings inside of our fastq files. Let’s first make sure we are in the correct directory:\n$ cd ~/shell_data/untrimmed_fastq\nSuppose we want to see how many reads in our file have really bad segments containing 10 consecutive unknown nucleotides (Ns).\n\n\n\n\n\n\nDetermining quality\n\n\n\nIn this lesson, we’re going to be manually searching for strings of Ns within our sequence results to illustrate some principles of file searching. It can be really useful to do this type of searching to get a feel for the quality of your sequencing results, however, in your research you will most likely use a bioinformatics tool that has a built-in program for filtering out low-quality reads. You can learn more about how to use one such tool in this Data Carpentry lesson.\n\n\nLet’s search for the string NNNNNNNNNN in the SRR098026 file:\n$ grep NNNNNNNNNN SRR098026.fastq\nThis command returns a lot of output to the terminal. Every single line in the SRR098026 file that contains at least 10 consecutive Ns is printed to the terminal, regardless of how long or short the file is. We may be interested not only in the actual sequence which contains this string, but in the name (or identifier) of that sequence. We discussed in a previous lesson that the identifier line immediately precedes the nucleotide sequence for each read in a FASTQ file. We may also want to inspect the quality scores associated with each of these reads. To get all of this information, we will return the line immediately before each match and the two lines immediately after each match.\nWe can use the -B argument for grep to return a specific number of lines before each match. The -A argument returns a specific number of lines after each matching line. Here we want the line before and the two lines after each matching line, so we add -B1 -A2 to our grep command:\n$ grep -B1 -A2 NNNNNNNNNN SRR098026.fastq\nOne of the sets of lines returned by this command is:\n@SRR098026.177 HWUSI-EAS1599_1:2:1:1:2025 length=35\nCNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNN\n+SRR098026.177 HWUSI-EAS1599_1:2:1:1:2025 length=35\n#!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\ngrep stands for global regular expression print. Regular expressions (or regex) are a system and syntax for sophisticated pattern matching in text (i.e in strings). We won’t be delving deeping into regex syntax here (for more on regex see this lesson), but we can make our code a little more succinct using the -E flag and a regex for matching a character a specified number of times.\n$ grep -B1 -A2 -E \"N{10}\" SRR098026.fastq\nand we get the same output as above.\n\n\n\n\n\n\nExercise\n\n\n\n\nSearch for the sequence GNATNACCACTTCC in the SRR098026.fastq file. Have your search return all matching lines and the name (or identifier) for each sequence that contains a match.\nSearch for the sequence AAGTT in both FASTQ files. Have your search return all matching lines and the name (or identifier) for each sequence that contains a match.\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\ngrep -B1 GNATNACCACTTCC SRR098026.fastq\n\n@SRR098026.245 HWUSI-EAS1599_1:2:1:2:801 length=35\nGNATNACCACTTCCAGTGCTGANNNNNNNGGGATG\n\ngrep -B1 AAGTT *.fastq\n\nSRR097977.fastq-@SRR097977.11 209DTAAXX_Lenski2_1_7:8:3:247:351 length=36\nSRR097977.fastq:GATTGCTTTAATGAAAAAGTCATATAAGTTGCCATG\n--\nSRR097977.fastq-@SRR097977.67 209DTAAXX_Lenski2_1_7:8:3:544:566 length=36\nSRR097977.fastq:TTGTCCACGCTTTTCTATGTAAAGTTTATTTGCTTT\n--\nSRR097977.fastq-@SRR097977.68 209DTAAXX_Lenski2_1_7:8:3:724:110 length=36\nSRR097977.fastq:TGAAGCCTGCTTTTTTATACTAAGTTTGCATTATAA\n--\nSRR097977.fastq-@SRR097977.80 209DTAAXX_Lenski2_1_7:8:3:258:281 length=36\nSRR097977.fastq:GTGGCGCTGCTGCATAAGTTGGGTTATCAGGTCGTT\n--\nSRR097977.fastq-@SRR097977.92 209DTAAXX_Lenski2_1_7:8:3:353:318 length=36\nSRR097977.fastq:GGCAAAATGGTCCTCCAGCCAGGCCAGAAGCAAGTT\n--\nSRR097977.fastq-@SRR097977.139 209DTAAXX_Lenski2_1_7:8:3:703:655 length=36\nSRR097977.fastq:TTTATTTGTAAAGTTTTGTTGAAATAAGGGTTGTAA\n--\nSRR097977.fastq-@SRR097977.238 209DTAAXX_Lenski2_1_7:8:3:592:919 length=36\nSRR097977.fastq:TTCTTACCATCCTGAAGTTTTTTCATCTTCCCTGAT\n--\nSRR098026.fastq-@SRR098026.158 HWUSI-EAS1599_1:2:1:1:1505 length=35\nSRR098026.fastq:GNNNNNNNNCAAAGTTGATCNNNNNNNNNTGTGCG"
  },
  {
    "objectID": "shell_lesson/05-redirection.html#redirecting-output",
    "href": "shell_lesson/05-redirection.html#redirecting-output",
    "title": "Redirection",
    "section": "Redirecting output",
    "text": "Redirecting output\ngrep allowed us to identify sequences in our FASTQ files that match a particular pattern. All of these sequences were printed to our terminal screen, but in order to work with these sequences and perform other operations on them, we will need to capture that output in some way.\nWe can do this with something called “redirection”. The idea is that we are taking what would ordinarily be printed to the terminal screen and redirecting it to another location. In our case, we want to print this information to a file so that we can look at it later and use other commands to analyze this data.\nThe command for redirecting output to a file is &gt;.\nLet’s try out this command and copy all the records (including all four lines of each record) in our FASTQ files that contain ‘NNNNNNNNNN’ to another file called bad_reads.txt.\n$ grep -B1 -A2 -E \"N{10}\" SRR098026.fastq &gt; bad_reads.txt\n\n\n\n\n\n\nFile extensions\n\n\n\n\n\nYou might be confused about why we’re naming our output file with a .txt extension. After all, it will be holding FASTQ formatted data that we’re extracting from our FASTQ files. Won’t it also be a FASTQ file? The answer is, yes - it will be a FASTQ file and it would make sense to name it with a .fastq extension. However, using a .fastq extension will lead us to problems when we move to using wildcards later in this episode. We’ll point out where this becomes important. For now, it’s good that you’re thinking about file extensions!\n\n\n\nThe prompt should sit there a little bit, and then it should look like nothing happened. But type ls. You should see a new file called bad_reads.txt.\nWe can check the number of lines in our new file using a command called wc. wc stands for word count. This command counts the number of words, lines, and characters in a file. The FASTQ file may change over time, so given the potential for updates, make sure your file matches your instructor’s output.\nAs of Sept. 2023, wc gives the following output:\n$ wc bad_reads.txt\n  537  1073 23217 bad_reads.txt\nThis will tell us the number of lines, words and characters in the file. If we want only the number of lines, we can use the -l flag for lines.\n$ wc -l bad_reads.txt\n537 bad_reads.txt\n\n\n\n\n\n\nExercise\n\n\n\nHow many sequences in SRR098026.fastq contain at least 3 consecutive Ns?\n\n\n\n\n\n\nSolution\n\n\n\n\n\n$ grep NNN SRR098026.fastq &gt; bad_reads.txt\n$ wc -l bad_reads.txt\n249 bad_reads.txt\n\n\n\n\n\nWe might want to search multiple FASTQ files for sequences that match our search pattern. However, we need to be careful, because each time we use the &gt; command to redirect output to a file, the new output will replace the output that was already present in the file. This is called “overwriting”.\n$ grep -B1 -A2 -E \"N{10}\" SRR098026.fastq &gt; bad_reads.txt\n$ wc -l bad_reads.txt\n537 bad_reads.txt\n$ grep -B1 -A2 -E \"N{10}\" SRR097977.fastq &gt; bad_reads.txt\n$ wc -l bad_reads.txt\n0 bad_reads.txt\nHere, the output of our second call to wc shows that we no longer have any lines in our bad_reads.txt file. This is because the second file we searched (SRR097977.fastq) does not contain any lines that match our search sequence. So our file was overwritten and is now empty.\nWe can avoid overwriting our files by using the command &gt;&gt;. &gt;&gt; is known as the “append redirect” and will append new output to the end of a file, rather than overwriting it.\n$ grep -B1 -A2 -E \"N{10}\" SRR098026.fastq &gt; bad_reads.txt\n$ wc -l bad_reads.txt\n537 bad_reads.txt\n$ grep -B1 -A2 -E \"N{10}\" SRR097977.fastq &gt;&gt; bad_reads.txt\n$ wc -l bad_reads.txt\n537 bad_reads.txt\nThe output of our second call to wc shows that we have not overwritten our original data.\nWe can also do this with a single line of code by using a wildcard:\n$ grep -B1 -A2 NNNNNNNNNN *.fastq &gt; bad_reads.txt\n$ wc -l bad_reads.txt\n537 bad_reads.txt\n\n\n\n\n\n\nFile extensions - part 2\n\n\n\n\n\nThis is where we would have trouble if we were naming our output file with a .fastq extension. If we already had a file called bad_reads.fastq (from our previous grep practice) and then ran the command above using a .fastq extension instead of a .txt extension, grep would give us a warning.\ngrep -B1 -A2 -E \"N{10}\" *.fastq &gt; bad_reads.fastq\ngrep: input file ‘bad_reads.fastq' is also the output\ngrep is letting you know that the output file bad_reads.fastq is also included in your grep call because it matches the *.fastq pattern. Be careful with this as it can lead to some unintended results.\n\n\n\nSince we might have multiple different criteria we want to search for, creating a new output file each time has the potential to clutter up our workspace. We also thus far haven’t been interested in the actual contents of those files, only in the number of reads that we’ve found. We created the files to store the reads and then counted the lines in the file to see how many reads matched our criteria. There’s a way to do this, however, that doesn’t require us to create these intermediate files - the pipe command (|).\nThis is probably not a key on your keyboard you use very much, so let’s all take a minute to find that key. In the UK and US keyboard layouts, and several others, the | character can be found using the key combination Shift + \\ .\nThis may be different for other language-specific layouts.\nWhat | does is take the output that is scrolling by on the terminal and uses that output as input to another command.\nIf we don’t want to create a file before counting lines of output from our grep search, we could directly pipe the output of the grep search to the command wc -l. This can be helpful for investigating your output if you are not sure you would like to save it to a file.\n$ grep -B1 -A2 -E \"N{10}\" SRR098026.fastq | wc -l \n537\nBecause we asked grep for all four lines of each FASTQ record, we need to divide the output by four to get the number of sequences that match our search pattern.\n$ echo $((537 / 4))\n134\nor to do this programatically\n$ echo $(($(grep -B1 -A2 -E \"N{10}\" *.fastq | wc -l) /4))\n134\n\n\n\n\n\n\nImportant\n\n\n\nUnix has a few different ways to do basic arithmetic, one of which we demonstrate here with echo and $((expression)) notation. It’s important to know that most built-in Unix utilities do not do floating point arithmetic - that is, calculations will always return an integer.\nIf you try 537 / 4 in a calculator you’ll get 134.25. Where does the extra line come from? In this case, there were two sequences that had no Ns and grep inserted some additional lines in our file to separate them out. For more information see: the full Data Carpentry lesson.\n\n\n\n\n\n\n\n\nCustom grep control\n\n\n\nUse grep --help (or man grep on a Mac) to read more about other options to customize the output of grep including extended options, anchoring characters, and much more.\n\n\nRedirecting output is often not intuitive, and can take some time to get used to. Once you’re comfortable with redirection, however, you’ll be able to combine any number of commands to do all sorts of exciting things with your data!\nNone of the command line programs we’ve been learning do anything all that impressive on their own, but when you start chaining them together, you can do some really powerful things very efficiently.\n\n\n\n\n\n\nFile manipulation and more practices with pipes\n\n\n\nTo practice a bit more with the tools we’ve added to our tool kit so far and learn a few extra ones you can follow this extra lesson which uses the SRA metadata file."
  },
  {
    "objectID": "shell_lesson/05-redirection.html#writing-for-loops",
    "href": "shell_lesson/05-redirection.html#writing-for-loops",
    "title": "Redirection",
    "section": "Writing for loops",
    "text": "Writing for loops\nLoops are key to productivity improvements through automation as they allow us to execute commands repeatedly. Similar to wildcards and tab completion, using loops also reduces the amount of typing (and typing mistakes). Loops are helpful when performing operations on groups of sequencing files, such as unzipping or trimming multiple files. We will use loops for these purposes in subsequent analyses, but will cover the basics of them for now.\nWhen the shell sees the keyword for, it knows to repeat a command (or group of commands) once for each item in a list. Each time the loop runs (called an iteration), an item in the list is assigned in sequence to the variable, and the commands inside the loop are executed, before moving on to the next item in the list. Inside the loop, we call for the variable’s value by putting $ in front of it. The $ tells the shell interpreter to treat the variable as a variable name and substitute its value in its place, rather than treat it as text or an external command. In shell programming, this is usually called “expanding” the variable.\nWe declare a variable by saying\n$ varname=value\nlike\n$ day=Thurs\nand to check it was assigned we can print the variable and concatenate into a larger string with echo. We call the variable with a $\n$ echo today is $day\ntoday is Thurs\nSometimes, we want to expand a variable without any whitespace to its right. Suppose we would like to expand Thurs to create the text Thursday.\n$ echo today is $dayday      # doesn't work\ntoday is\nThe interpreter is trying to expand a variable named Thursday, which (probably) doesn’t exist. We can avoid this problem by enclosing the variable name in braces ({ and }, also called “curly brackets”). bash treats the # character as a comment character. Any text on a line after a # is ignored by bash when evaluating the text as code.\n$ echo today is ${day}day      # now it works!\ntoday is Thursday\nLet’s write a for loop to show us the first two lines of the fastq files we downloaded earlier.\nThe basic template of a for loop is\n\n\n\n\n\n\nfor &lt;variable&gt; in &lt;group to iterate over&gt;\n  do\n    &lt;line or lines of code involving the variable&gt;\ndone\n\n\n\nSo now let’s try it\n$ cd ../untrimmed_fastq/\n$ for filename in *.fastq\n&gt; do\n&gt; head -n 2 ${filename}\n&gt; done\nYou will notice the shell prompt changes from $ to &gt; and back again as we were typing in our loop. The second prompt, &gt;, is different to remind us that we haven’t finished typing a complete command yet. A semicolon, ;, can be used to separate two commands written on a single line.\nIn this case, the word filename is designated as the variable to be used over each iteration. In our case SRR097977.fastq and SRR098026.fastq will be substituted for filename because they fit the pattern of ending with .fastq in the directory we’ve specified. The next line of the for loop is do.\nThe next line is the code that we want to execute. We are telling the loop to print the first two lines of each variable we iterate over.\nFinally, the word done ends the loop.\nAfter executing the loop, you should see the first two lines of both fastq files printed to the terminal. Let’s create a loop that will save this information to a file.\n$ for filename in *.fastq\n&gt; do\n&gt; head -n 2 ${filename} &gt;&gt; seq_info.txt\n&gt; done\nWhen writing a loop, you will not be able to return to previous lines once you have pressed Enter. Remember that we can cancel the current command using\n\nCtrl+C\n\nIf you notice a mistake that is going to prevent your loop for executing correctly.\nNote that we are using &gt;&gt; to append the text to our seq_info.txt file. If we used &gt;, the seq_info.txt file would be rewritten every time the loop iterates, so it would only have text from the last variable used. Instead, &gt;&gt; adds to the end of the file.\n\n\n\n\n\n\nUsing Basename in for loops\n\n\n\n\n\nBasename is a function in UNIX that is helpful for removing a uniform part of a name from a list of files. In this case, we will use basename to remove the .fastq extension from the files that we’ve been working with.\n$ basename SRR097977.fastq .fastq\nWe see that this returns just the SRR accession, and no longer has the .fastq file extension on it.\nSRR097977\nIf we try the same thing but use .fasta as the file extension instead, nothing happens. This is because basename only works when it exactly matches a string in the file.\n$ basename SRR097977.fastq .fasta\nSRR097977.fastq\nBasename is really powerful when used in a for loop. It allows to access just the file prefix, which you can use to name things. Let’s try this.\nInside our for loop, we create a new name variable. We call the basename function inside the parenthesis, then give our variable name from the for loop, in this case ${filename}, and finally state that .fastq should be removed from the file name. It’s important to note that we’re not changing the actual files, we’re creating a new variable called name. The line &gt; echo $name will print to the terminal the variable name each time the for loop runs. Because we are iterating over two files, we expect to see two lines of output.\n$ for filename in *.fastq\n&gt; do\n&gt; name=$(basename ${filename} .fastq)\n&gt; echo ${name}\n&gt; done\n\n\n\n\n\n\nExercise\n\n\n\nPrint the file prefix of all of the .txt files in our current directory.\n\n\n\n\n\n\nSolution\n\n\n\n\n\n$ for filename in *.txt\n&gt; do\n&gt; name=$(basename ${filename} .txt)\n&gt; echo ${name}\n&gt; done\n\n\n\n\n\nOne way this is really useful is to move files. Let’s rename all of our .txt files using mv so that they have the years on them, which will document when we created them.\n$ for filename in *.txt\n&gt; do\n&gt; name=$(basename ${filename} .txt)\n&gt; mv ${filename}  ${name}_2019.txt\n&gt; done\n\n\n\n\n\n\n\n\n\nExercise\n\n\n\nRemove _2019 from all of the .txt files.\n\n\n\n\n\n\nSolution\n\n\n\n\n\n$ for filename in *_2019.txt\n&gt; do\n&gt; name=$(basename ${filename} _2019.txt)\n&gt; mv ${filename} ${name}.txt\n&gt; done\n\n\n\n\n\n\n\n\n\n\n\nKey points\n\n\n\n\ngrep is a powerful search tool with many options for customization.\n&gt;, &gt;&gt;, and | are different ways of redirecting output.\ncommand &gt; file redirects a command’s output to a file.\ncommand &gt;&gt; file redirects a command’s output to a file without overwriting the existing contents of the file.\ncommand_1 | command_2 redirects the output of the first command as input to the second command.\nfor loops are used for iteration.\nbasename gets rid of repetitive parts of names."
  },
  {
    "objectID": "shell_lesson/03-working-with-files-part01.html",
    "href": "shell_lesson/03-working-with-files-part01.html",
    "title": "Working with Files and Directories I",
    "section": "",
    "text": "Objectives\n\nUse wildcards (*) to perform operations on multiple files.\nUse the history command to view and repeat recently used commands.\n\nQuestions to be answered in this lesson\n\nHow can I view and search file contents?\nHow can I repeat recently used commands?"
  },
  {
    "objectID": "shell_lesson/03-working-with-files-part01.html#working-with-files",
    "href": "shell_lesson/03-working-with-files-part01.html#working-with-files",
    "title": "Working with Files and Directories I",
    "section": "Working with Files",
    "text": "Working with Files\n\nOur data set: FASTQ files\nNow that we know how to navigate around our directory structure, let’s start working with our sequencing files. We did a sequencing experiment and have two results files, which are stored in our untrimmed_fastq directory.\n\n\nWildcards\nNavigate to your untrimmed_fastq directory:\n$ cd shell_data/untrimmed_fastq\nWe are interested in looking at the FASTQ files in this directory. We can list all files with the .fastq extension using the command:\n$ ls *.fastq\nOutput:\nSRR097977.fastq  SRR098026.fastq\nThe * character is a special type of character called a wildcard, which can be used to represent any number of any type of character. Thus, *.fastq matches every file that ends with .fastq.\nThis command lists only the file that ends with 977.fastq. Command:\n$ ls *977.fastq\nOutput:\nSRR097977.fastq\nNow lest search for files in your root directory. The following command lists every file in /usr/bin that ends in the characters .sh. Note that the output displays full paths to files, since each result starts with /.\nCommand:\n$ ls /usr/bin/*.sh\nOutput:\n/usr/bin/findssl.sh  /usr/bin/gettext.sh"
  },
  {
    "objectID": "shell_lesson/03-working-with-files-part01.html#exercise",
    "href": "shell_lesson/03-working-with-files-part01.html#exercise",
    "title": "Working with Files and Directories I",
    "section": "Exercise",
    "text": "Exercise\nDo each of the following tasks from your current directory using a single ls command for each:\n\nList all of the files in /usr/bin that start with the letter ‘c’.\nList all of the files in /usr/bin that contain the letter ‘a’.\nList all of the files in /usr/bin that end with the letter ‘o’.\n\nBonus: List all of the files in /usr/bin that contain the letter ‘a’ or the letter ‘c’.\nHint: The bonus question requires a Unix wildcard that we haven’t talked about yet. Try searching the internet for information about Unix wildcards to find what you need to solve the bonus problem.\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\nls /usr/bin/c*\nls /usr/bin/*a*\nls /usr/bin/*o\nBonus: ls /usr/bin/*[ac]*"
  },
  {
    "objectID": "shell_lesson/03-working-with-files-part01.html#exercise-1",
    "href": "shell_lesson/03-working-with-files-part01.html#exercise-1",
    "title": "Working with Files and Directories I",
    "section": "Exercise",
    "text": "Exercise\necho is a built-in shell command that writes its arguments, like a line of text to standard output. The echo command can also be used with pattern matching characters, such as wildcard characters. Here we will use the echo command to see how the wildcard character is interpreted by the shell.\nCommand:\n$ echo *.fastq\nOutput:\nSRR097977.fastq SRR098026.fastq\nThe * is expanded to include any file that ends with .fastq. We can see that the output of echo *.fastq is the same as that of ls *.fastq.\nWhat would the output look like if the wildcard could not be matched? Compare the outputs of echo *.missing and ls *.missing.\n\n\n\n\n\n\nTip\n\n\n\n\n\n##Solution\nCommand:\n$ echo *.missing\nOutput:\n*.missing\nCommand:\n$ ls *.missing\nOutput: Note: This is an example\nls: cannot access '*.missing': No such file or directory"
  },
  {
    "objectID": "shell_lesson/03-working-with-files-part01.html#command-history",
    "href": "shell_lesson/03-working-with-files-part01.html#command-history",
    "title": "Working with Files and Directories I",
    "section": "Command History",
    "text": "Command History\nIf you want to repeat a command that you’ve run recently, you can access previous commands using the up arrow on your keyboard to go back to the most recent command. Likewise, the down arrow takes you forward in the command history.\nA few more useful shortcuts:\n\nCtrl+C will cancel the command you are writing, and give you a fresh prompt.\nCtrl+R will do a reverse-search through your command history. This is very useful.\nCtrl+L or the clear command will clear your screen.\n\nYou can also review your recent commands with the history command, by entering:\n$ history\nto see a numbered list of recent commands. You can reuse one of these commands directly by referring to the number of that command.\nFor example, if your history looked like this:\n259  ls *\n260  ls /usr/bin/*.sh\n261  ls *R1*fastq\nthen you could repeat command #260 by entering:\n$ !260\nType ! (exclamation point) and then the number of the command from your history. You will be glad you learned this when you need to re-run very complicated commands. For more information on advanced usage of history, read section 9.3 of Bash manual."
  },
  {
    "objectID": "shell_lesson/03-working-with-files-part01.html#exercise-2",
    "href": "shell_lesson/03-working-with-files-part01.html#exercise-2",
    "title": "Working with Files and Directories I",
    "section": "Exercise",
    "text": "Exercise\nFind the line number in your history for the command that listed all the .sh files in /usr/bin. Rerun that command.\n\n\n\n\n\n\nTip\n\n\n\n\n\n##Solution\nFirst type history. Then use ! followed by the line number to rerun that command."
  },
  {
    "objectID": "shell_lesson/03-working-with-files-part01.html#examining-files",
    "href": "shell_lesson/03-working-with-files-part01.html#examining-files",
    "title": "Working with Files and Directories I",
    "section": "Examining Files",
    "text": "Examining Files\nWe now know how to switch directories, run programs, and look at the contents of directories, but how do we look at the contents of files?\nOne way to examine a file is to print out all of the contents using the program cat.\nEnter the following command from within the untrimmed_fastq directory:\n$ cat SRR098026.fastq\nThis will print out all of the contents of the SRR098026.fastq to the screen.\nExercise\n\nPrint out the contents of the ~/shell_data/untrimmed_fastq/SRR097977.fastq file. What is the last line of the file?\nFrom your home directory, and without changing directories, use one short command to print the contents of all of the files in the ~/shell_data/untrimmed_fastq directory.\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\nThe last line of the file is C:CCC::CCCCCCCC&lt;8?6A:C28C&lt;608'&&&,'$.\ncat Desktop/unix_lesson/shell_data/untrimmed_fastq/*\n\n\n\n\ncat is a terrific program, but when the file is really big, it can be annoying to use. The program, less, is useful for this case. less opens the file as read only, and lets you navigate through it. The navigation commands are identical to the --help program.\nEnter the following command:\n$ less SRR097977.fastq\nSome navigation commands in less:\n\n\n\nkey\naction\n\n\n\n\nSpace\nto go forward\n\n\nb\nto go backward\n\n\ng\nto go to the beginning\n\n\nG\nto go to the end\n\n\nq\nto quit\n\n\n\nless also gives you a way of searching through files. Use the “/” key to begin a search. Enter the word you would like to search for and press enter. The screen will jump to the next location where that word is found.\nShortcut:\nIf you hit “/” then “enter”, less will repeat the previous search. less searches from the current location and works its way forward. Scroll up a couple lines on your terminal to verify you are at the beginning of the file. Note, if you are at the end of the file and search for the sequence “CAA”, less will not find it. You either need to go to the beginning of the file (by typing g) and search again using / or you can use ? to search backwards in the same way you used / previously.\nFor instance, let’s search forward for the sequence TTTTT in our file. You can see that we go right to that sequence, what it looks like, and where it is in the file. If you continue to type / and hit return, you will move forward to the next instance of this sequence motif. If you instead type ? and hit return, you will search backwards and move up the file to previous examples of this motif."
  },
  {
    "objectID": "shell_lesson/03-working-with-files-part01.html#exercise-3",
    "href": "shell_lesson/03-working-with-files-part01.html#exercise-3",
    "title": "Working with Files and Directories I",
    "section": "Exercise",
    "text": "Exercise\nWhat are the next three nucleotides (characters) after the first instance of the sequence quoted above?\n\n\n\n\n\n\nSolution\n\n\n\n\n\nCAC\n\n\n\nRemember, the --help program actually uses less internally and therefore uses the same commands, so you can search documentation using “/” as well!\nThere’s another way that we can look at files, and in this case, just look at part of them. This can be particularly useful if we just want to see the beginning or end of the file, or see how it’s formatted.\nThe commands are head and tail and they let you look at the beginning and end of a file respectively.\nCommand:\n$ head SRR098026.fastq\nOutput:\n@SRR098026.1 HWUSI-EAS1599_1:2:1:0:968 length=35\nNNNNNNNNNNNNNNNNCNNNNNNNNNNNNNNNNNN\n+SRR098026.1 HWUSI-EAS1599_1:2:1:0:968 length=35\n!!!!!!!!!!!!!!!!#!!!!!!!!!!!!!!!!!!\n@SRR098026.2 HWUSI-EAS1599_1:2:1:0:312 length=35\nNNNNNNNNNNNNNNNNANNNNNNNNNNNNNNNNNN\n+SRR098026.2 HWUSI-EAS1599_1:2:1:0:312 length=35\n!!!!!!!!!!!!!!!!#!!!!!!!!!!!!!!!!!!\n@SRR098026.3 HWUSI-EAS1599_1:2:1:0:570 length=35\nNNNNNNNNNNNNNNNNANNNNNNNNNNNNNNNNNN\nCommand:\n$ tail SRR098026.fastq\nOutput:\n+SRR098026.247 HWUSI-EAS1599_1:2:1:2:1311 length=35\n#!##!#################!!!!!!!######\n@SRR098026.248 HWUSI-EAS1599_1:2:1:2:118 length=35\nGNTGNGGTCATCATACGCGCCCNNNNNNNGGCATG\n+SRR098026.248 HWUSI-EAS1599_1:2:1:2:118 length=35\nB!;?!A=5922:##########!!!!!!!######\n@SRR098026.249 HWUSI-EAS1599_1:2:1:2:1057 length=35\nCNCTNTATGCGTACGGCAGTGANNNNNNNGGAGAT\n+SRR098026.249 HWUSI-EAS1599_1:2:1:2:1057 length=35\nA!@B!BBB@ABAB#########!!!!!!!######\nThe -n option to either of these commands can be used to print the first or last n lines of a file.\nCommand:\n$ head -n 1 SRR098026.fastq\nOutput:\n@SRR098026.1 HWUSI-EAS1599_1:2:1:0:968 length=35\nCommand:\n$ tail -n 1 SRR098026.fastq\nOutput:\nA!@B!BBB@ABAB#########!!!!!!!######\nLesson Keypoints\n\nYou can view file contents using less, cat, head, less or tail.\nThe history command and the up arrow on your keyboard can be used to repeat recently used commands.\nUsing echo for The echo pattern matching characters, and for printing stuff in the terminal."
  },
  {
    "objectID": "shell_lesson/01-introduction.html",
    "href": "shell_lesson/01-introduction.html",
    "title": "Introducing the Shell",
    "section": "",
    "text": "Objectives\n\n\n\n\nDescribe key reasons for learning shell.\nNavigate your file system using the Git Bash command line.\nAccess and read help files for bash programs and use help files to identify useful command options.\nDemonstrate the use of tab completion, and explain its advantages.\n\nQuestions to be answered in this lesson\n\nWhat is a command shell and why would I use one?\nHow can I move around on my computer?\nHow can I see what files and directories I have?\nHow can I specify the location of a file or directory on my computer?"
  },
  {
    "objectID": "shell_lesson/01-introduction.html#what-is-a-shell",
    "href": "shell_lesson/01-introduction.html#what-is-a-shell",
    "title": "Introducing the Shell",
    "section": "What is a shell?",
    "text": "What is a shell?\nA shell is a computer program that presents a command line interface which allows you to control your computer using commands entered with a keyboard instead of controlling graphical user interfaces (GUIs) with a mouse/keyboard/touchscreen combination.\nThere are different types of shell such as Windows Powershell, Windows Command Shell, Bash and zsh for Mac computers.\nFor this workshop we will be using Git Bash, which is a command-line shell that enables Git commands and provides some unix based shell utilities but not all of them. The commands that we will be exploring can be also used in a zsh (Mac Terminal) or PowerShell (Windows Shell) with very little or no modifications.\nIt is important to consider that Git Bash may not be compatible with other command line programs, and it is recommended to use Windows Linux Subsystem, a Linux Distribution if you plan on working with a Linux enviroment in a Windows machine."
  },
  {
    "objectID": "shell_lesson/01-introduction.html#why-should-i-learn-shell",
    "href": "shell_lesson/01-introduction.html#why-should-i-learn-shell",
    "title": "Introducing the Shell",
    "section": "Why should I learn Shell?",
    "text": "Why should I learn Shell?\nThere are many reasons that may benefit you from learning about about the shell:\n\nAutomate repetitive tasks. If you often need to repeat tasks with a large number of files, with the shell, you can automate those.\nMake your work less error-prone. The shell makes your work less error-prone. When humans do the same thing a hundred different times (or even ten times), they’re likely to make a mistake. Your computer can do the same thing a thousand times with no mistakes.\nMake your work reproductible. By using the command-line, the your computer keeps a record of every step that you’ve carried out, which you can use to re-do your work when you need to. It also gives you a way to communicate unambiguously what you’ve done, so that others can inspect or apply your process to new data.\nSave on computing capacity. Sometimes, when we work with data some tasks may require large amounts of computing power and can’t realistically be run on your own machine. These tasks are best performed using remote computers or cloud computing, which can only be accessed through a shell.\nGet advantage of the command line tools. Many bioinformatics tools can only be used through a command line interface. Many more have features and parameter options which are not available in the GUI. BLAST is an example. Many of the advanced functions are only accessible to users who know how to use a shell."
  },
  {
    "objectID": "shell_lesson/01-introduction.html#the-git-bash-window",
    "href": "shell_lesson/01-introduction.html#the-git-bash-window",
    "title": "Introducing the Shell",
    "section": "The Git Bash Window",
    "text": "The Git Bash Window\nAs you open your Git Bash Window, you may see something like the following:\nComputerUserName-####ABC MINGW64 ~\n$\nThe dollar sign is a prompt, which shows us that the shell is waiting for input; your shell may use a different character as a prompt and may add information before the prompt. When typing commands, either from these lessons or from other sources, do not type the prompt, only the commands that follow it.\nThis symbol may be different if you are using a Linux or Mac computer."
  },
  {
    "objectID": "shell_lesson/01-introduction.html#navigating-your-file-system",
    "href": "shell_lesson/01-introduction.html#navigating-your-file-system",
    "title": "Introducing the Shell",
    "section": "Navigating your file system",
    "text": "Navigating your file system\nThe part of the operating system that manages files and directories is called the file system. It organizes our data into files, which hold information, and directories (also called “folders”), which hold files or other directories.\nSeveral commands are frequently used to create, inspect, rename, and delete files and directories.\nLet’s find out where we are by running a command called pwd (which stands for “print working directory”).\nAt any moment, our current working directory is our current default directory, i.e., the directory that the computer assumes we want to run commands in, unless we explicitly specify something else.\nCommand:\n$ pwd\nLet’s look at how our file system is organized. We can see what files and subdirectories are in this directory by running ls, which stands for “listing”:\nCommand:\n$ ls\nls prints the names of the files and directories in the current directory in alphabetical order, arranged neatly into columns. We’ll be working within the shell_data subdirectory, and creating new subdirectories, throughout this workshop.\nThe command to change locations in our file system is cd, followed by a directory name to change our working directory. cd stands for “change directory”.\nLet’s say we want to navigate to the shell_data directory we saw above. We can use the following command to get there:\nCommand:\n$ cd shell_data\nLet’s look at what is in this directory:\nCommand:\n$ ls\nOutput:\nsra_metadata  untrimmed_fastq\nWe can make the ls output more comprehensible by using the flag -F, which tells ls to add a trailing / to the names of directories:\nCommand:\n$ ls -F\nOutput:\nsra_metadata/  untrimmed_fastq/\nAnything with a “/” after it is a directory. Things with a “*” after them are programs. If there are no decorations, it’s a file. ls has lots of other options.\nTo find out what they are, we can type:\n$ ls --help\nls --help displays detailed documentation for commands in git bash. It is a powerful resource to explore bash commands, understand their usage and flags. Some manual files are very long. You can scroll through the file using your keyboard’s down arrow or use the Space key to go forward one page and the b key to go backwards one page. When you are done reading, hit q to quit."
  },
  {
    "objectID": "shell_lesson/01-introduction.html#exercise",
    "href": "shell_lesson/01-introduction.html#exercise",
    "title": "Introducing the Shell",
    "section": "Exercise",
    "text": "Exercise\nUse the -l option for the ls command to display more information for each item in the directory.\nWhat is one piece of additional information this long format gives you that you don’t see with the bare ls command?\n\n\n\n\n\n\nSolution\n\n\n\n\n\nCommand:\n$ ls -l\nOutput: Note: This is an example\ntotal 8\ndrwxr-x--- user user 4096 Jul 30  2015 sra_metadata\ndrwxr-xr-x user user 4096 Nov 15  2017 untrimmed_fastq\n\n\n\nThe additional information given includes the name of the owner of the file, when the file was last modified, and whether the current user has permission to read and write to the file.\n\n\n\n\n\n\nTip\n\n\n\nNo one can possibly learn all of these arguments, that’s what the help page is for. You can (and should) refer to the help page or other help files as needed.\n\n\nLet’s go into the untrimmed_fastq directory and see what is in there.\nCommand:\n$ cd untrimmed_fastq\n$ ls -F\nOutput:\nSRR097977.fastq  SRR098026.fastq\nThis directory contains two files with .fastq extensions. FASTQ is a format for storing information about sequencing reads and their quality. We will be learning more about FASTQ files in a later lesson."
  },
  {
    "objectID": "shell_lesson/01-introduction.html#shortcut-tab-completion",
    "href": "shell_lesson/01-introduction.html#shortcut-tab-completion",
    "title": "Introducing the Shell",
    "section": "Shortcut: Tab Completion",
    "text": "Shortcut: Tab Completion\nTyping out file or directory names can waste a lot of time and it’s easy to make typing mistakes.Instead we can use tab complete as a shortcut. When you start typing out the name of a directory or file, then hit the Tab key, the shell will try to fill in the rest of the directory or file name.\nReturn to your home directory and navigate to your desktop.\nCommand:\n$ cd \n$ cd Desktop\n$ cd unix_lesson\nUse the tab shorcut to return to shell_data directory.\n$ cd she&lt;tab&gt;\nThe shell will fill in the rest of the directory name for shell_data.\nNow, change directories to untrimmed_fastq\n$ cd un&lt;tab&gt;&lt;tab&gt;\nUsing tab complete can be very helpful. However, it will only autocomplete a file or directory name if you’ve typed enough characters to provide a unique identifier for the file or directory you are trying to access.\nFor example, if we now try to list the files which names start with SR by using tab complete:\n$ ls SR&lt;tab&gt;\nThe shell auto-completes your command to SRR09, because all file names in the directory begin with this prefix. When you hit Tab again, the shell will list the possible choices.\nCommand:\n$ ls SRR09&lt;tab&gt;&lt;tab&gt;\nOutput:\nSRR097977.fastq  SRR098026.fastq\nTab completion can also fill in the names of programs, which can be useful if you remember the beginning of a program name.\nCommand:\n$ pw&lt;tab&gt;&lt;tab&gt;\nOutput:\npwck      pwconv    pwd       pwdx      pwunconv\nDisplays the name of every program that starts with pw."
  },
  {
    "objectID": "shell_lesson/01-introduction.html#summary",
    "href": "shell_lesson/01-introduction.html#summary",
    "title": "Introducing the Shell",
    "section": "Summary",
    "text": "Summary\nWe now know how to move around our file system using the command line. This gives us an advantage over interacting with the file system through a GUI as it allows us to work on a remote server, carry out the same set of operations on a large number of files quickly, and opens up many opportunities for using bioinformatic software that is only available in command line versions.\nIn the next few episodes, we’ll be expanding on these skills and seeing how using the command line shell enables us to make our workflow more efficient and reproducible.\nLesson Keypoints\n\nThe shell gives you the ability to work more efficiently by using keyboard commands rather than a GUI.\nUseful commands for navigating your file system include: ls, pwd, and cd.\nMost commands take options (flags) which begin with a -.\nTab completion can reduce errors from mistyping and make work more efficient in the shell."
  },
  {
    "objectID": "r_lesson/06-r-help.html",
    "href": "r_lesson/06-r-help.html",
    "title": "Getting help with R",
    "section": "",
    "text": "Locate help for an R function using ?, ??, and args()\nCheck the version of R\nBe able to ask effective questions when searching for help on forums or using web searches"
  },
  {
    "objectID": "r_lesson/06-r-help.html#getting-help-with-r",
    "href": "r_lesson/06-r-help.html#getting-help-with-r",
    "title": "Getting help with R",
    "section": "Getting help with R",
    "text": "Getting help with R\n\nNo matter how much experience you have with R, you will find yourself needing help. There is no shame in researching how to do something in R, and most people will find themselves looking up how to do the same things that they “should know how to do” over and over again. Here are some tips to make this process as helpful and efficient as possible.\n\n“Never memorize something that you can look up” -- A. Einstein"
  },
  {
    "objectID": "r_lesson/06-r-help.html#finding-help-on-stackoverflow-and-biostars",
    "href": "r_lesson/06-r-help.html#finding-help-on-stackoverflow-and-biostars",
    "title": "Getting help with R",
    "section": "Finding help on Stackoverflow and Biostars",
    "text": "Finding help on Stackoverflow and Biostars\nTwo popular websites will be of great help with many R problems. For general R questions, Stack Overflow is probably the most popular online community for developers. If you start your question “How to do X in R” results from Stack Overflow are usually near the top of the list. For bioinformatics specific questions, Biostars is a popular online forum.\n\n\n\n\n\n\nTip: Asking for help using online forums:\n\n\n\n\nWhen searching for R help, look for answers with the ‘r’ tag.\nGet an account; not required to view answers but to required to post\nPut in effort to check thoroughly before you post a question; folks get annoyed if you ask a very common question that has been answered multiple times\nBe careful. While forums are very helpful, you can’t know for sure if the advice you are getting is correct\nSee the How to ask for R help blog post for more useful tips"
  },
  {
    "objectID": "r_lesson/06-r-help.html#help-people-help-you",
    "href": "r_lesson/06-r-help.html#help-people-help-you",
    "title": "Getting help with R",
    "section": "Help people help you",
    "text": "Help people help you\nOften, in order to duplicate the issue you are having, someone may need to see the data you are working with or verify the versions of R or R packages you are using. The following R functions will help with this:\nYou can check the version of R you are working with using the sessionInfo() function. Actually, it is good to save this information as part of your notes on any analysis you are doing. When you run the same script that has worked fine a dozen times before, looking back at these notes will remind you that you upgraded R and forget to check your script.\nsessionInfo()\nR version 3.2.3 (2015-12-10)\nPlatform: x86_64-pc-linux-gnu (64-bit)\nRunning under: Ubuntu 14.04.3 LTS\n\nlocale:\n[1] LC_CTYPE=en_US.UTF-8       LC_NUMERIC=C               LC_TIME=en_US.UTF-8\n[4] LC_COLLATE=en_US.UTF-8     LC_MONETARY=en_US.UTF-8    LC_MESSAGES=en_US.UTF-8\n[7] LC_PAPER=en_US.UTF-8       LC_NAME=C                  LC_ADDRESS=C\n[10] LC_TELEPHONE=C             LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base\n\nloaded via a namespace (and not attached):\n[1] tools_3.2.3     packrat_0.4.9-1\nMany times, there may be some issues with your data and the way it is formatted. In that case, you may want to share that data with someone else. However, you may not need to share the whole dataset; looking at a subset of your 50,000 row, 10,000 column dataframe may be TMI (too much information)! You can take an object you have in memory such as dataframe (if you don’t know what this means yet, we will get to it!) and save it to a file. In our example we will use the dput() function on the iris dataframe which is an example dataset that is installed in R:\ndput(head(iris)) # iris is an example data.frame that comes with R\n                 # the `head()` function just takes the first 6 lines of the iris dataset\nThis generates some output (below) which you will be better able to interpret after covering the other R lessons. This info would be helpful in understanding how the data is formatted and possibly revealing problematic issues.\nstructure(list(Sepal.Length = c(5.1, 4.9, 4.7, 4.6, 5, 5.4),\n    Sepal.Width = c(3.5, 3, 3.2, 3.1, 3.6, 3.9), Petal.Length = c(1.4,\n    1.4, 1.3, 1.5, 1.4, 1.7), Petal.Width = c(0.2, 0.2, 0.2,\n    0.2, 0.2, 0.4), Species = structure(c(1L, 1L, 1L, 1L, 1L,\n    1L), .Label = c(\"setosa\", \"versicolor\", \"virginica\"), class = \"factor\")), .Names = c(\"Sepal.Length\",\n\"Sepal.Width\", \"Petal.Length\", \"Petal.Width\", \"Species\"), row.names = c(NA,\n6L), class = \"data.frame\")\nAlternatively, you can also save objects in R memory to a file by specifying the name of the object, in this case the iris data frame, and passing a filename to the file= argument.\n\nsaveRDS(iris, file=\"iris.rds\") # By convention, we use the .rds file extension"
  },
  {
    "objectID": "r_lesson/06-r-help.html#final-faqs-on-r",
    "href": "r_lesson/06-r-help.html#final-faqs-on-r",
    "title": "Getting help with R",
    "section": "Final FAQs on R",
    "text": "Final FAQs on R\nFinally, here are a few pieces of introductory R knowledge that are too good to pass up. While we won’t return to them in this course, we put them here because they come up commonly:\nDo I need to click Run every time I want to run a script?\n\nNo. In fact, the most common shortcut key allows you to run a command (or any lines of the script that are highlighted):\n\nWindows execution shortcut: Ctrl+Enter\nMac execution shortcut: Cmd(⌘)+Enter\n\nTo see a complete list of shortcuts, click on the Tools menu and select Keyboard Shortcuts Help\n\nWhat’s with the brackets in R console output?\n\nR returns an index with your result. When your result contains multiple values, the number tells you what ordinal number begins the line, for example:\n\n\n1:101 # generates the sequence of numbers from 1 to 101\n\n  [1]   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17  18\n [19]  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35  36\n [37]  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53  54\n [55]  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71  72\n [73]  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89  90\n [91]  91  92  93  94  95  96  97  98  99 100 101\n\n\nIn the output above, [81] indicates that the first value on that line is the 81st item in your result\nCan I run my R script without RStudio?\n\nYes, remember - RStudio is running R. You get to use lots of the enhancements RStudio provides, but R works independent of RStudio. See these tips for running your commands at the command line\n\nWhere else can I learn about RStudio?\n\nCheck out the Help menu, especially “Cheatsheets” section\n\n\n\nR provides thousands of functions for analyzing data, and provides several way to get help\nUsing R will mean searching for online help, and there are tips and resources on how to search effectively"
  },
  {
    "objectID": "r_lesson/04-dplyr.html",
    "href": "r_lesson/04-dplyr.html",
    "title": "Data Wrangling and Analyses with Tidyverse",
    "section": "",
    "text": "Objectives\n\n\n\n\nDescribe what the dplyr package in R is used for.\nApply common dplyr functions to manipulate data in R.\nEmploy the pipe operator to link together a sequence of functions.\nEmploy the mutate() function to apply other chosen functions to existing columns and create new columns of data.\nEmploy the ‘split-apply-combine’ concept to split the data into groups, apply analysis to each group, and combine the results.\nBracket subsetting is handy, but it can be cumbersome and difficult to read, especially for complicated operations.\nLuckily, the dplyr package provides a number of very useful functions for manipulating data frames in a way that will reduce repetition, reduce the probability of making errors, and probably even save you some typing. As an added bonus, you might even find the dplyr grammar easier to read.\nHere we’re going to cover some of the most commonly used functions as well as using pipes (%&gt;%) to combine them:\nPackages in R are sets of additional functions that let you do more stuff in R. The functions we’ve been using, like str(), come built into R; packages give you access to more functions. You need to install a package and then load it to be able to use it.\ninstall.packages(\"dplyr\") ## installs dplyr package\ninstall.packages(\"tidyr\") ## installs tidyr package\ninstall.packages(\"ggplot2\") ## installs ggplot2 package\ninstall.packages(\"readr\") ## install readr package\nYou only need to install a package once per computer, but you need to load it every time you open a new R session and want to use that package.\nlibrary(\"dplyr\")          ## loads in dplyr package to use\nlibrary(\"tidyr\")          ## loads in tidyr package to use\nlibrary(\"ggplot2\")          ## loads in ggplot2 package to use\nlibrary(\"readr\")          ## load in readr package to use\nYou only need to install a package once per computer, but you need to load it with the library() function every time you open a new R session and want to use that package."
  },
  {
    "objectID": "r_lesson/04-dplyr.html#what-is-dplyr",
    "href": "r_lesson/04-dplyr.html#what-is-dplyr",
    "title": "Data Wrangling and Analyses with Tidyverse",
    "section": "What is dplyr?",
    "text": "What is dplyr?\nThe package dplyr provides easy tools for the most common data manipulation tasks. This package is also included in the tidyverse package, which is a collection of eight different core packages (dplyr, ggplot2, tibble, tidyr, readr, purrr, stringr, and forcats) and many others that have been added over the years. It is built to work directly with data frames."
  },
  {
    "objectID": "r_lesson/04-dplyr.html#taking-a-quick-look-at-data-frames",
    "href": "r_lesson/04-dplyr.html#taking-a-quick-look-at-data-frames",
    "title": "Data Wrangling and Analyses with Tidyverse",
    "section": "Taking a quick look at data frames",
    "text": "Taking a quick look at data frames\nSimilar to str(), which comes built into R, glimpse() is a dplyr function that (as the name suggests) gives a glimpse of the data frame.\n\n\nRows: 801\nColumns: 29\n$ sample_id     &lt;chr&gt; \"SRR2584863\", \"SRR2584863\", \"SRR2584863\", \"SRR2584863\", …\n$ CHROM         &lt;chr&gt; \"CP000819.1\", \"CP000819.1\", \"CP000819.1\", \"CP000819.1\", …\n$ POS           &lt;dbl&gt; 9972, 263235, 281923, 433359, 473901, 648692, 1331794, 1…\n$ ID            &lt;lgl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, …\n$ REF           &lt;chr&gt; \"T\", \"G\", \"G\", \"CTTTTTTT\", \"CCGC\", \"C\", \"C\", \"G\", \"ACAGC…\n$ ALT           &lt;chr&gt; \"G\", \"T\", \"T\", \"CTTTTTTTT\", \"CCGCGC\", \"T\", \"A\", \"A\", \"AC…\n$ QUAL          &lt;dbl&gt; 91.0000, 85.0000, 217.0000, 64.0000, 228.0000, 210.0000,…\n$ FILTER        &lt;lgl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, …\n$ INDEL         &lt;lgl&gt; FALSE, FALSE, FALSE, TRUE, TRUE, FALSE, FALSE, FALSE, TR…\n$ IDV           &lt;dbl&gt; NA, NA, NA, 12, 9, NA, NA, NA, 2, 7, NA, NA, NA, NA, NA,…\n$ IMF           &lt;dbl&gt; NA, NA, NA, 1.000000, 0.900000, NA, NA, NA, 0.666667, 1.…\n$ DP            &lt;dbl&gt; 4, 6, 10, 12, 10, 10, 8, 11, 3, 7, 9, 20, 12, 19, 15, 10…\n$ VDB           &lt;dbl&gt; 0.0257451, 0.0961330, 0.7740830, 0.4777040, 0.6595050, 0…\n$ RPB           &lt;dbl&gt; NA, 1.000000, NA, NA, NA, NA, NA, NA, NA, NA, 0.900802, …\n$ MQB           &lt;dbl&gt; NA, 1.0000000, NA, NA, NA, NA, NA, NA, NA, NA, 0.1501340…\n$ BQB           &lt;dbl&gt; NA, 1.000000, NA, NA, NA, NA, NA, NA, NA, NA, 0.750668, …\n$ MQSB          &lt;dbl&gt; NA, NA, 0.974597, 1.000000, 0.916482, 0.916482, 0.900802…\n$ SGB           &lt;dbl&gt; -0.556411, -0.590765, -0.662043, -0.676189, -0.662043, -…\n$ MQ0F          &lt;dbl&gt; 0.000000, 0.166667, 0.000000, 0.000000, 0.000000, 0.0000…\n$ ICB           &lt;lgl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, …\n$ HOB           &lt;lgl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, …\n$ AC            &lt;dbl&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,…\n$ AN            &lt;dbl&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,…\n$ DP4           &lt;chr&gt; \"0,0,0,4\", \"0,1,0,5\", \"0,0,4,5\", \"0,1,3,8\", \"1,0,2,7\", \"…\n$ MQ            &lt;dbl&gt; 60, 33, 60, 60, 60, 60, 60, 60, 60, 60, 25, 60, 10, 60, …\n$ Indiv         &lt;chr&gt; \"/home/dcuser/dc_workshop/results/bam/SRR2584863.aligned…\n$ gt_PL         &lt;dbl&gt; 1210, 1120, 2470, 910, 2550, 2400, 2080, 2550, 11128, 19…\n$ gt_GT         &lt;dbl&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,…\n$ gt_GT_alleles &lt;chr&gt; \"G\", \"T\", \"T\", \"CTTTTTTTT\", \"CCGCGC\", \"T\", \"A\", \"A\", \"AC…\n\n\nIn the above output, we can already gather some information about variants, such as the number of rows and columns, column names, type of vector in the columns, and the first few entries of each column. Although what we see is similar to outputs of str(), this method gives a cleaner visual output."
  },
  {
    "objectID": "r_lesson/04-dplyr.html#select",
    "href": "r_lesson/04-dplyr.html#select",
    "title": "Data Wrangling and Analyses with Tidyverse",
    "section": "select()",
    "text": "select()\nTo select columns of a data frame, use select(). The first argument to this function is the data frame (variants), and the subsequent arguments are the columns to keep.\n\nselect(variants, sample_id, REF, ALT, DP)\n\n# A tibble: 801 × 4\n   sample_id  REF                              ALT                            DP\n   &lt;chr&gt;      &lt;chr&gt;                            &lt;chr&gt;                       &lt;dbl&gt;\n 1 SRR2584863 T                                G                               4\n 2 SRR2584863 G                                T                               6\n 3 SRR2584863 G                                T                              10\n 4 SRR2584863 CTTTTTTT                         CTTTTTTTT                      12\n 5 SRR2584863 CCGC                             CCGCGC                         10\n 6 SRR2584863 C                                T                              10\n 7 SRR2584863 C                                A                               8\n 8 SRR2584863 G                                A                              11\n 9 SRR2584863 ACAGCCAGCCAGCCAGCCAGCCAGCCAGCCAG ACAGCCAGCCAGCCAGCCAGCCAGCC…     3\n10 SRR2584863 AT                               ATT                             7\n# ℹ 791 more rows\n\n\nTo select all columns except certain ones, put a “-” in front of the variable to exclude it.\n\nselect(variants, -CHROM)\n\n# A tibble: 801 × 28\n   sample_id      POS ID    REF      ALT    QUAL FILTER INDEL   IDV    IMF    DP\n   &lt;chr&gt;        &lt;dbl&gt; &lt;lgl&gt; &lt;chr&gt;    &lt;chr&gt; &lt;dbl&gt; &lt;lgl&gt;  &lt;lgl&gt; &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt;\n 1 SRR2584863    9972 NA    T        G        91 NA     FALSE    NA NA         4\n 2 SRR2584863  263235 NA    G        T        85 NA     FALSE    NA NA         6\n 3 SRR2584863  281923 NA    G        T       217 NA     FALSE    NA NA        10\n 4 SRR2584863  433359 NA    CTTTTTTT CTTT…    64 NA     TRUE     12  1        12\n 5 SRR2584863  473901 NA    CCGC     CCGC…   228 NA     TRUE      9  0.9      10\n 6 SRR2584863  648692 NA    C        T       210 NA     FALSE    NA NA        10\n 7 SRR2584863 1331794 NA    C        A       178 NA     FALSE    NA NA         8\n 8 SRR2584863 1733343 NA    G        A       225 NA     FALSE    NA NA        11\n 9 SRR2584863 2103887 NA    ACAGCCA… ACAG…    56 NA     TRUE      2  0.667     3\n10 SRR2584863 2333538 NA    AT       ATT     167 NA     TRUE      7  1         7\n# ℹ 791 more rows\n# ℹ 17 more variables: VDB &lt;dbl&gt;, RPB &lt;dbl&gt;, MQB &lt;dbl&gt;, BQB &lt;dbl&gt;, MQSB &lt;dbl&gt;,\n#   SGB &lt;dbl&gt;, MQ0F &lt;dbl&gt;, ICB &lt;lgl&gt;, HOB &lt;lgl&gt;, AC &lt;dbl&gt;, AN &lt;dbl&gt;, DP4 &lt;chr&gt;,\n#   MQ &lt;dbl&gt;, Indiv &lt;chr&gt;, gt_PL &lt;dbl&gt;, gt_GT &lt;dbl&gt;, gt_GT_alleles &lt;chr&gt;\n\n\ndplyr also provides useful functions to select columns based on their names. For instance, ends_with() allows you to select columns that ends with specific letters. For instance, if you wanted to select columns that end with the letter “B”:\n\nselect(variants, ends_with(\"B\"))\n\n# A tibble: 801 × 8\n      VDB   RPB   MQB   BQB   MQSB    SGB ICB   HOB  \n    &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt; &lt;lgl&gt; &lt;lgl&gt;\n 1 0.0257    NA    NA    NA NA     -0.556 NA    NA   \n 2 0.0961     1     1     1 NA     -0.591 NA    NA   \n 3 0.774     NA    NA    NA  0.975 -0.662 NA    NA   \n 4 0.478     NA    NA    NA  1     -0.676 NA    NA   \n 5 0.660     NA    NA    NA  0.916 -0.662 NA    NA   \n 6 0.268     NA    NA    NA  0.916 -0.670 NA    NA   \n 7 0.624     NA    NA    NA  0.901 -0.651 NA    NA   \n 8 0.992     NA    NA    NA  1.01  -0.670 NA    NA   \n 9 0.902     NA    NA    NA  1     -0.454 NA    NA   \n10 0.568     NA    NA    NA  1.01  -0.617 NA    NA   \n# ℹ 791 more rows\n\n\n\n\n\n\n\n\nTip\n\n\n\nCheck out the help documentation for select() and see what other helper functions are available.\n\n\n\nThe pipe %&gt;%\nWe can make our task easier by using a special operator called the pipe. Pipes let you take the output of one function and send it directly to the next, which is useful when you need to do many things to the same data set. This helps you avoid messy and hard to read nested expressions, or needing to create many intermediate objects.\nPipes in R look like %&gt;% and are made available via the magrittr package, which is installed as part of dplyr. If you use RStudio, you can type the pipe with Ctrl + Shift + M if you’re using a PC, or Cmd + Shift + M if you’re using a Mac.\nThe first required argument of most dplyr functions is the data frame you will be performing the function on. Therefore, an expression using the pipe will usually start with a data frame. So let’s try rewriting our select statement to use the pipe.\n\nvariants %&gt;% \n  select(sample_id, REF, ALT, DP)\n\n# A tibble: 801 × 4\n   sample_id  REF                              ALT                            DP\n   &lt;chr&gt;      &lt;chr&gt;                            &lt;chr&gt;                       &lt;dbl&gt;\n 1 SRR2584863 T                                G                               4\n 2 SRR2584863 G                                T                               6\n 3 SRR2584863 G                                T                              10\n 4 SRR2584863 CTTTTTTT                         CTTTTTTTT                      12\n 5 SRR2584863 CCGC                             CCGCGC                         10\n 6 SRR2584863 C                                T                              10\n 7 SRR2584863 C                                A                               8\n 8 SRR2584863 G                                A                              11\n 9 SRR2584863 ACAGCCAGCCAGCCAGCCAGCCAGCCAGCCAG ACAGCCAGCCAGCCAGCCAGCCAGCC…     3\n10 SRR2584863 AT                               ATT                             7\n# ℹ 791 more rows\n\n\nNotice that when you use the pipe RStudio will be able to helpfully autocomplete column names for you, which is a good way to reduce typing and avoid errors.\n\n\n\n\n\n\nExercise\n\n\n\nCreate a table that contains all the columns with the letter “i” and column “POS”, without columns “Indiv” and “FILTER”. Hint: look at for a function called contains(), which can be found in the help documentation for ends with we just covered (?ends_with). Note that contains() is not case sensistive.\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\n# First, we select \"POS\" and all columns with letter \"i\". This will contain columns Indiv and FILTER. \nvariants_subset &lt;- select(variants, POS, contains(\"i\"))\n# Next, we remove columns Indiv and FILTER\nvariants_result &lt;- select(variants_subset, -Indiv, -FILTER)\nvariants_result\n\n# A tibble: 801 × 7\n       POS sample_id  ID    INDEL   IDV    IMF ICB  \n     &lt;dbl&gt; &lt;chr&gt;      &lt;lgl&gt; &lt;lgl&gt; &lt;dbl&gt;  &lt;dbl&gt; &lt;lgl&gt;\n 1    9972 SRR2584863 NA    FALSE    NA NA     NA   \n 2  263235 SRR2584863 NA    FALSE    NA NA     NA   \n 3  281923 SRR2584863 NA    FALSE    NA NA     NA   \n 4  433359 SRR2584863 NA    TRUE     12  1     NA   \n 5  473901 SRR2584863 NA    TRUE      9  0.9   NA   \n 6  648692 SRR2584863 NA    FALSE    NA NA     NA   \n 7 1331794 SRR2584863 NA    FALSE    NA NA     NA   \n 8 1733343 SRR2584863 NA    FALSE    NA NA     NA   \n 9 2103887 SRR2584863 NA    TRUE      2  0.667 NA   \n10 2333538 SRR2584863 NA    TRUE      7  1     NA   \n# ℹ 791 more rows\n\n\n\n\n\nWe can also get to variants_result in one line of code:\n\n\n\n\n\n\nAlternative solution\n\n\n\n\n\n\nvariants_result &lt;- select(variants, POS, contains(\"i\"), -Indiv, -FILTER)\nvariants_result\n\n# A tibble: 801 × 7\n       POS sample_id  ID    INDEL   IDV    IMF ICB  \n     &lt;dbl&gt; &lt;chr&gt;      &lt;lgl&gt; &lt;lgl&gt; &lt;dbl&gt;  &lt;dbl&gt; &lt;lgl&gt;\n 1    9972 SRR2584863 NA    FALSE    NA NA     NA   \n 2  263235 SRR2584863 NA    FALSE    NA NA     NA   \n 3  281923 SRR2584863 NA    FALSE    NA NA     NA   \n 4  433359 SRR2584863 NA    TRUE     12  1     NA   \n 5  473901 SRR2584863 NA    TRUE      9  0.9   NA   \n 6  648692 SRR2584863 NA    FALSE    NA NA     NA   \n 7 1331794 SRR2584863 NA    FALSE    NA NA     NA   \n 8 1733343 SRR2584863 NA    FALSE    NA NA     NA   \n 9 2103887 SRR2584863 NA    TRUE      2  0.667 NA   \n10 2333538 SRR2584863 NA    TRUE      7  1     NA   \n# ℹ 791 more rows"
  },
  {
    "objectID": "r_lesson/04-dplyr.html#filter",
    "href": "r_lesson/04-dplyr.html#filter",
    "title": "Data Wrangling and Analyses with Tidyverse",
    "section": "filter()",
    "text": "filter()\nselect() lets you choose columns. To choose rows, use filter():\n\nvariants %&gt;% \n  filter(sample_id == \"SRR2584863\")\n\n# A tibble: 25 × 29\n   sample_id  CHROM        POS ID    REF   ALT    QUAL FILTER INDEL   IDV    IMF\n   &lt;chr&gt;      &lt;chr&gt;      &lt;dbl&gt; &lt;lgl&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;lgl&gt;  &lt;lgl&gt; &lt;dbl&gt;  &lt;dbl&gt;\n 1 SRR2584863 CP000819… 9.97e3 NA    T     G        91 NA     FALSE    NA NA    \n 2 SRR2584863 CP000819… 2.63e5 NA    G     T        85 NA     FALSE    NA NA    \n 3 SRR2584863 CP000819… 2.82e5 NA    G     T       217 NA     FALSE    NA NA    \n 4 SRR2584863 CP000819… 4.33e5 NA    CTTT… CTTT…    64 NA     TRUE     12  1    \n 5 SRR2584863 CP000819… 4.74e5 NA    CCGC  CCGC…   228 NA     TRUE      9  0.9  \n 6 SRR2584863 CP000819… 6.49e5 NA    C     T       210 NA     FALSE    NA NA    \n 7 SRR2584863 CP000819… 1.33e6 NA    C     A       178 NA     FALSE    NA NA    \n 8 SRR2584863 CP000819… 1.73e6 NA    G     A       225 NA     FALSE    NA NA    \n 9 SRR2584863 CP000819… 2.10e6 NA    ACAG… ACAG…    56 NA     TRUE      2  0.667\n10 SRR2584863 CP000819… 2.33e6 NA    AT    ATT     167 NA     TRUE      7  1    \n# ℹ 15 more rows\n# ℹ 18 more variables: DP &lt;dbl&gt;, VDB &lt;dbl&gt;, RPB &lt;dbl&gt;, MQB &lt;dbl&gt;, BQB &lt;dbl&gt;,\n#   MQSB &lt;dbl&gt;, SGB &lt;dbl&gt;, MQ0F &lt;dbl&gt;, ICB &lt;lgl&gt;, HOB &lt;lgl&gt;, AC &lt;dbl&gt;,\n#   AN &lt;dbl&gt;, DP4 &lt;chr&gt;, MQ &lt;dbl&gt;, Indiv &lt;chr&gt;, gt_PL &lt;dbl&gt;, gt_GT &lt;dbl&gt;,\n#   gt_GT_alleles &lt;chr&gt;\n\n\nfilter() will keep all the rows that match the conditions that are provided. Here are a few examples:\n\n# rows for which the reference genome has T or G\nvariants %&gt;% \n  filter(REF %in% c(\"T\", \"G\"))\n\n# A tibble: 340 × 29\n   sample_id CHROM    POS ID    REF   ALT    QUAL FILTER INDEL   IDV   IMF    DP\n   &lt;chr&gt;     &lt;chr&gt;  &lt;dbl&gt; &lt;lgl&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;lgl&gt;  &lt;lgl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n 1 SRR25848… CP00… 9.97e3 NA    T     G      91   NA     FALSE    NA    NA     4\n 2 SRR25848… CP00… 2.63e5 NA    G     T      85   NA     FALSE    NA    NA     6\n 3 SRR25848… CP00… 2.82e5 NA    G     T     217   NA     FALSE    NA    NA    10\n 4 SRR25848… CP00… 1.73e6 NA    G     A     225   NA     FALSE    NA    NA    11\n 5 SRR25848… CP00… 2.62e6 NA    G     T      31.9 NA     FALSE    NA    NA    12\n 6 SRR25848… CP00… 3.00e6 NA    G     A     225   NA     FALSE    NA    NA    15\n 7 SRR25848… CP00… 3.91e6 NA    G     T     225   NA     FALSE    NA    NA    10\n 8 SRR25848… CP00… 9.97e3 NA    T     G     214   NA     FALSE    NA    NA    10\n 9 SRR25848… CP00… 1.06e4 NA    G     A     225   NA     FALSE    NA    NA    11\n10 SRR25848… CP00… 6.40e4 NA    G     A     225   NA     FALSE    NA    NA    18\n# ℹ 330 more rows\n# ℹ 17 more variables: VDB &lt;dbl&gt;, RPB &lt;dbl&gt;, MQB &lt;dbl&gt;, BQB &lt;dbl&gt;, MQSB &lt;dbl&gt;,\n#   SGB &lt;dbl&gt;, MQ0F &lt;dbl&gt;, ICB &lt;lgl&gt;, HOB &lt;lgl&gt;, AC &lt;dbl&gt;, AN &lt;dbl&gt;, DP4 &lt;chr&gt;,\n#   MQ &lt;dbl&gt;, Indiv &lt;chr&gt;, gt_PL &lt;dbl&gt;, gt_GT &lt;dbl&gt;, gt_GT_alleles &lt;chr&gt;\n\n# rows that have TRUE in the column INDEL\nvariants %&gt;% \n  filter(INDEL)\n\n# A tibble: 101 × 29\n   sample_id CHROM    POS ID    REF   ALT    QUAL FILTER INDEL   IDV   IMF    DP\n   &lt;chr&gt;     &lt;chr&gt;  &lt;dbl&gt; &lt;lgl&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;lgl&gt;  &lt;lgl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n 1 SRR25848… CP00… 4.33e5 NA    CTTT… CTTT…  64   NA     TRUE     12 1        12\n 2 SRR25848… CP00… 4.74e5 NA    CCGC  CCGC… 228   NA     TRUE      9 0.9      10\n 3 SRR25848… CP00… 2.10e6 NA    ACAG… ACAG…  56   NA     TRUE      2 0.667     3\n 4 SRR25848… CP00… 2.33e6 NA    AT    ATT   167   NA     TRUE      7 1         7\n 5 SRR25848… CP00… 3.90e6 NA    A     AC     43.4 NA     TRUE      2 1         2\n 6 SRR25848… CP00… 4.43e6 NA    TGG   T     228   NA     TRUE     10 1        10\n 7 SRR25848… CP00… 1.48e5 NA    AGGGG AGGG… 122   NA     TRUE      8 1         8\n 8 SRR25848… CP00… 1.58e5 NA    GTTT… GTTT…  19.5 NA     TRUE      6 1         6\n 9 SRR25848… CP00… 1.73e5 NA    CAA   CA    180   NA     TRUE     11 1        11\n10 SRR25848… CP00… 1.75e5 NA    GAA   GA    194   NA     TRUE     10 1        10\n# ℹ 91 more rows\n# ℹ 17 more variables: VDB &lt;dbl&gt;, RPB &lt;dbl&gt;, MQB &lt;dbl&gt;, BQB &lt;dbl&gt;, MQSB &lt;dbl&gt;,\n#   SGB &lt;dbl&gt;, MQ0F &lt;dbl&gt;, ICB &lt;lgl&gt;, HOB &lt;lgl&gt;, AC &lt;dbl&gt;, AN &lt;dbl&gt;, DP4 &lt;chr&gt;,\n#   MQ &lt;dbl&gt;, Indiv &lt;chr&gt;, gt_PL &lt;dbl&gt;, gt_GT &lt;dbl&gt;, gt_GT_alleles &lt;chr&gt;\n\n# rows that don't have missing data in the IDV column\nvariants %&gt;% \n  filter(!is.na(IDV))\n\n# A tibble: 101 × 29\n   sample_id CHROM    POS ID    REF   ALT    QUAL FILTER INDEL   IDV   IMF    DP\n   &lt;chr&gt;     &lt;chr&gt;  &lt;dbl&gt; &lt;lgl&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;lgl&gt;  &lt;lgl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n 1 SRR25848… CP00… 4.33e5 NA    CTTT… CTTT…  64   NA     TRUE     12 1        12\n 2 SRR25848… CP00… 4.74e5 NA    CCGC  CCGC… 228   NA     TRUE      9 0.9      10\n 3 SRR25848… CP00… 2.10e6 NA    ACAG… ACAG…  56   NA     TRUE      2 0.667     3\n 4 SRR25848… CP00… 2.33e6 NA    AT    ATT   167   NA     TRUE      7 1         7\n 5 SRR25848… CP00… 3.90e6 NA    A     AC     43.4 NA     TRUE      2 1         2\n 6 SRR25848… CP00… 4.43e6 NA    TGG   T     228   NA     TRUE     10 1        10\n 7 SRR25848… CP00… 1.48e5 NA    AGGGG AGGG… 122   NA     TRUE      8 1         8\n 8 SRR25848… CP00… 1.58e5 NA    GTTT… GTTT…  19.5 NA     TRUE      6 1         6\n 9 SRR25848… CP00… 1.73e5 NA    CAA   CA    180   NA     TRUE     11 1        11\n10 SRR25848… CP00… 1.75e5 NA    GAA   GA    194   NA     TRUE     10 1        10\n# ℹ 91 more rows\n# ℹ 17 more variables: VDB &lt;dbl&gt;, RPB &lt;dbl&gt;, MQB &lt;dbl&gt;, BQB &lt;dbl&gt;, MQSB &lt;dbl&gt;,\n#   SGB &lt;dbl&gt;, MQ0F &lt;dbl&gt;, ICB &lt;lgl&gt;, HOB &lt;lgl&gt;, AC &lt;dbl&gt;, AN &lt;dbl&gt;, DP4 &lt;chr&gt;,\n#   MQ &lt;dbl&gt;, Indiv &lt;chr&gt;, gt_PL &lt;dbl&gt;, gt_GT &lt;dbl&gt;, gt_GT_alleles &lt;chr&gt;\n\n\nWe have a column titled “QUAL”. This is a Phred-scaled confidence score that a polymorphism exists at this position given the sequencing data. Lower QUAL scores indicate low probability of a polymorphism existing at that site. filter() can be useful for selecting mutations that have a QUAL score above a certain threshold:\n\n# rows with QUAL values greater than or equal to 100\nvariants %&gt;% \n  filter(QUAL &gt;= 100)\n\n# A tibble: 666 × 29\n   sample_id CHROM    POS ID    REF   ALT    QUAL FILTER INDEL   IDV   IMF    DP\n   &lt;chr&gt;     &lt;chr&gt;  &lt;dbl&gt; &lt;lgl&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;lgl&gt;  &lt;lgl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n 1 SRR25848… CP00… 2.82e5 NA    G     T       217 NA     FALSE    NA  NA      10\n 2 SRR25848… CP00… 4.74e5 NA    CCGC  CCGC…   228 NA     TRUE      9   0.9    10\n 3 SRR25848… CP00… 6.49e5 NA    C     T       210 NA     FALSE    NA  NA      10\n 4 SRR25848… CP00… 1.33e6 NA    C     A       178 NA     FALSE    NA  NA       8\n 5 SRR25848… CP00… 1.73e6 NA    G     A       225 NA     FALSE    NA  NA      11\n 6 SRR25848… CP00… 2.33e6 NA    AT    ATT     167 NA     TRUE      7   1       7\n 7 SRR25848… CP00… 2.41e6 NA    A     C       104 NA     FALSE    NA  NA       9\n 8 SRR25848… CP00… 2.45e6 NA    A     C       225 NA     FALSE    NA  NA      20\n 9 SRR25848… CP00… 2.67e6 NA    A     T       225 NA     FALSE    NA  NA      19\n10 SRR25848… CP00… 3.00e6 NA    G     A       225 NA     FALSE    NA  NA      15\n# ℹ 656 more rows\n# ℹ 17 more variables: VDB &lt;dbl&gt;, RPB &lt;dbl&gt;, MQB &lt;dbl&gt;, BQB &lt;dbl&gt;, MQSB &lt;dbl&gt;,\n#   SGB &lt;dbl&gt;, MQ0F &lt;dbl&gt;, ICB &lt;lgl&gt;, HOB &lt;lgl&gt;, AC &lt;dbl&gt;, AN &lt;dbl&gt;, DP4 &lt;chr&gt;,\n#   MQ &lt;dbl&gt;, Indiv &lt;chr&gt;, gt_PL &lt;dbl&gt;, gt_GT &lt;dbl&gt;, gt_GT_alleles &lt;chr&gt;\n\n\nfilter() allows you to combine multiple conditions. You can separate them using a , as arguments to the function, they will be combined using the & (AND) logical operator. If you need to use the | (OR) logical operator, you can specify it explicitly:\n\n# this is equivalent to:\n#   filter(variants, sample_id == \"SRR2584863\" & QUAL &gt;= 100)\nvariants %&gt;% \n  filter(sample_id == \"SRR2584863\", QUAL &gt;= 100)\n\n# A tibble: 19 × 29\n   sample_id CHROM    POS ID    REF   ALT    QUAL FILTER INDEL   IDV   IMF    DP\n   &lt;chr&gt;     &lt;chr&gt;  &lt;dbl&gt; &lt;lgl&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;lgl&gt;  &lt;lgl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n 1 SRR25848… CP00… 2.82e5 NA    G     T       217 NA     FALSE    NA  NA      10\n 2 SRR25848… CP00… 4.74e5 NA    CCGC  CCGC…   228 NA     TRUE      9   0.9    10\n 3 SRR25848… CP00… 6.49e5 NA    C     T       210 NA     FALSE    NA  NA      10\n 4 SRR25848… CP00… 1.33e6 NA    C     A       178 NA     FALSE    NA  NA       8\n 5 SRR25848… CP00… 1.73e6 NA    G     A       225 NA     FALSE    NA  NA      11\n 6 SRR25848… CP00… 2.33e6 NA    AT    ATT     167 NA     TRUE      7   1       7\n 7 SRR25848… CP00… 2.41e6 NA    A     C       104 NA     FALSE    NA  NA       9\n 8 SRR25848… CP00… 2.45e6 NA    A     C       225 NA     FALSE    NA  NA      20\n 9 SRR25848… CP00… 2.67e6 NA    A     T       225 NA     FALSE    NA  NA      19\n10 SRR25848… CP00… 3.00e6 NA    G     A       225 NA     FALSE    NA  NA      15\n11 SRR25848… CP00… 3.34e6 NA    A     C       211 NA     FALSE    NA  NA      10\n12 SRR25848… CP00… 3.40e6 NA    C     A       225 NA     FALSE    NA  NA      14\n13 SRR25848… CP00… 3.48e6 NA    A     G       200 NA     FALSE    NA  NA       9\n14 SRR25848… CP00… 3.49e6 NA    A     C       225 NA     FALSE    NA  NA      13\n15 SRR25848… CP00… 3.91e6 NA    G     T       225 NA     FALSE    NA  NA      10\n16 SRR25848… CP00… 4.10e6 NA    A     G       225 NA     FALSE    NA  NA      16\n17 SRR25848… CP00… 4.20e6 NA    A     C       225 NA     FALSE    NA  NA      11\n18 SRR25848… CP00… 4.43e6 NA    TGG   T       228 NA     TRUE     10   1      10\n19 SRR25848… CP00… 4.62e6 NA    A     C       185 NA     FALSE    NA  NA       9\n# ℹ 17 more variables: VDB &lt;dbl&gt;, RPB &lt;dbl&gt;, MQB &lt;dbl&gt;, BQB &lt;dbl&gt;, MQSB &lt;dbl&gt;,\n#   SGB &lt;dbl&gt;, MQ0F &lt;dbl&gt;, ICB &lt;lgl&gt;, HOB &lt;lgl&gt;, AC &lt;dbl&gt;, AN &lt;dbl&gt;, DP4 &lt;chr&gt;,\n#   MQ &lt;dbl&gt;, Indiv &lt;chr&gt;, gt_PL &lt;dbl&gt;, gt_GT &lt;dbl&gt;, gt_GT_alleles &lt;chr&gt;\n\n# using `|` logical operator\nvariants %&gt;% \n  filter(sample_id == \"SRR2584863\", (MQ &gt;= 50 | QUAL &gt;= 100))\n\n# A tibble: 23 × 29\n   sample_id  CHROM        POS ID    REF   ALT    QUAL FILTER INDEL   IDV    IMF\n   &lt;chr&gt;      &lt;chr&gt;      &lt;dbl&gt; &lt;lgl&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;lgl&gt;  &lt;lgl&gt; &lt;dbl&gt;  &lt;dbl&gt;\n 1 SRR2584863 CP000819… 9.97e3 NA    T     G        91 NA     FALSE    NA NA    \n 2 SRR2584863 CP000819… 2.82e5 NA    G     T       217 NA     FALSE    NA NA    \n 3 SRR2584863 CP000819… 4.33e5 NA    CTTT… CTTT…    64 NA     TRUE     12  1    \n 4 SRR2584863 CP000819… 4.74e5 NA    CCGC  CCGC…   228 NA     TRUE      9  0.9  \n 5 SRR2584863 CP000819… 6.49e5 NA    C     T       210 NA     FALSE    NA NA    \n 6 SRR2584863 CP000819… 1.33e6 NA    C     A       178 NA     FALSE    NA NA    \n 7 SRR2584863 CP000819… 1.73e6 NA    G     A       225 NA     FALSE    NA NA    \n 8 SRR2584863 CP000819… 2.10e6 NA    ACAG… ACAG…    56 NA     TRUE      2  0.667\n 9 SRR2584863 CP000819… 2.33e6 NA    AT    ATT     167 NA     TRUE      7  1    \n10 SRR2584863 CP000819… 2.41e6 NA    A     C       104 NA     FALSE    NA NA    \n# ℹ 13 more rows\n# ℹ 18 more variables: DP &lt;dbl&gt;, VDB &lt;dbl&gt;, RPB &lt;dbl&gt;, MQB &lt;dbl&gt;, BQB &lt;dbl&gt;,\n#   MQSB &lt;dbl&gt;, SGB &lt;dbl&gt;, MQ0F &lt;dbl&gt;, ICB &lt;lgl&gt;, HOB &lt;lgl&gt;, AC &lt;dbl&gt;,\n#   AN &lt;dbl&gt;, DP4 &lt;chr&gt;, MQ &lt;dbl&gt;, Indiv &lt;chr&gt;, gt_PL &lt;dbl&gt;, gt_GT &lt;dbl&gt;,\n#   gt_GT_alleles &lt;chr&gt;\n\n\n\n\n\n\n\n\nExercise\n\n\n\nSelect all the mutations that occurred between the positions 1e6 (one million) and 2e6 (inclusive) that have a QUAL greater than 200, and exclude INDEL mutations. Hint: to flip logical values such as TRUE to a FALSE, we can use to negation symbol “!”. (eg. !TRUE == FALSE).\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\nfilter(variants, POS &gt;= 1e6 & POS &lt;= 2e6, QUAL &gt; 200, !INDEL)\n\n# A tibble: 77 × 29\n   sample_id CHROM    POS ID    REF   ALT    QUAL FILTER INDEL   IDV   IMF    DP\n   &lt;chr&gt;     &lt;chr&gt;  &lt;dbl&gt; &lt;lgl&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;lgl&gt;  &lt;lgl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n 1 SRR25848… CP00… 1.73e6 NA    G     A       225 NA     FALSE    NA    NA    11\n 2 SRR25848… CP00… 1.00e6 NA    A     G       225 NA     FALSE    NA    NA    15\n 3 SRR25848… CP00… 1.02e6 NA    A     G       225 NA     FALSE    NA    NA    12\n 4 SRR25848… CP00… 1.06e6 NA    C     T       225 NA     FALSE    NA    NA    17\n 5 SRR25848… CP00… 1.06e6 NA    A     G       206 NA     FALSE    NA    NA     9\n 6 SRR25848… CP00… 1.07e6 NA    G     T       225 NA     FALSE    NA    NA    11\n 7 SRR25848… CP00… 1.07e6 NA    T     C       225 NA     FALSE    NA    NA    12\n 8 SRR25848… CP00… 1.10e6 NA    C     T       225 NA     FALSE    NA    NA    15\n 9 SRR25848… CP00… 1.11e6 NA    C     T       212 NA     FALSE    NA    NA     9\n10 SRR25848… CP00… 1.11e6 NA    A     G       225 NA     FALSE    NA    NA    14\n# ℹ 67 more rows\n# ℹ 17 more variables: VDB &lt;dbl&gt;, RPB &lt;dbl&gt;, MQB &lt;dbl&gt;, BQB &lt;dbl&gt;, MQSB &lt;dbl&gt;,\n#   SGB &lt;dbl&gt;, MQ0F &lt;dbl&gt;, ICB &lt;lgl&gt;, HOB &lt;lgl&gt;, AC &lt;dbl&gt;, AN &lt;dbl&gt;, DP4 &lt;chr&gt;,\n#   MQ &lt;dbl&gt;, Indiv &lt;chr&gt;, gt_PL &lt;dbl&gt;, gt_GT &lt;dbl&gt;, gt_GT_alleles &lt;chr&gt;\n\n\n\n\n\n\n\nBecause of the pipe it’s easy to combine different actions like selecting and filtering without the need to create intermediate objects or write messy nested code.\n\nvariants %&gt;%\n  filter(sample_id == \"SRR2584863\") %&gt;%\n  select(REF, ALT, DP)\n\n# A tibble: 25 × 3\n   REF                              ALT                                       DP\n   &lt;chr&gt;                            &lt;chr&gt;                                  &lt;dbl&gt;\n 1 T                                G                                          4\n 2 G                                T                                          6\n 3 G                                T                                         10\n 4 CTTTTTTT                         CTTTTTTTT                                 12\n 5 CCGC                             CCGCGC                                    10\n 6 C                                T                                         10\n 7 C                                A                                          8\n 8 G                                A                                         11\n 9 ACAGCCAGCCAGCCAGCCAGCCAGCCAGCCAG ACAGCCAGCCAGCCAGCCAGCCAGCCAGCCAGCCAGC…     3\n10 AT                               ATT                                        7\n# ℹ 15 more rows\n\n\nIn the above code, we use the pipe to send the variants data set first through filter(), to keep rows where sample_id matches a particular sample, and then through select() to keep only the REF, ALT, and DP columns. Since %&gt;% takes the object on its left and passes it as the first argument to the function on its right, we don’t need to explicitly include the data frame as an argument to the filter() and select() functions any more.\nSome may find it helpful to read the pipe like the word “then”. For instance, in the above example, we took the data frame variants, then we filtered for rows where sample_id was SRR2584863, then we selected the REF, ALT, and DP columns, then we showed only the first six rows. The dplyr functions by themselves are somewhat simple, but by combining them into linear workflows with the pipe, we can accomplish more complex manipulations of data frames.\nIf we want to create a new object with this smaller version of the data we can do so by assigning it a new name:\n\nSRR2584863_variants &lt;- variants %&gt;%\n  filter(sample_id == \"SRR2584863\") %&gt;%\n  select(REF, ALT, DP)\n\nThis new object includes all of the data from this sample. Let’s look at just the first six rows to confirm it’s what we want:\n\nhead(SRR2584863_variants)\n\n# A tibble: 6 × 3\n  REF      ALT          DP\n  &lt;chr&gt;    &lt;chr&gt;     &lt;dbl&gt;\n1 T        G             4\n2 G        T             6\n3 G        T            10\n4 CTTTTTTT CTTTTTTTT    12\n5 CCGC     CCGCGC       10\n6 C        T            10\n\n\nSimilar to head() and tail() functions, we can also look at the first or last six rows using tidyverse function slice(). Slice is a more versatile function that allows users to specify a range to view:\n\nSRR2584863_variants %&gt;% slice(1:6)\n\n# A tibble: 6 × 3\n  REF      ALT          DP\n  &lt;chr&gt;    &lt;chr&gt;     &lt;dbl&gt;\n1 T        G             4\n2 G        T             6\n3 G        T            10\n4 CTTTTTTT CTTTTTTTT    12\n5 CCGC     CCGCGC       10\n6 C        T            10\n\n\n\nSRR2584863_variants %&gt;% slice(10:25)\n\n# A tibble: 16 × 3\n   REF   ALT      DP\n   &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt;\n 1 AT    ATT       7\n 2 A     C         9\n 3 A     C        20\n 4 G     T        12\n 5 A     T        19\n 6 G     A        15\n 7 A     C        10\n 8 C     A        14\n 9 A     G         9\n10 A     C        13\n11 A     AC        2\n12 G     T        10\n13 A     G        16\n14 A     C        11\n15 TGG   T        10\n16 A     C         9\n\n\n\n\n\n\n\n\nExercise: Pipe and filter\n\n\n\nStarting with the variants data frame, use pipes to subset the data to include only observations from SRR2584863 sample, where the filtered depth (DP) is at least 10. Showing only 5th through 11th rows of columns REF, ALT, and POS.\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\n variants %&gt;%\n filter(sample_id == \"SRR2584863\" & DP &gt;= 10) %&gt;%\n slice(5:11) %&gt;%\n select(sample_id, DP, REF, ALT, POS)\n\n# A tibble: 7 × 5\n  sample_id     DP REF   ALT       POS\n  &lt;chr&gt;      &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt;   &lt;dbl&gt;\n1 SRR2584863    11 G     A     1733343\n2 SRR2584863    20 A     C     2446984\n3 SRR2584863    12 G     T     2618472\n4 SRR2584863    19 A     T     2665639\n5 SRR2584863    15 G     A     2999330\n6 SRR2584863    10 A     C     3339313\n7 SRR2584863    14 C     A     3401754"
  },
  {
    "objectID": "r_lesson/04-dplyr.html#mutate",
    "href": "r_lesson/04-dplyr.html#mutate",
    "title": "Data Wrangling and Analyses with Tidyverse",
    "section": "mutate()",
    "text": "mutate()\nFrequently you’ll want to create new columns based on the values in existing columns, for example to do unit conversions or find the ratio of values in two columns. For this we’ll use the dplyr function mutate().\nFor example, we can convert the polymorphism confidence value QUAL to a probability value according to the formula:\nProbability = 1- 10 ^ -(QUAL/10)\nWe can use mutate to add a column (POLPROB) to our variants data frame that shows the probability of a polymorphism at that site given the data.\n\nvariants %&gt;%\n  mutate(POLPROB = 1 - (10 ^ -(QUAL/10)))\n\n# A tibble: 801 × 30\n   sample_id  CHROM        POS ID    REF   ALT    QUAL FILTER INDEL   IDV    IMF\n   &lt;chr&gt;      &lt;chr&gt;      &lt;dbl&gt; &lt;lgl&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;lgl&gt;  &lt;lgl&gt; &lt;dbl&gt;  &lt;dbl&gt;\n 1 SRR2584863 CP000819… 9.97e3 NA    T     G        91 NA     FALSE    NA NA    \n 2 SRR2584863 CP000819… 2.63e5 NA    G     T        85 NA     FALSE    NA NA    \n 3 SRR2584863 CP000819… 2.82e5 NA    G     T       217 NA     FALSE    NA NA    \n 4 SRR2584863 CP000819… 4.33e5 NA    CTTT… CTTT…    64 NA     TRUE     12  1    \n 5 SRR2584863 CP000819… 4.74e5 NA    CCGC  CCGC…   228 NA     TRUE      9  0.9  \n 6 SRR2584863 CP000819… 6.49e5 NA    C     T       210 NA     FALSE    NA NA    \n 7 SRR2584863 CP000819… 1.33e6 NA    C     A       178 NA     FALSE    NA NA    \n 8 SRR2584863 CP000819… 1.73e6 NA    G     A       225 NA     FALSE    NA NA    \n 9 SRR2584863 CP000819… 2.10e6 NA    ACAG… ACAG…    56 NA     TRUE      2  0.667\n10 SRR2584863 CP000819… 2.33e6 NA    AT    ATT     167 NA     TRUE      7  1    \n# ℹ 791 more rows\n# ℹ 19 more variables: DP &lt;dbl&gt;, VDB &lt;dbl&gt;, RPB &lt;dbl&gt;, MQB &lt;dbl&gt;, BQB &lt;dbl&gt;,\n#   MQSB &lt;dbl&gt;, SGB &lt;dbl&gt;, MQ0F &lt;dbl&gt;, ICB &lt;lgl&gt;, HOB &lt;lgl&gt;, AC &lt;dbl&gt;,\n#   AN &lt;dbl&gt;, DP4 &lt;chr&gt;, MQ &lt;dbl&gt;, Indiv &lt;chr&gt;, gt_PL &lt;dbl&gt;, gt_GT &lt;dbl&gt;,\n#   gt_GT_alleles &lt;chr&gt;, POLPROB &lt;dbl&gt;\n\n\n\n\n\n\n\n\nExercise\n\n\n\nThere are a lot of columns in our data set, so let’s just look at the sample_id, POS, QUAL, and POLPROB columns for now. Add a line to the above code to only show those columns.\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\nvariants %&gt;%\n mutate(POLPROB = 1 - 10 ^ -(QUAL/10)) %&gt;%\n select(sample_id, POS, QUAL, POLPROB)\n\n# A tibble: 801 × 4\n   sample_id      POS  QUAL POLPROB\n   &lt;chr&gt;        &lt;dbl&gt; &lt;dbl&gt;   &lt;dbl&gt;\n 1 SRR2584863    9972    91    1.00\n 2 SRR2584863  263235    85    1.00\n 3 SRR2584863  281923   217    1   \n 4 SRR2584863  433359    64    1.00\n 5 SRR2584863  473901   228    1   \n 6 SRR2584863  648692   210    1   \n 7 SRR2584863 1331794   178    1   \n 8 SRR2584863 1733343   225    1   \n 9 SRR2584863 2103887    56    1.00\n10 SRR2584863 2333538   167    1   \n# ℹ 791 more rows"
  },
  {
    "objectID": "r_lesson/04-dplyr.html#group_by-and-summarize",
    "href": "r_lesson/04-dplyr.html#group_by-and-summarize",
    "title": "Data Wrangling and Analyses with Tidyverse",
    "section": "group_by() and summarize()",
    "text": "group_by() and summarize()\nMany data analysis tasks can be approached using the “split-apply-combine” paradigm: split the data into groups, apply some analysis to each group, and then combine the results. dplyr makes this very easy through the use of the group_by() function, which splits the data into groups.\n\nvariants %&gt;%\n  group_by(sample_id)\n\n# A tibble: 801 × 29\n# Groups:   sample_id [3]\n   sample_id  CHROM        POS ID    REF   ALT    QUAL FILTER INDEL   IDV    IMF\n   &lt;chr&gt;      &lt;chr&gt;      &lt;dbl&gt; &lt;lgl&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;lgl&gt;  &lt;lgl&gt; &lt;dbl&gt;  &lt;dbl&gt;\n 1 SRR2584863 CP000819… 9.97e3 NA    T     G        91 NA     FALSE    NA NA    \n 2 SRR2584863 CP000819… 2.63e5 NA    G     T        85 NA     FALSE    NA NA    \n 3 SRR2584863 CP000819… 2.82e5 NA    G     T       217 NA     FALSE    NA NA    \n 4 SRR2584863 CP000819… 4.33e5 NA    CTTT… CTTT…    64 NA     TRUE     12  1    \n 5 SRR2584863 CP000819… 4.74e5 NA    CCGC  CCGC…   228 NA     TRUE      9  0.9  \n 6 SRR2584863 CP000819… 6.49e5 NA    C     T       210 NA     FALSE    NA NA    \n 7 SRR2584863 CP000819… 1.33e6 NA    C     A       178 NA     FALSE    NA NA    \n 8 SRR2584863 CP000819… 1.73e6 NA    G     A       225 NA     FALSE    NA NA    \n 9 SRR2584863 CP000819… 2.10e6 NA    ACAG… ACAG…    56 NA     TRUE      2  0.667\n10 SRR2584863 CP000819… 2.33e6 NA    AT    ATT     167 NA     TRUE      7  1    \n# ℹ 791 more rows\n# ℹ 18 more variables: DP &lt;dbl&gt;, VDB &lt;dbl&gt;, RPB &lt;dbl&gt;, MQB &lt;dbl&gt;, BQB &lt;dbl&gt;,\n#   MQSB &lt;dbl&gt;, SGB &lt;dbl&gt;, MQ0F &lt;dbl&gt;, ICB &lt;lgl&gt;, HOB &lt;lgl&gt;, AC &lt;dbl&gt;,\n#   AN &lt;dbl&gt;, DP4 &lt;chr&gt;, MQ &lt;dbl&gt;, Indiv &lt;chr&gt;, gt_PL &lt;dbl&gt;, gt_GT &lt;dbl&gt;,\n#   gt_GT_alleles &lt;chr&gt;\n\n\nYou might notice that nothing appears to have changed. group_by() is often used together with other functions, like summarize(). When the data is grouped, summarize() can be used to collapse each group into a single-row summary. summarize() does this by applying an aggregating or summary function to each group.\nIt can be a bit tricky at first, but we can imagine physically splitting the data frame by groups and applying a certain function to summarize the data.\n\nknitr::include_graphics(\"fig/split_apply_combine.png\")\n\n1\nWe can also apply many other functions to individual columns to get other summary statistics. For example,we can use built-in functions like mean(), median(), min(), and max(). These are called “built-in functions” because they come with R and don’t require that you install any additional packages. By default, all R functions operating on vectors that contains missing data will return NA. It’s a way to make sure that users know they have missing data, and make a conscious decision on how to deal with it. When dealing with simple statistics like the mean, the easiest way to ignore NA (the missing data) is to use na.rm = TRUE (rm stands for remove).\nSo to view the mean filtered depth (DP) for each sample:\n\nvariants %&gt;%\n  group_by(sample_id) %&gt;%\n  summarize(mean_DP = mean(DP))\n\n# A tibble: 3 × 2\n  sample_id  mean_DP\n  &lt;chr&gt;        &lt;dbl&gt;\n1 SRR2584863    10.4\n2 SRR2584866    10.6\n3 SRR2589044     9.3\n\n\nThis will create a new column called mean_DP (note the similarity in syntax to mutate())\nWe can produce multiple summary columns in the same function call, by separating each with commas.\nSo to view the mean, median, maximum, and minimum filtered depth (DP) for each sample:\n\nvariants %&gt;%\n  group_by(sample_id) %&gt;%\n  summarize(\n    mean_DP = mean(DP),\n    median_DP = median(DP),\n    min_DP = min(DP),\n    max_DP = max(DP))\n\n# A tibble: 3 × 5\n  sample_id  mean_DP median_DP min_DP max_DP\n  &lt;chr&gt;        &lt;dbl&gt;     &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;\n1 SRR2584863    10.4      10        2     20\n2 SRR2584866    10.6      10        2     79\n3 SRR2589044     9.3       9.5      3     16\n\n\nWe could use group_by() and summarize() to find the number of mutations detected in each sample.\n\nvariants %&gt;%\n  group_by(sample_id) %&gt;%\n  summarize(n=n())\n\n# A tibble: 3 × 2\n  sample_id      n\n  &lt;chr&gt;      &lt;int&gt;\n1 SRR2584863    25\n2 SRR2584866   766\n3 SRR2589044    10"
  },
  {
    "objectID": "r_lesson/04-dplyr.html#count",
    "href": "r_lesson/04-dplyr.html#count",
    "title": "Data Wrangling and Analyses with Tidyverse",
    "section": "count()",
    "text": "count()\nSince counting or tallying values is a common use case for group_by(), an alternative function was created count():\n\nvariants %&gt;%\n  count(sample_id)\n\n# A tibble: 3 × 2\n  sample_id      n\n  &lt;chr&gt;      &lt;int&gt;\n1 SRR2584863    25\n2 SRR2584866   766\n3 SRR2589044    10\n\n\ncount() works similarly to the base R function we looked at in the last section table(), but it outputs the data as a tibble.\n\n\n\n\n\n\nExercise\n\n\n\n\nHow many mutations are INDELs?\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\nvariants %&gt;%\n  count(INDEL)\n\n# A tibble: 2 × 2\n  INDEL     n\n  &lt;lgl&gt; &lt;int&gt;\n1 FALSE   700\n2 TRUE    101"
  },
  {
    "objectID": "r_lesson/04-dplyr.html#reshaping-data-frames",
    "href": "r_lesson/04-dplyr.html#reshaping-data-frames",
    "title": "Data Wrangling and Analyses with Tidyverse",
    "section": "Reshaping data frames",
    "text": "Reshaping data frames\nIt can sometimes be useful to transform the “long” tidy format, into the wide format. This transformation can be done with the pivot_wider() function provided by the tidyr package (also part of the tidyverse).\npivot_wider() takes a data frame as the first argument, and two arguments: the column name that will become the columns and the column name that will become the cells in the wide data.\n\nvariants_wide &lt;- variants %&gt;%\n  group_by(sample_id, CHROM) %&gt;%\n  summarize(mean_DP = mean(DP)) %&gt;%\n  pivot_wider(names_from = sample_id, values_from = mean_DP)\n\n`summarise()` has grouped output by 'sample_id'. You can override using the\n`.groups` argument.\n\nvariants_wide\n\n# A tibble: 1 × 4\n  CHROM      SRR2584863 SRR2584866 SRR2589044\n  &lt;chr&gt;           &lt;dbl&gt;      &lt;dbl&gt;      &lt;dbl&gt;\n1 CP000819.1       10.4       10.6        9.3\n\n\nThe opposite operation of pivot_wider() is taken care by pivot_longer(). We specify the names of the new columns, and here add -CHROM as this column shouldn’t be affected by the reshaping:\n\nvariants_wide %&gt;%\n  pivot_longer(-CHROM, names_to = \"sample_id\", values_to = \"mean_DP\")\n\n# A tibble: 3 × 3\n  CHROM      sample_id  mean_DP\n  &lt;chr&gt;      &lt;chr&gt;        &lt;dbl&gt;\n1 CP000819.1 SRR2584863    10.4\n2 CP000819.1 SRR2584866    10.6\n3 CP000819.1 SRR2589044     9.3"
  },
  {
    "objectID": "r_lesson/04-dplyr.html#resources",
    "href": "r_lesson/04-dplyr.html#resources",
    "title": "Data Wrangling and Analyses with Tidyverse",
    "section": "Resources",
    "text": "Resources\n\nHandy dplyr cheatsheet\nMuch of this lesson was copied or adapted from Jeff Hollister’s materials\n\n\n\n\n\n\n\nKey points\n\n\n\n\nUse the dplyr package to manipulate data frames.\nUse glimpse() to quickly look at your data frame.\nUse select() to choose variables from a data frame.\nUse filter() to choose data based on values.\nUse mutate() to create new variables.\nUse group_by() and summarize() to work with subsets of data."
  },
  {
    "objectID": "r_lesson/04-dplyr.html#footnotes",
    "href": "r_lesson/04-dplyr.html#footnotes",
    "title": "Data Wrangling and Analyses with Tidyverse",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nThe figure was adapted from the Software Carpentry lesson, R for Reproducible Scientific Analysis↩︎"
  },
  {
    "objectID": "r_lesson/02-data-prelude.html",
    "href": "r_lesson/02-data-prelude.html",
    "title": "Introduction to the example dataset and file type",
    "section": "",
    "text": "Know what the example dataset represents\nKnow the concepts of how VCF files are generated"
  },
  {
    "objectID": "r_lesson/02-data-prelude.html#preface",
    "href": "r_lesson/02-data-prelude.html#preface",
    "title": "Introduction to the example dataset and file type",
    "section": "Preface",
    "text": "Preface\nThe Intro to R and RStudio for Genomics is a part of the Genomics Data Carpentry lessons. In this lesson we will learn the necessary skill sets for R and RStudio and apply them directly to a real next-generation sequencing (NGS) data in the variant calling format (VCF) file type. Previous Genomics Data Carpentry lessons teach learners how to generate a VCF file from FASTQ files downloaded from NCBI Sequence Read Archive (SRA), so we won’t cover that here. Instead, in this episode we will give a brief overview of the data and a what VCF file types are for those who wish to teach the Intro to R and RStudio for Genomics lesson independently of the Genomics Data Carpentry lessons.\nThis dataset was selected for several reasons, including:\n\nSimple, but iconic NGS-problem: Examine a population where we want to characterize changes in sequence a priori\nDataset publicly available - in this case through the NCBI SRA (http://www.ncbi.nlm.nih.gov/sra)"
  },
  {
    "objectID": "r_lesson/02-data-prelude.html#introduction-to-the-dataset",
    "href": "r_lesson/02-data-prelude.html#introduction-to-the-dataset",
    "title": "Introduction to the example dataset and file type",
    "section": "Introduction to the dataset",
    "text": "Introduction to the dataset\nMicrobes are ideal organisms for exploring ‘Long-term Evolution Experiments’ (LTEEs) - thousands of generations can be generated and stored in a way that would be virtually impossible for more complex eukaryotic systems. In Tenaillon et al 2016, 12 populations of Escherichia coli were propagated for more than 50,000 generations in a glucose-limited minimal medium. This medium was supplemented with citrate which E. coli cannot metabolize in the aerobic conditions of the experiment. Sequencing of the populations at regular time points reveals that spontaneous citrate-using mutants (Cit+) appeared in a population of E.coli (designated Ara-3) at around 31,000 generations. It should be noted that spontaneous Cit+ mutants are extraordinarily rare - inability to metabolize citrate is one of the defining characters of the E. coli species. Eventually, Cit+ mutants became the dominant population as the experimental growth medium contained a high concentration of citrate relative to glucose. Around the same time that this mutation emerged, another phenotype become prominent in the Ara-3 population. Many E. coli began to develop excessive numbers of mutations, meaning they became hypermutable.\nStrains from generation 0 to generation 50,000 were sequenced, including ones that were both Cit+ and Cit- and hypermutable in later generations.\nFor the purposes of this workshop we’re going to be working with 3 of the sequence reads from this experiment.\n\n\n\n\n\n\n\n\n\n\n\n\nSRA Run Number\nClone\nGeneration\nCit\nHypermutable\nRead Length\nSequencing Depth\n\n\n\n\nSRR2589044\nREL2181A\n5,000\nUnknown\nNone\n150\n60.2\n\n\nSRR2584863\nREL7179B\n15,000\nUnknown\nNone\n150\n88\n\n\nSRR2584866\nREL11365\n50,000\nCit+\nplus\n150\n138.3\n\n\n\nWe want to be able to look at differences in mutation rates between hypermutable and non-hypermutable strains. We also want to analyze the sequences to figure out what changes occurred in genomes to make the strains Cit+. Ultimately, we will use R to answer the questions:\n\nHow many base pair changes are there between the Cit+ and Cit- strains?\nWhat are the base pair changes between strains?"
  },
  {
    "objectID": "r_lesson/02-data-prelude.html#how-vcf-files-are-generated",
    "href": "r_lesson/02-data-prelude.html#how-vcf-files-are-generated",
    "title": "Introduction to the example dataset and file type",
    "section": "How VCF files are generated",
    "text": "How VCF files are generated\nPublicly accessible sequencing files in FASTQ formats can be downloaded from NCBI SRA. However, at FASTQ files contain unaligned sequences of varying quality, and requires clean up and alignment steps for variants to be called from the reference genome.\nFive steps are taken to transform FASTQ files to variant calls contained in VCF files and at each step, specialized non-R based bioinformatics tools that are used:"
  },
  {
    "objectID": "r_lesson/02-data-prelude.html#how-variant-calls-are-stored-in-vcf-files",
    "href": "r_lesson/02-data-prelude.html#how-variant-calls-are-stored-in-vcf-files",
    "title": "Introduction to the example dataset and file type",
    "section": "How variant calls are stored in VCF files",
    "text": "How variant calls are stored in VCF files\nVCF files contain variants that were called against a reference genome. These files are slightly more complicated than regular tables you can open using programs like Excel and contain two sections: header and records.\nBelow you will see the header (which describes the format), the time and date the file was created, the version of bcftools that was used, the command line parameters used, and some additional information:\n##fileformat=VCFv4.2\n##FILTER=&lt;ID=PASS,Description=\"All filters passed\"&gt;\n##bcftoolsVersion=1.8+htslib-1.8\n##bcftoolsCommand=mpileup -O b -o results/bcf/SRR2584866_raw.bcf -f data/ref_genome/ecoli_rel606.fasta results/bam/SRR2584866.aligned.sorted.bam\n##reference=file://data/ref_genome/ecoli_rel606.fasta\n##contig=&lt;ID=CP000819.1,length=4629812&gt;\n##ALT=&lt;ID=*,Description=\"Represents allele(s) other than observed.\"&gt;\n##INFO=&lt;ID=INDEL,Number=0,Type=Flag,Description=\"Indicates that the variant is an INDEL.\"&gt;\n##INFO=&lt;ID=IDV,Number=1,Type=Integer,Description=\"Maximum number of reads supporting an indel\"&gt;\n##INFO=&lt;ID=IMF,Number=1,Type=Float,Description=\"Maximum fraction of reads supporting an indel\"&gt;\n##INFO=&lt;ID=DP,Number=1,Type=Integer,Description=\"Raw read depth\"&gt;\n##INFO=&lt;ID=VDB,Number=1,Type=Float,Description=\"Variant Distance Bias for filtering splice-site artefacts in RNA-seq data (bigger is better)\",Version=\n##INFO=&lt;ID=RPB,Number=1,Type=Float,Description=\"Mann-Whitney U test of Read Position Bias (bigger is better)\"&gt;\n##INFO=&lt;ID=MQB,Number=1,Type=Float,Description=\"Mann-Whitney U test of Mapping Quality Bias (bigger is better)\"&gt;\n##INFO=&lt;ID=BQB,Number=1,Type=Float,Description=\"Mann-Whitney U test of Base Quality Bias (bigger is better)\"&gt;\n##INFO=&lt;ID=MQSB,Number=1,Type=Float,Description=\"Mann-Whitney U test of Mapping Quality vs Strand Bias (bigger is better)\"&gt;\n##INFO=&lt;ID=SGB,Number=1,Type=Float,Description=\"Segregation based metric.\"&gt;\n##INFO=&lt;ID=MQ0F,Number=1,Type=Float,Description=\"Fraction of MQ0 reads (smaller is better)\"&gt;\n##FORMAT=&lt;ID=PL,Number=G,Type=Integer,Description=\"List of Phred-scaled genotype likelihoods\"&gt;\n##FORMAT=&lt;ID=GT,Number=1,Type=String,Description=\"Genotype\"&gt;\n##INFO=&lt;ID=ICB,Number=1,Type=Float,Description=\"Inbreeding Coefficient Binomial test (bigger is better)\"&gt;\n##INFO=&lt;ID=HOB,Number=1,Type=Float,Description=\"Bias in the number of HOMs number (smaller is better)\"&gt;\n##INFO=&lt;ID=AC,Number=A,Type=Integer,Description=\"Allele count in genotypes for each ALT allele, in the same order as listed\"&gt;\n##INFO=&lt;ID=AN,Number=1,Type=Integer,Description=\"Total number of alleles in called genotypes\"&gt;\n##INFO=&lt;ID=DP4,Number=4,Type=Integer,Description=\"Number of high-quality ref-forward , ref-reverse, alt-forward and alt-reverse bases\"&gt;\n##INFO=&lt;ID=MQ,Number=1,Type=Integer,Description=\"Average mapping quality\"&gt;\n##bcftools_callVersion=1.8+htslib-1.8\n##bcftools_callCommand=call --ploidy 1 -m -v -o results/bcf/SRR2584866_variants.vcf results/bcf/SRR2584866_raw.bcf; Date=Tue Oct  9 18:48:10 2018\nFollowed by information on each of the variations observed:\n#CHROM  POS     ID      REF     ALT     QUAL    FILTER  INFO    FORMAT  results/bam/SRR2584866.aligned.sorted.bam\nCP000819.1      1521    .       C       T       207     .       DP=9;VDB=0.993024;SGB=-0.662043;MQSB=0.974597;MQ0F=0;AC=1;AN=1;DP4=0,0,4,5;MQ=60\nCP000819.1      1612    .       A       G       225     .       DP=13;VDB=0.52194;SGB=-0.676189;MQSB=0.950952;MQ0F=0;AC=1;AN=1;DP4=0,0,6,5;MQ=60\nCP000819.1      9092    .       A       G       225     .       DP=14;VDB=0.717543;SGB=-0.670168;MQSB=0.916482;MQ0F=0;AC=1;AN=1;DP4=0,0,7,3;MQ=60\nCP000819.1      9972    .       T       G       214     .       DP=10;VDB=0.022095;SGB=-0.670168;MQSB=1;MQ0F=0;AC=1;AN=1;DP4=0,0,2,8;MQ=60      GT:PL\nCP000819.1      10563   .       G       A       225     .       DP=11;VDB=0.958658;SGB=-0.670168;MQSB=0.952347;MQ0F=0;AC=1;AN=1;DP4=0,0,5,5;MQ=60\nCP000819.1      22257   .       C       T       127     .       DP=5;VDB=0.0765947;SGB=-0.590765;MQSB=1;MQ0F=0;AC=1;AN=1;DP4=0,0,2,3;MQ=60      GT:PL\nCP000819.1      38971   .       A       G       225     .       DP=14;VDB=0.872139;SGB=-0.680642;MQSB=1;MQ0F=0;AC=1;AN=1;DP4=0,0,4,8;MQ=60      GT:PL\nCP000819.1      42306   .       A       G       225     .       DP=15;VDB=0.969686;SGB=-0.686358;MQSB=1;MQ0F=0;AC=1;AN=1;DP4=0,0,5,9;MQ=60      GT:PL\nCP000819.1      45277   .       A       G       225     .       DP=15;VDB=0.470998;SGB=-0.680642;MQSB=0.95494;MQ0F=0;AC=1;AN=1;DP4=0,0,7,5;MQ=60\nCP000819.1      56613   .       C       G       183     .       DP=12;VDB=0.879703;SGB=-0.676189;MQSB=1;MQ0F=0;AC=1;AN=1;DP4=0,0,8,3;MQ=60      GT:PL\nCP000819.1      62118   .       A       G       225     .       DP=19;VDB=0.414981;SGB=-0.691153;MQSB=0.906029;MQ0F=0;AC=1;AN=1;DP4=0,0,8,10;MQ=59\nCP000819.1      64042   .       G       A       225     .       DP=18;VDB=0.451328;SGB=-0.689466;MQSB=1;MQ0F=0;AC=1;AN=1;DP4=0,0,7,9;MQ=60      GT:PL\nThe first few columns represent the information we have about a predicted variation.\n\n\n\n\n\n\n\ncolumn\ninfo\n\n\n\n\nCHROM\ncontig location where the variation occurs\n\n\nPOS\nposition within the contig where the variation occurs\n\n\nID\na . until we add annotation information\n\n\nREF\nreference genotype (forward strand)\n\n\nALT\nsample genotype (forward strand)\n\n\nQUAL\nPhred-scaled probability that the observed variant exists at this site (higher is better)\n\n\nFILTER\na . if no quality filters have been applied, PASS if a filter is passed, or the name of the filters this variant failed\n\n\n\nIn an ideal world, the information in the QUAL column would be all we needed to filter out bad variant calls. However, in reality we need to filter on multiple other metrics.\nThe last two columns contain the genotypes and can be tricky to decode.\n\n\n\n\n\n\n\ncolumn\ninfo\n\n\n\n\nFORMAT\nlists in order the metrics presented in the final column\n\n\nresults\nlists the values associated with those metrics in order\n\n\n\nFor our file, the metrics presented are GT:PL:GQ.\n\n\n\n\n\n\n\nmetric\ndefinition\n\n\n\n\nAD, DP\nthe depth per allele by sample and coverage\n\n\nGT\nthe genotype for the sample at this loci. For a diploid organism, the GT field indicates the two alleles carried by the sample, encoded by a 0 for the REF allele, 1 for the first ALT allele, 2 for the second ALT allele, etc. A 0/0 means homozygous reference, 0/1 is heterozygous, and 1/1 is homozygous for the alternate allele.\n\n\nPL\nthe likelihoods of the given genotypes\n\n\nGQ\nthe Phred-scaled confidence for the genotype\n\n\n\nFor more information on VCF files visit The Broad Institute’s VCF guide."
  },
  {
    "objectID": "r_lesson/02-data-prelude.html#references",
    "href": "r_lesson/02-data-prelude.html#references",
    "title": "Introduction to the example dataset and file type",
    "section": "References",
    "text": "References\nTenaillon O, Barrick JE, Ribeck N, Deatherage DE, Blanchard JL, Dasgupta A, Wu GC, Wielgoss S, Cruveiller S, Médigue C, Schneider D, Lenski RE. Tempo and mode of genome evolution in a 50,000-generation experiment (2016) Nature. 536(7615): 165–170. Paper, Supplemental materials Data on NCBI SRA: https://trace.ncbi.nlm.nih.gov/Traces/sra/?study=SRP064605 Data on EMBL-EBI ENA: https://www.ebi.ac.uk/ena/data/view/PRJNA295606\nThis episode was adapted from the Data Carpentry Genomic lessons:\n\nProject organization and management for Genomics\nData wrangling and processing for genomics\n\n\n\nThe dataset comes from a real world experiment in E. coli.\nPublicly available FASTQ files can be downloaded from NCBI SRA.\nSeveral steps are taken outside of R/RStudio to create VCF files from FASTQ files.\nVCF files store variant calls in a special format."
  },
  {
    "objectID": "r_lesson/00-introduction.html",
    "href": "r_lesson/00-introduction.html",
    "title": "Introduction to R and R Studio",
    "section": "",
    "text": "Understand the value of learning R\nNavigate RStudio\nDefine terms: object, function, argument, package, vector, data frame.\nUse help documentation in RStudio."
  },
  {
    "objectID": "r_lesson/00-introduction.html#learning-objectives",
    "href": "r_lesson/00-introduction.html#learning-objectives",
    "title": "Introduction to R and R Studio",
    "section": "",
    "text": "Understand the value of learning R\nNavigate RStudio\nDefine terms: object, function, argument, package, vector, data frame.\nUse help documentation in RStudio."
  },
  {
    "objectID": "r_lesson/00-introduction.html#why-learn-r",
    "href": "r_lesson/00-introduction.html#why-learn-r",
    "title": "Introduction to R and R Studio",
    "section": "Why learn R?",
    "text": "Why learn R?\n\nR is free, open-source, and cross-platform. Anyone can inspect the source code to see how R works. Because of this transparency, there is less chance for mistakes, and if you (or someone else) find some, you can report and fix bugs. Because R is open source and is supported by a large community of developers and users, there is a very large selection of third-party add-on packages which are freely available to extend R’s native capabilities.\nR code is great for reproducibility. Reproducibility is when someone else (including your future self) can obtain the same results from the same dataset when using the same analysis. R integrates with other tools to generate manuscripts from your code. If you collect more data, or fix a mistake in your dataset, the figures and the statistical tests in your manuscript are updated automatically.\nR relies on a series of written commands, not on remembering a succession of pointing and clicking. If you want to redo your analysis because you collected more data, you don’t have to remember which button you clicked in which order to obtain your results; you just have to run your script again.\nR is interdisciplinary and extensible With 10,000+ packages that can be installed to extend its capabilities, R provides a framework that allows you to combine statistical approaches from many scientific disciplines to best suit the analytical framework you need to analyze your data. For instance, R has packages for image analysis, GIS, time series, population genetics, and a lot more.\nR works on data of all shapes and sizes. The skills you learn with R scale easily with the size of your dataset. Whether your dataset has hundreds or millions of lines, it won’t make much difference to you. R is designed for data analysis. It comes with special data structures and data types that make handling of missing data and statistical factors convenient. R can connect to spreadsheets, databases, and many other data formats, on your computer or on the web.\nR produces high-quality graphics. The plotting functionalities in R are endless, and allow you to adjust any aspect of your graph to convey most effectively the message from your data.\nR has a large and welcoming community. Thousands of people use R daily. Many of them are willing to help you through mailing lists and websites such as Stack Overflow, or on the RStudio community. Questions which are backed up with short, reproducible code snippets are more likely to attract knowledgeable responses."
  },
  {
    "objectID": "r_lesson/00-introduction.html#starting-out-in-r",
    "href": "r_lesson/00-introduction.html#starting-out-in-r",
    "title": "Introduction to R and R Studio",
    "section": "Starting out in R",
    "text": "Starting out in R\nR is both a programming language and an interactive environment for data exploration and statistics.\nWorking with R is primarily text-based. The basic mode of use for R is that the user provides commands in the R language and then R computes and displays the result.\n\nDownloading, Installing and Running R\nDownload\nR can be downloaded from CRAN (The Comprehensive R Archive Network) for Windows, Linux, or Mac.\nInstall\nInstallation of R is like most software packages and you will be guided. Should you have any issues or need help you can refer to R Installation and Administration\nRunning\nR can be launched from your software or applications launcher or When working at a command line on UNIX or Windows, the command R can be used for starting the main R program in the form R\nYou will see a console similar to this appear:\n\n\n\n\n\n\n\n\n\nWhile it is possible to work solely through the console or using a command line interface, the ideal environment to work in R is RStudio.\n\n\nRStudio\nWe will be working in RStudio.\nThe console provides an interactive way of working with R; you enter commands and view results. RStudio surrounds this with various conveniences.\nRStudio is divided into four “panes”. The placement of these panes and their content can be customized (see menu, Tools -&gt; Global Options -&gt; Pane Layout).\nThe Default Layout is:\n\nTop Left - Source: your scripts and documents\nBottom Left - Console: what R would look and be like without RStudio\nTop Right - Environment/History: look here to see what you have done\nBottom Right - Files and more: see the contents of the project/working directory here, like your Script.R file\n\n\n\n\n\n\n\n\n\n\n\n\nPosit Cloud\nPosit Cloud is a browser-based version of RStudio (Posit being the company that owns RStudio). It will allow you to use RStudio without needing to download anything to your computer. You can also easily share your R projects with others. While we recommend downloading RStudio for regular use, there may be times you find it helpful to have a cloud based solution."
  },
  {
    "objectID": "r_lesson/00-introduction.html#setting-up-a-project",
    "href": "r_lesson/00-introduction.html#setting-up-a-project",
    "title": "Introduction to R and R Studio",
    "section": "Setting up a project",
    "text": "Setting up a project\nA R Project is an RStudio feature that makes it easy to keep all scripts, data, and other material together for a given project.\nTo create a new project go to\nFile &gt; New Project &gt; Create Project From Existing Directory\n\nThen we can use the wizard to navigate to the r_lesson folder on our Desktop. For now you can leave the Open in New Session button unchecked.\nNow you should notice an .Rproj file in your files pane. This is essentially a container file for everything in this directory."
  },
  {
    "objectID": "python_lesson/06-controlstructure2.html",
    "href": "python_lesson/06-controlstructure2.html",
    "title": "Control Structures II",
    "section": "",
    "text": "Questions:\n\n“How can I do the same operations on many different values?”\n\nObjectives:\n\n“Explain what a for loop does.”\n“Correctly write for loops to repeat simple calculations.”\n“Trace changes to a loop variable as the loop runs.”\n“Trace changes to other variables as they are updated by a for loop.”\n\n\n\n\nIt is very good coding practice to reuse as much code as posible as generally, the fewer lines of code there are, the fewer bugs you’ll have. Loops are a very good way of doing this where a block of code is repeated a number of times or on each element in a collection. An example task that we might want to repeat is printing each character in a word on a line of its own.\n\nword = \"lead\"\n\nWe can access a character in a string using its index. For example, we can get the first character of the word \"lead\", by using word[0]. One way to print each character is to use four print statements:\n\nprint(word[0])\nprint(word[1])\nprint(word[2])\nprint(word[3])\n\nl\ne\na\nd\n\n\nThis is a bad approach for two reasons:\n\nIt doesn’t scale. If we want to print the characters in a string that’s hundreds of letters long, we’d be better off just typing them in.\nIt’s fragile. If we give it a longer string, it only prints part of the data,and if we give it a shorter one, it produces an error because we’re asking for characters that don’t exist.\n\nword = 'tin'\nprint(word[0])\nprint(word[1])\nprint(word[2])\nprint(word[3])\nt\ni\nn\n\n---------------------------------------------------------------------------\nIndexError                                Traceback (most recent call last)\n&lt;ipython-input-3-7974b6cdaf14&gt; in &lt;module&gt;()\n      3 print(word[1])\n      4 print(word[2])\n----&gt; 5 print(word[3])\n\nIndexError: string index out of range\nHere’s a better approach:\n\nword = 'lead'\nfor char in word:\n    print(char)\n\nl\ne\na\nd\n\n\nThis is shorter — certainly shorter than something that prints every character in a hundred-letter string — and more robust as well. The improved version uses a for loop to repeat an operation — in this case, printing — once for each thing in a sequence."
  },
  {
    "objectID": "python_lesson/06-controlstructure2.html#python-basics-for-loops",
    "href": "python_lesson/06-controlstructure2.html#python-basics-for-loops",
    "title": "Control Structures II",
    "section": "",
    "text": "Questions:\n\n“How can I do the same operations on many different values?”\n\nObjectives:\n\n“Explain what a for loop does.”\n“Correctly write for loops to repeat simple calculations.”\n“Trace changes to a loop variable as the loop runs.”\n“Trace changes to other variables as they are updated by a for loop.”\n\n\n\n\nIt is very good coding practice to reuse as much code as posible as generally, the fewer lines of code there are, the fewer bugs you’ll have. Loops are a very good way of doing this where a block of code is repeated a number of times or on each element in a collection. An example task that we might want to repeat is printing each character in a word on a line of its own.\n\nword = \"lead\"\n\nWe can access a character in a string using its index. For example, we can get the first character of the word \"lead\", by using word[0]. One way to print each character is to use four print statements:\n\nprint(word[0])\nprint(word[1])\nprint(word[2])\nprint(word[3])\n\nl\ne\na\nd\n\n\nThis is a bad approach for two reasons:\n\nIt doesn’t scale. If we want to print the characters in a string that’s hundreds of letters long, we’d be better off just typing them in.\nIt’s fragile. If we give it a longer string, it only prints part of the data,and if we give it a shorter one, it produces an error because we’re asking for characters that don’t exist.\n\nword = 'tin'\nprint(word[0])\nprint(word[1])\nprint(word[2])\nprint(word[3])\nt\ni\nn\n\n---------------------------------------------------------------------------\nIndexError                                Traceback (most recent call last)\n&lt;ipython-input-3-7974b6cdaf14&gt; in &lt;module&gt;()\n      3 print(word[1])\n      4 print(word[2])\n----&gt; 5 print(word[3])\n\nIndexError: string index out of range\nHere’s a better approach:\n\nword = 'lead'\nfor char in word:\n    print(char)\n\nl\ne\na\nd\n\n\nThis is shorter — certainly shorter than something that prints every character in a hundred-letter string — and more robust as well. The improved version uses a for loop to repeat an operation — in this case, printing — once for each thing in a sequence."
  },
  {
    "objectID": "python_lesson/06-controlstructure2.html#python-concepts-iteration-and-iterator",
    "href": "python_lesson/06-controlstructure2.html#python-concepts-iteration-and-iterator",
    "title": "Control Structures II",
    "section": "Python Concepts: Iteration and Iterator",
    "text": "Python Concepts: Iteration and Iterator\nTwo very important concepts in Python are Iteration and Iterators.\nThe Iteration is a process of repeating the same piece of code several times, this is mostly used in a for or while loops.\nThe Iterator is an object that allows you to iterate over collections of data, such as lists, tuples, dictionaries, and sets. For this lesson we have only discussed list and dictionaries.\nIterators take responsibility for two main actions:\n\nReturning the data from a stream or container one item at a time\nKeeping track of the current and visited items\n\nThe general form of a loop is:\nfor item in group of items:\n    # do things \nWe can call the loop variable anything we like, but there must be a colon at the end of the line starting the loop. Also, we must indent anything we want to run inside the loop."
  },
  {
    "objectID": "python_lesson/06-controlstructure2.html#updating-variables-with-a-for-loop",
    "href": "python_lesson/06-controlstructure2.html#updating-variables-with-a-for-loop",
    "title": "Control Structures II",
    "section": "Updating variables with a for loop",
    "text": "Updating variables with a for loop\nHere’s another loop that repeatedly updates a variable:\n\nlength = 0 #Counter\nvowels = 'aeiou'\n\nfor char in vowels:\n    length += 1\nprint('There are', length, 'vowels')\n\nThere are 5 vowels\n\n\nIt’s worth tracing the execution of this little program step by step.\nSince there are five characters in 'aeiou', the statement on line 3 will be executed five times.\n\nThe first time around, length is zero (the value assigned to it on line 1) and vowel is 'a'. The statement adds 1 to the old value of length, producing 1, and updates length to refer to that new value.\nThe next time around, vowel is 'e' and length is 1, so length is updated to be 2.\nAfter three more updates, length is 5; since there is nothing left in 'aeiou' for Python to process, the loop finishes and the print statement on line 4 tells us our final answer.\n\nNote that a loop variable is just a variable that’s being used to record progress in a loop. It still exists after the loop is over, and we can re-use variables previously defined as loop variables as well:\n\nletter = 'z'\nfor letter in 'abc':\n    print(letter)\nprint('after the loop, letter is', letter)\n\na\nb\nc\nafter the loop, letter is c\n\n\nNote also that finding the length of a string is such a common operation that Python actually has a built-in function to do it called len:\n\nprint(len('aeiou'))\n\n5\n\n\nlen is much faster than any function we could write ourselves, and much easier to read than a two-line loop; it will also give us the length of many other things that we haven’t met yet, so we should always use it when we can."
  },
  {
    "objectID": "python_lesson/06-controlstructure2.html#from-1-to-n",
    "href": "python_lesson/06-controlstructure2.html#from-1-to-n",
    "title": "Control Structures II",
    "section": "From 1 to N",
    "text": "From 1 to N\nPython has a built-in function called range that creates a sequence of numbers range can accept 1, 2, or 3 parameters.\n\nIf one parameter is given, range creates an array of that length, starting at zero and incrementing by 1.\n\nFor example, range(3) produces the numbers 0, 1, 2.\n\nIf two parameters are given, range starts at the first and ends just before the second, incrementing by one. For example, range(2, 5) produces 2, 3, 4.\nIf range is given 3 parameters, it starts at the first one, ends just before the second one, and increments by the third one. For exmaple range(3, 10, 2) produces 3, 5, 7, 9.\n\n\nfor num in range(2,16,3):\n    print(num)\n\n2\n5\n8\n11\n14\n\n\nYou can also use range with the length of the list to iterate through a list.\n\ncat_names = [\"Tomasina\", \"Cometa\", \"Betsy\", \"Fiona\"]\nfor index in range(0,len(cat_names),2):\n    print(f\"{index}){cat_names[index]}\")\n\n0)Tomasina\n2)Betsy"
  },
  {
    "objectID": "python_lesson/06-controlstructure2.html#count-occurences-of-letters-in-a-string",
    "href": "python_lesson/06-controlstructure2.html#count-occurences-of-letters-in-a-string",
    "title": "Control Structures II",
    "section": "Count Occurences of Letters in a String",
    "text": "Count Occurences of Letters in a String\nCount the number of occurences of each letter in a string. Use a dictionary to store the number of times each letter comes up and the loop variable as the key to that dictionary.\nYou will need to check if the letter has been encountered before, i.e. is it in the dictionary? and if not, create it.\n\nmy_str = \"A long string that contains lots of different letters\"\nletter_freq = {} # Dictionary as table of frequency\n\nfor char in my_str:\n    char = char.lower() # Do not distinguish upper and lower case\n    if char not in letter_freq.keys():\n        letter_freq[char] = 0 # Initial frequency of 0\n    letter_freq[char] += 1\nprint(\"Letter frequency:  \", letter_freq)\n\nLetter frequency:   {'a': 3, ' ': 8, 'l': 3, 'o': 4, 'n': 5, 'g': 2, 's': 4, 't': 8, 'r': 3, 'i': 3, 'h': 1, 'c': 1, 'f': 3, 'd': 1, 'e': 4}"
  },
  {
    "objectID": "python_lesson/06-controlstructure2.html#looping-over-lists",
    "href": "python_lesson/06-controlstructure2.html#looping-over-lists",
    "title": "Control Structures II",
    "section": "Looping Over Lists",
    "text": "Looping Over Lists\nThe easiest way to loop over list is to follow the same pattern we have used for strings.\n\nguests = [\"Mario\", \"Luigi\", \"Peach\"]\n\nfor guest in guests:\n    print(f\"Welcome {guest}!\")\n\nWelcome Mario!\nWelcome Luigi!\nWelcome Peach!\n\n\nIn general any iterable object can be loop through using this pattern. Iterable is an object which can be looped over or iterated over with the help of a for loop."
  },
  {
    "objectID": "python_lesson/06-controlstructure2.html#looping-over-dictionaries",
    "href": "python_lesson/06-controlstructure2.html#looping-over-dictionaries",
    "title": "Control Structures II",
    "section": "Looping Over Dictionaries",
    "text": "Looping Over Dictionaries\nDictionaries are iterable objects, but when you iterate you are provided with keys.\n\ncat = {\"name\": \"Cometa\", \"color\":\"black\",\"breed\":\"Russian-Blue\"}\n\nfor item in cat:\n    print(item)\n\nname\ncolor\nbreed\n\n\nYou can verbosely request the keys, values or both of them by making use of the keys, values and items methods. The items method in particular provides both the keys and values at the same time.\nGetting the Keys:\n\ncat = {\"name\": \"Cometa\", \"color\":\"black\",\"breed\":\"Russian-Blue\"}\n\nfor key in cat.keys():\n    print(key)\n\nname\ncolor\nbreed\n\n\nGetting the values:\n\ncat = {\"name\": \"Cometa\", \"color\":\"black\",\"breed\":\"Russian-Blue\"}\n\nfor value in cat.values():\n    print(value)\n\nCometa\nblack\nRussian-Blue\n\n\nGetting the both keys and values:\n\ncat = {\"name\": \"Cometa\", \"color\":\"black\",\"breed\":\"Russian-Blue\"}\n\nfor key, value in cat.items():\n    print(f\"{key}={value}\")\n\nname=Cometa\ncolor=black\nbreed=Russian-Blue"
  },
  {
    "objectID": "python_lesson/06-controlstructure2.html#while-loops-do-exist",
    "href": "python_lesson/06-controlstructure2.html#while-loops-do-exist",
    "title": "Control Structures II",
    "section": "While loops do exist!",
    "text": "While loops do exist!\nwhile is another example of iteration, and what it means is that while the condition still true, the code will be repeating itself until is no longer true.\nExample of while loops:\n\ntimes = 0 #counter\nwhile times &lt; 3:\n    print(\"Hello!\")\n    times += 1 #update counter\n    print(times)\n\nHello!\n1\nHello!\n2\nHello!\n3\n\n\n\n\n\n\n\n\nKeypoints:\n\n“Use for variable in sequence to process the elements of a sequence one at a time.”\n“The body of a for loop must be indented.”\n“Use len(thing) to determine the length of something that contains other values.”"
  },
  {
    "objectID": "python_lesson/04-controlstructures1.html",
    "href": "python_lesson/04-controlstructures1.html",
    "title": "Control Structures I",
    "section": "",
    "text": "Questions:\n\n“How can my programs do different things based on data values?”\n\nObjectives:\n\n“Write conditional statements including if, elif, and else branches.”\n“Correctly evaluate expressions containing and and or.”\n\n\n\n\nA key part of programming is making the computer do different things depending on the outcome of a test. This functionality is provided by the conditional statements if, elif, and else.\nFor this processes, and also for the for loops, Python relays on indentation. Indentation refers to the spaces at the beginning of a code line. Python uses indentation to indicate a block of code. This is a very importnat concept because without properly indenting Python may raise an IndentationError.\n\n\n\nPython Indentation"
  },
  {
    "objectID": "python_lesson/04-controlstructures1.html#python-basics-if-statements-and-conditional-execution",
    "href": "python_lesson/04-controlstructures1.html#python-basics-if-statements-and-conditional-execution",
    "title": "Control Structures I",
    "section": "",
    "text": "Questions:\n\n“How can my programs do different things based on data values?”\n\nObjectives:\n\n“Write conditional statements including if, elif, and else branches.”\n“Correctly evaluate expressions containing and and or.”\n\n\n\n\nA key part of programming is making the computer do different things depending on the outcome of a test. This functionality is provided by the conditional statements if, elif, and else.\nFor this processes, and also for the for loops, Python relays on indentation. Indentation refers to the spaces at the beginning of a code line. Python uses indentation to indicate a block of code. This is a very importnat concept because without properly indenting Python may raise an IndentationError.\n\n\n\nPython Indentation"
  },
  {
    "objectID": "python_lesson/04-controlstructures1.html#conditionals",
    "href": "python_lesson/04-controlstructures1.html#conditionals",
    "title": "Control Structures I",
    "section": "Conditionals",
    "text": "Conditionals\nWe can ask Python to take different actions, depending on a condition, with an if statement:\n\nnum = 37\nif num &gt; 100:\n    print('greater')\nelse:\n    print('not greater')\nprint('done')\n\nnot greater\ndone\n\n\nOutput:\nnot greater\ndone\nThe second line of this code uses the keyword if to tell Python that we want to make a choice. If the test that follows the if statement is true, the body of the if (i.e., the lines indented underneath it) are executed. If the test is false, the body of the else is executed instead. Only one or the other is ever executed.\n\n\n\nExecuting a Conditional\n\n\nConditional statements don’t have to include an else. If there isn’t one, Python simply does nothing if the test is false:\n\nnum = 53\nprint('before conditional...')\nif num &gt; 100:\n    print(num,' is greater than 100')\nprint('...after conditional')\n\nbefore conditional...\n...after conditional\n\n\nOutput:\nbefore conditional...\n...after conditional\nWe can also chain several tests together using elif, which is short for “else if”. The following Python code uses elif to print the sign of a number.\n\nnum = -3\n\nif num &gt; 0:\n    print(num, 'is positive')\nelif num == 0:\n    print(num, 'is zero')\nelse:\n    print(num, 'is negative')\n\n-3 is negative\n\n\nOutput:\n\"-3 is negative\"\nNote that to test for equality we use a double equals sign == rather than a single equals sign = which is used to assign values.\nWe can also combine tests using and and or. and is only true if both parts are true:\n\nif (1 &gt; 0) and (-1 &gt; 0):\n    print('both parts are true')\nelse:\n    print('at least one part is false')\n\nat least one part is false\n\n\nOutput:\nat least one part is false\nWhile or is true if at least one part is true:\n\nif (1 &lt; 0) or (-1 &lt; 0):\n    print('at least one test is true')\n\nat least one test is true\n\n\nOutput:\nat least one test is true\n\n\n\n\n\n\nTrue and False: Examples\n\n\n\nTrue and False are special words in Python called booleans, which represent truth values. A statement such as 1 &lt; 0 returns the value False, while -1 &lt; 0 returns the value True.\nConsider this code:\n\n if 4 &gt; 5:\n     print('A')\n elif 4 == 5:\n    print('B')\nelif 4 &lt; 5:\n    print('C')\n\nC\n\n\nWhich of the following would be printed if you were to run this code? Why did you pick this answer?\n\nA\nB\nC\nB and C\n\n\n\n\n\n\n\nTip\n\n\n\n\n\nC gets printed because the first two conditions, 4 &gt; 5 and 4 == 5, are not true, but 4 &lt; 5 is true.\n\n\n\nTrue and False booleans are not the only values in Python that are true and false. In fact, any value can be used in an if or elif. After reading and running the code below, explain what the rule is for which values are considered true and which are considered false.\n\nif '':\n    print('empty string is true')\nif 'word':\n    print('word is true')\nif []:\n    print('empty list is true')\nif [1, 2, 3]:\n    print('non-empty list is true')\nif 0:\n    print('zero is true')\nif 1:\n    print('one is true')\n\nword is true\nnon-empty list is true\none is true\n\n\nOutput:\nword is true\nnon-empty list is true\none is true\nSometimes it is useful to check whether some condition is not true. The Boolean operator not can do this explicitly. After reading and running the code below write some if statements that use not to test the rule that you formulated in the previous challenge.\n\nif not '':\n    print('empty string is not true')\nif not 'word':\n    print('word is not true')\nif not not True:\n    print('not not True is true')\n\nempty string is not true\nnot not True is true\n\n\nOutput:\nempty string is not true\nnot not True is true\nWrite some conditions that print True if the variable a is within 10% of the variable b and False otherwise.\nHint: You can make the condition easier to understand if you use the abs function — help will tell you what it does!\n\n\n\n\n\n\nTip\n\n\n\n\n\n## Solution 1\n\na = 5\nb = 5.1\n\nif abs(a - b) &lt; 0.1 * abs(b):\n    print('True')\nelse:\n    print('False')\n\nTrue\n\n\n\nSolution 2\n\nprint(abs(a - b) &lt; 0.1 * abs(b))\n\nTrue\n\n\nThis works because the Booleans True and False have string representations which can be printed.\n\n\n\n\n\n\n\n\n\n\n\n\nKeypoints:\n\n“Use if condition to start a conditional statement, elif condition to provide additional tests, and else to provide a default.”\n“The bodies of the branches of conditional statements must be indented.”\n“Use == to test for equality.”\n“X and Y is only true if both X and Y are true.”\n“X or Y is true if either X or Y, or both, are true.”\n“Zero, the empty string, and the empty list are considered false; all other numbers, strings, and lists are considered true.”\n“True and False represent truth values.”"
  },
  {
    "objectID": "python_lesson/04-controlstructures1.html#solution-2",
    "href": "python_lesson/04-controlstructures1.html#solution-2",
    "title": "Control Structures I",
    "section": "Solution 2",
    "text": "Solution 2\n\nprint(abs(a - b) &lt; 0.1 * abs(b))\n\nTrue\n\n\nThis works because the Booleans True and False have string representations which can be printed."
  },
  {
    "objectID": "python_lesson/02-jupyternotebooks.html",
    "href": "python_lesson/02-jupyternotebooks.html",
    "title": "Jupyter Notebooks",
    "section": "",
    "text": "For this lesson we will be creating and using Jupyter Notebooks. The Jupyter Notebook is an open source web application that you can use to create and share documents that contain live code, equations, visualizations, and text. Jupyter Notebook is maintained by the people at Project Jupyter. Jupyter supports over 40 programming languages, including Python, R, Julia, and Scala. Notebooks can be shared with others using email, Dropbox, GitHub and the Jupyter Notebook Viewer."
  },
  {
    "objectID": "python_lesson/02-jupyternotebooks.html#what-is-a-jupyter-notebook",
    "href": "python_lesson/02-jupyternotebooks.html#what-is-a-jupyter-notebook",
    "title": "Jupyter Notebooks",
    "section": "",
    "text": "For this lesson we will be creating and using Jupyter Notebooks. The Jupyter Notebook is an open source web application that you can use to create and share documents that contain live code, equations, visualizations, and text. Jupyter Notebook is maintained by the people at Project Jupyter. Jupyter supports over 40 programming languages, including Python, R, Julia, and Scala. Notebooks can be shared with others using email, Dropbox, GitHub and the Jupyter Notebook Viewer."
  },
  {
    "objectID": "python_lesson/02-jupyternotebooks.html#python-vs.-jupyter",
    "href": "python_lesson/02-jupyternotebooks.html#python-vs.-jupyter",
    "title": "Jupyter Notebooks",
    "section": "Python vs. Jupyter",
    "text": "Python vs. Jupyter\nYou may be wondering why you type jupyter notebook to run the Python interpreter rather than just python. This does also work but this is a much more basic interpreter than Jupyter Notebook that doesn’t have tab completion, syntax highlighting, etc. If you ever need an interactive Python prompt, Jupyter notebook is the best option!"
  },
  {
    "objectID": "python_lesson/02-jupyternotebooks.html#start-a-jupyter-notebook",
    "href": "python_lesson/02-jupyternotebooks.html#start-a-jupyter-notebook",
    "title": "Jupyter Notebooks",
    "section": "Start a Jupyter Notebook:",
    "text": "Start a Jupyter Notebook:\nFor this lesson, Jupyter Notebook is installed in a specific Conda environment. In our class computer that environment is called python-intro. After activating the conda environment using Conda activate python intro, you can start a Jupyter Notebook server with the following command:\njupyter notebook\nThis command may run up a series of processes that will end up in two ways:\n\nThe terminal may end up providing you a link to click on so you can access the Jupyter Notebook.\n\nOR\n\nA Chrome, Firefox or Edge window will pop-up with a Jupyter Notebook tab open."
  },
  {
    "objectID": "python_lesson/02-jupyternotebooks.html#creating-a-notebook",
    "href": "python_lesson/02-jupyternotebooks.html#creating-a-notebook",
    "title": "Jupyter Notebooks",
    "section": "Creating a Notebook",
    "text": "Creating a Notebook\nAfter starting a Notebook server the next thing to do is create or open an actual Notebook document!\nTo create the Notebook click the New button (upper right) which opens a drop down with a list of choices. You will select the option for Python 3.\n\n\n\nNew Notebook\n\n\nThe webpage should now look like this:\n\n\n\nCreate Jupyter Notebook"
  },
  {
    "objectID": "python_lesson/02-jupyternotebooks.html#naming-your-notebook",
    "href": "python_lesson/02-jupyternotebooks.html#naming-your-notebook",
    "title": "Jupyter Notebooks",
    "section": "Naming your notebook",
    "text": "Naming your notebook\nYou will notice that at the top of the page is the word Untitled. This is the title for the page and the name of your Notebook. Go ahead and change it to something more meaningful. Just move your mouse over the word Untitled and click on the text. You should now see an in-browser dialog titled Rename Notebook.\n\n\n\nRename Jupyter Notebook"
  },
  {
    "objectID": "python_lesson/02-jupyternotebooks.html#running-cells",
    "href": "python_lesson/02-jupyternotebooks.html#running-cells",
    "title": "Jupyter Notebooks",
    "section": "Running Cells",
    "text": "Running Cells\nA Notebook’s cell defaults to using code whenever you first create one, and that cell uses the kernel that you chose when you started your Notebook.\nIn this case, you started yours with Python 3 as your kernel, so that means you can write Python code in your code cells. Since your initial Notebook has only one empty cell in it, the Notebook can’t really do anything.\nThus, to verify that everything is working as it should, you can add some Python code to the cell and try running its contents."
  },
  {
    "objectID": "python_lesson/02-jupyternotebooks.html#getting-python-to-do-something",
    "href": "python_lesson/02-jupyternotebooks.html#getting-python-to-do-something",
    "title": "Jupyter Notebooks",
    "section": "Getting Python to do something",
    "text": "Getting Python to do something\nNow we can start and (possibly more importantly!) exit Python, we can try to get it do something by giving it a command. The Jupyter Notebook intepreter (i.e. the In [x]: prompt) works in a very similar way to the shell except that here you will be typing python code directly instead of running programs. We shall start by getting Python to print something. This is very basic but will be invaluable going forward:\nprint(\"Hello World\")\nRunning a cell means that you will execute the cell’s contents. To execute a cell, you can just select the cell and click the Run button that is in the row of buttons along the top. It’s towards the middle. If you prefer using your keyboard, you can just press Shift+Enter.\n\n\n\nRun a Cell in Jupyter Notebook\n\n\nSo what did we just do? We typed in a python statement that was interpreted by Python and acted on when we pressed Shift+Enter. It interpreted this as ’call the function print with the argument \"Hello World\". It went away, ran the appropriate code and returned.\nBut what does the print function do? In this case, it’s fairly self-expanatory but if you wanted to know more you can use the help function:\n\nhelp(print)\n\nHelp on built-in function print in module builtins:\n\nprint(*args, sep=' ', end='\\n', file=None, flush=False)\n    Prints the values to a stream, or to sys.stdout by default.\n    \n    sep\n      string inserted between values, default a space.\n    end\n      string appended after the last value, default a newline.\n    file\n      a file-like object (stream); defaults to the current sys.stdout.\n    flush\n      whether to forcibly flush the stream.\n\n\n\nJupyter Notebooks also have shell-like behavior in that you can use Tab to auto-complete a function or variable name:\npri [Tab]\nprint"
  },
  {
    "objectID": "python_lesson/02-jupyternotebooks.html#jupyter-notebook-menus",
    "href": "python_lesson/02-jupyternotebooks.html#jupyter-notebook-menus",
    "title": "Jupyter Notebooks",
    "section": "Jupyter Notebook menus",
    "text": "Jupyter Notebook menus\nThe Jupyter notebook has several menus that help you interact with the notebook. The menus are found along the top similar to menus from other applications. You are encouraged to go through the menu tabs and explore what possibilities exist within each. It is worth noting that many of the commands within the menu tabs will provide a corresponding keyboard short-cut to use them for reducing mouse fatigue. Use of the menu resources will become more apparent as you proceed in working with Jupyter Notebooks.\nThe Help menu is particularly useful. The Help menu is where you go to learn about the Notebook’s keyboard shortcuts, a user interface tour, and lots of reference material."
  },
  {
    "objectID": "python_lesson/02-jupyternotebooks.html#adding-rich-content-to-your-notebook",
    "href": "python_lesson/02-jupyternotebooks.html#adding-rich-content-to-your-notebook",
    "title": "Jupyter Notebooks",
    "section": "Adding Rich Content to your Notebook",
    "text": "Adding Rich Content to your Notebook\nJupyter Notebook supports adding rich content to its cells. Lets take a look some of the things you can do with your cells using Markup and Code.\n\nCell Types\nThere are 3 cell types you can create in a Notebook: Code, Markdown, Raw NBConvert. The Cell menu Cell Type selection shows you them with their corresponding keyboard short-cut:\nCell Types\nThe primary cell types that you will use are the Code and Markdown cell types. You have already learned how code cells work, so let’s learn how to style your text with Markdown.\n\n\nStyling text with Markdown\nJupyter Notebook supports Markdown, which is a markup language that is a superset of HTML. We will look at some of the basic styling possible using Markdown in the following examples, for a more extensive guide visit: Ultimate Markdown Guide\nTo write Markdown in the Notebook, lets first set a new cell to Markdown or use keyboard short-cut M and add some text to the cell:\n\n\n\nStyling cell with markdown\n\n\nRun the cell using your favorite method and it should look like this:\n\n\n\nRendered styling\n\n\nTo make your text BOLD, use a double underscore or a double asterisk.\nCreating headers in Markdown involves placing a pound sign at the beginning of a line and making a space after! The more pound signs you use, the smaller the header. Jupyter Notebook even kind of previews it for you:\n\n\n\nHeaders in Markdown\n\n\nRunning the cell you are left with a beautiful header for your notebook.\n\n\n\nRendered headers\n\n\nIn case you want to insert a code example that you don’t expect to be run by the end user, there’s a Markdown for that too! For inline code highlighting, just surround the code with backticks. If you want to insert a block of code, you can use triple backticks and also specify the programming language:\n\n\n\nBackticks\n\n\nJupyter notebooks provide a wide set of features to explore and use. You will want to investigate more on the topic. Some important topics not covered are Exporting Notebooks, Installing Kernels, Notebook extensions, hosting your Jupyter Notebook on Jupyter Hub and more!"
  },
  {
    "objectID": "python_lesson/00-introduction.html",
    "href": "python_lesson/00-introduction.html",
    "title": "Introduction to Python, Conda and Jupyter Notebooks",
    "section": "",
    "text": "Introduce participants to Conda, a popular package and virtual environment management tool.\nIntroduce participants to Jupyter Notebooks\nTeach participants how to create, edit, and use Jupyter Notebooks effectively.\nIntroduce participants to the fundamentals of Python programming."
  },
  {
    "objectID": "python_lesson/00-introduction.html#learning-objectives",
    "href": "python_lesson/00-introduction.html#learning-objectives",
    "title": "Introduction to Python, Conda and Jupyter Notebooks",
    "section": "",
    "text": "Introduce participants to Conda, a popular package and virtual environment management tool.\nIntroduce participants to Jupyter Notebooks\nTeach participants how to create, edit, and use Jupyter Notebooks effectively.\nIntroduce participants to the fundamentals of Python programming."
  },
  {
    "objectID": "python_lesson/00-introduction.html#why-python-conda-and-jupyter-notebook",
    "href": "python_lesson/00-introduction.html#why-python-conda-and-jupyter-notebook",
    "title": "Introduction to Python, Conda and Jupyter Notebooks",
    "section": "Why Python, Conda and Jupyter Notebook?",
    "text": "Why Python, Conda and Jupyter Notebook?\nThis course is designed to introduce participants to a reproducible research environment. Briefly, it attempts to provide an experience of how to interact with a Jupyter Notebooks web interface where documentation and computational processes are combined in a single document. Likewise, participants will be able to interact with the Conda package manager. Conda minimizes research software installation errors by allowing the creation of virtual environments. Finally, participants will be exposed to the Python programming language by being able to practice basic commands.\n\nWhat is reproducible research environments?\n Image from: The Turing Way project illustration by Scriberia. Used under a CC-BY 4.0 licence. DOI: 10.5281/zenodo.3332807.\nThe term reproducible research is the idea of compiling enough information about your code, data, text files, software use, software licencing, and other information that allows other researchers to replicate not only the computer systems used for analysis, but the experiment itself too.\nTo accomplish this, there are softwares that allows you to automatically collect information about the programs, code or packages that you are using and the analytical changes that you are performing in your research environment. Some of those software are Jupyter Notebook and MiniConda.\nThis is also very convenient for research labs or research colleages that need to share or emulate the same computing environment in order to perform their research.\n\n\n\n\n\n\nWant to learn more about research reproducibility?\n\n\n\nGoodman, S. N., Fanelli, D., & Ioannidis, J. P. A. (2016). What does research reproducibility mean? Science Translational Medicine, 8(341). doi: 10.1126/scitranslmed.aaf5027\nThe Turing Way Community. (2021, November 10). The Turing Way: A handbook for reproducible, ethical and collaborative research. https://the-turing-way.netlify.app/index.html#"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this site\n\n1 + 1\n\n[1] 2"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Intro to Programming",
    "section": "",
    "text": "Intro to the shell In this lesson, you will be learning about the command line, also known as the shell, terminal, bash, etc. You will learn concepts essential for using the command line for bioinformatics, such as navigating the file system, computationally manipulating your files (including copying, moving, and renaming), searching files, redirecting output, and writing shell scripts.\nIntro to R and RStudio In this lesson, you will be learning about R and how it is used for data science and bioinformatics. You will learn about R syntax, data types, and how to set up and use RStudio – a powerful and convenient environment in which to work with R. You will also be introduced to the popular Tidyverse collection of packages for data wrangling and visualization.\nIntro to Python In this lesson, you will be learning about Python and how it is used for data science and bioinformatics. You will learn Python syntax and package management, using both a text editor and Jupyter notebooks to write and execute Python code.\nSchedule\n\n\n\nDate\nTopic\n\n\n\n\nOctober 5th, 2023\nIntro to the Command Line\n\n\nOctober 12th, 2023\nR and RStudio\n\n\nOctober 19th, 2023\nPython"
  },
  {
    "objectID": "index.html#course-description",
    "href": "index.html#course-description",
    "title": "Intro to Programming",
    "section": "",
    "text": "Intro to the shell In this lesson, you will be learning about the command line, also known as the shell, terminal, bash, etc. You will learn concepts essential for using the command line for bioinformatics, such as navigating the file system, computationally manipulating your files (including copying, moving, and renaming), searching files, redirecting output, and writing shell scripts.\nIntro to R and RStudio In this lesson, you will be learning about R and how it is used for data science and bioinformatics. You will learn about R syntax, data types, and how to set up and use RStudio – a powerful and convenient environment in which to work with R. You will also be introduced to the popular Tidyverse collection of packages for data wrangling and visualization.\nIntro to Python In this lesson, you will be learning about Python and how it is used for data science and bioinformatics. You will learn Python syntax and package management, using both a text editor and Jupyter notebooks to write and execute Python code.\nSchedule\n\n\n\nDate\nTopic\n\n\n\n\nOctober 5th, 2023\nIntro to the Command Line\n\n\nOctober 12th, 2023\nR and RStudio\n\n\nOctober 19th, 2023\nPython"
  },
  {
    "objectID": "index.html#resources",
    "href": "index.html#resources",
    "title": "Intro to Programming",
    "section": "Resources",
    "text": "Resources\nThis material was lightly adapted from the Data Carpentry Genomics Curriculum which is shared under a CC-BY 4.0 license."
  },
  {
    "objectID": "python_lesson/01-condaenvironments.html",
    "href": "python_lesson/01-condaenvironments.html",
    "title": "Conda Environments",
    "section": "",
    "text": "Image from: https://angus.readthedocs.io/en/2019/conda_tutorial.html\nConda virtual environments provide a way to install packages without worrying about package conflicts (eg. diferences on package version).\nIt is posible to create a web-development environment where we install Flask, Gunicorn and Requests libraries and a separate environment where we install pandas, biopython and other packages used to analyze data. Without virtual environments, a package installation may cause your operating system to break due to version conflicts. In the virtual environment, only programs run inside the enviroment will be affected by any of your installations.\nWhat is a package?\nA Package is a program that perform specific tasks. Like for example, tidyverse is a package for the R language,pandas is a package for Python language. Each package can include information related to its creation, versions and maintainers.\n\n\nA ‘base’ conda environment, is like the home base inside conda. In this place we do not want to install programs and/or packages because they may have conflicts with whatever you may end up doing in the future.\nTo avoid any potential issues in between projects it is recomended to create a conda enviroment, and after activating the conda environment, install the packages that your research may need.\nYour terminal display should look something similar to the following:\n(base) student@hostname~ % \nThe (base) symbolizes that you are in the conda base environment.\n\n\n\nTo create a new conda environment write the following command:\nconda create -n name-of-the-new-environment\nThe base command is conda create, then we are specifying the name of our new environment with -n name-of-the-new-environment. After hitting enter, the terminal is going to start some procesess and is going to ask you if you want to proceed with the creation of the conda environment. Select y (yes) and it will finish the process of creating the environment.\nYou will be seeing in your terminal something similar to the following:\nRetrieving notices: ...working... done\nCollecting package metadata (current_repodata.json): done\nSolving environment: done\n\n## Package Plan \n\n  environment location: /Users/username/anaconda3/envs/name-of-the-new-environment\n\nProceed ([y]/n)? y\n\nPreparing transaction: done\nVerifying transaction: done\nExecuting transaction: done\n#\n# To activate this environment, use\n#\n#     $ conda activate name-of-the-new-environment\n#\n# To deactivate an active environment, use\n#\n#     $ conda deactivate\n\n\n\nAfter creating the new environment, you need to activate so you can use it. To activate that environment, we need to execute:\nconda activate name-of-the-new-environment\nWhen you activate the environment, your terminal prompt will change to display the name of your new environment. That will letyou know that we have moved from the base environment to the new one.\n(name-of-the-new-environment) student@hostname~ % \nYou can also see a list of all the environments created by using the following command:\nconda env list\nconda env list will display all the available conda environments and will place an asterist to the ones that you are using at the moment.\nIt will display something similar to the following:\n(name-of-the-new-environment) student@hostname ~ % conda env list\n# conda environments:\n#\nname-of-the-new-environme    *  /Users/ifraticelli/anaconda3\npython-intro                  /Users/ifraticelli/anaconda3/envs/python-intro\ntest                         /Users/ifraticelli/anaconda3/envs/test\nTo verify what are the packages that your virtual environment has you can also use conda list.\nIt will display something similar to the following:\n(name-of-the-new-environment) student@hostname % conda list\n# packages in environment at /Users/ifraticelli/anaconda3/envs/python-intro:\n#\n# Name                    Version                   Build  Channel\npure_eval                 0.2.2              pyhd8ed1ab_0    conda-forge\npygments                  2.16.1             pyhd8ed1ab_0    conda-forge\npython                    3.11.5               hf27a42d_0  \npython-dateutil           2.8.2              pyhd3eb1b0_0  \npython-tzdata             2023.3             pyhd3eb1b0_0  \npython_abi                3.11                    2_cp311    conda-forge\n...                       ...                     ...           ...\n\n\n\nYou can deactivate a conda eniroment at any time by running the following code.\nconda deactivate\n\n\n\nMove to the conda environment called ‘python-intro’.\nThen name two the conda packages that the python-intro environment has.\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\nconda activate python-intro\nPandas, BioPython, Python…\n\n\n\n\n\n\n\n\n\n\nWant to learn more about Conda Packages?\n\n\n\nIf you want to learn more about Conda Packages you can visit their repository at the Anaconda Website."
  },
  {
    "objectID": "python_lesson/01-condaenvironments.html#what-is-conda-how-it-works",
    "href": "python_lesson/01-condaenvironments.html#what-is-conda-how-it-works",
    "title": "Conda Environments",
    "section": "",
    "text": "Image from: https://angus.readthedocs.io/en/2019/conda_tutorial.html\nConda virtual environments provide a way to install packages without worrying about package conflicts (eg. diferences on package version).\nIt is posible to create a web-development environment where we install Flask, Gunicorn and Requests libraries and a separate environment where we install pandas, biopython and other packages used to analyze data. Without virtual environments, a package installation may cause your operating system to break due to version conflicts. In the virtual environment, only programs run inside the enviroment will be affected by any of your installations.\nWhat is a package?\nA Package is a program that perform specific tasks. Like for example, tidyverse is a package for the R language,pandas is a package for Python language. Each package can include information related to its creation, versions and maintainers.\n\n\nA ‘base’ conda environment, is like the home base inside conda. In this place we do not want to install programs and/or packages because they may have conflicts with whatever you may end up doing in the future.\nTo avoid any potential issues in between projects it is recomended to create a conda enviroment, and after activating the conda environment, install the packages that your research may need.\nYour terminal display should look something similar to the following:\n(base) student@hostname~ % \nThe (base) symbolizes that you are in the conda base environment.\n\n\n\nTo create a new conda environment write the following command:\nconda create -n name-of-the-new-environment\nThe base command is conda create, then we are specifying the name of our new environment with -n name-of-the-new-environment. After hitting enter, the terminal is going to start some procesess and is going to ask you if you want to proceed with the creation of the conda environment. Select y (yes) and it will finish the process of creating the environment.\nYou will be seeing in your terminal something similar to the following:\nRetrieving notices: ...working... done\nCollecting package metadata (current_repodata.json): done\nSolving environment: done\n\n## Package Plan \n\n  environment location: /Users/username/anaconda3/envs/name-of-the-new-environment\n\nProceed ([y]/n)? y\n\nPreparing transaction: done\nVerifying transaction: done\nExecuting transaction: done\n#\n# To activate this environment, use\n#\n#     $ conda activate name-of-the-new-environment\n#\n# To deactivate an active environment, use\n#\n#     $ conda deactivate\n\n\n\nAfter creating the new environment, you need to activate so you can use it. To activate that environment, we need to execute:\nconda activate name-of-the-new-environment\nWhen you activate the environment, your terminal prompt will change to display the name of your new environment. That will letyou know that we have moved from the base environment to the new one.\n(name-of-the-new-environment) student@hostname~ % \nYou can also see a list of all the environments created by using the following command:\nconda env list\nconda env list will display all the available conda environments and will place an asterist to the ones that you are using at the moment.\nIt will display something similar to the following:\n(name-of-the-new-environment) student@hostname ~ % conda env list\n# conda environments:\n#\nname-of-the-new-environme    *  /Users/ifraticelli/anaconda3\npython-intro                  /Users/ifraticelli/anaconda3/envs/python-intro\ntest                         /Users/ifraticelli/anaconda3/envs/test\nTo verify what are the packages that your virtual environment has you can also use conda list.\nIt will display something similar to the following:\n(name-of-the-new-environment) student@hostname % conda list\n# packages in environment at /Users/ifraticelli/anaconda3/envs/python-intro:\n#\n# Name                    Version                   Build  Channel\npure_eval                 0.2.2              pyhd8ed1ab_0    conda-forge\npygments                  2.16.1             pyhd8ed1ab_0    conda-forge\npython                    3.11.5               hf27a42d_0  \npython-dateutil           2.8.2              pyhd3eb1b0_0  \npython-tzdata             2023.3             pyhd3eb1b0_0  \npython_abi                3.11                    2_cp311    conda-forge\n...                       ...                     ...           ...\n\n\n\nYou can deactivate a conda eniroment at any time by running the following code.\nconda deactivate\n\n\n\nMove to the conda environment called ‘python-intro’.\nThen name two the conda packages that the python-intro environment has.\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\nconda activate python-intro\nPandas, BioPython, Python…\n\n\n\n\n\n\n\n\n\n\nWant to learn more about Conda Packages?\n\n\n\nIf you want to learn more about Conda Packages you can visit their repository at the Anaconda Website."
  },
  {
    "objectID": "python_lesson/03-pythonbasics.html",
    "href": "python_lesson/03-pythonbasics.html",
    "title": "Python Basics",
    "section": "",
    "text": "Questions:\n\n“How can I store and access basic information in Python?”\n“How do I manipulate objects and data in Python?”\n\nObjectives:\n\n“Explain what Types, Objects, Values and Variables are with respect to Python”\n“Introduce the basic variable types”\n“Show how to initialise, access and change variables”\n“Show how to perform operations on python objects”\n“Introduce the basic operators”"
  },
  {
    "objectID": "python_lesson/03-pythonbasics.html#python-basics-types-objects-values-variables-and-operators",
    "href": "python_lesson/03-pythonbasics.html#python-basics-types-objects-values-variables-and-operators",
    "title": "Python Basics",
    "section": "",
    "text": "Questions:\n\n“How can I store and access basic information in Python?”\n“How do I manipulate objects and data in Python?”\n\nObjectives:\n\n“Explain what Types, Objects, Values and Variables are with respect to Python”\n“Introduce the basic variable types”\n“Show how to initialise, access and change variables”\n“Show how to perform operations on python objects”\n“Introduce the basic operators”"
  },
  {
    "objectID": "python_lesson/03-pythonbasics.html#what-is-python",
    "href": "python_lesson/03-pythonbasics.html#what-is-python",
    "title": "Python Basics",
    "section": "What is Python?",
    "text": "What is Python?\nPython is a general purpose programming language which means that it wasn’t designed to solve a particular problem or group of problems (like R or Matlab) but any problem you can think of to solve on a computer. Consequently, you can use Python to do almost anything from analyze data to running computer systems to creating games.\nThough comprised of fairly basic syntax (i.e. the grammar of the commands you give it) it is incredibly powerful. It is relatively easy to pick up as well and thanks to a very large and growing set of external modules (or blocks of code) written by other programmers, you can do complicated things quickly and easily.\nOne of the reasons for this power is that it is (to a certain degree) an interpreted language. This means that the code you type gets translated into instructions the computer can understand as Python reads it. There is not a separate optimisation or ‘compilation’ step to create your executable/binary before you can run your code like there is with some other languages like C++. This allows the language to be very dynamic but does have the drawback of being slower than others. However, there are many ways Python has of overcoming these drawbacks and you will almost certainly never notice a problem!\nNow we have learned the technical aspects of using the Python interpreter, we can move on to the basics of programming using it. The first thing we’ll learn about is how Python stores and interprets information."
  },
  {
    "objectID": "python_lesson/03-pythonbasics.html#python-at-the-terminal",
    "href": "python_lesson/03-pythonbasics.html#python-at-the-terminal",
    "title": "Python Basics",
    "section": "Python at the Terminal",
    "text": "Python at the Terminal\nWe could be using Python from the terminal, and perform basic calculations like the following:\npython3\nIn your terminal something similar to the following should appear:\nPython 3.11.2 (v3.11.2:878ead1ac1, Feb  7 2023, 10:02:41) [Clang 13.0.0 (clang-1300.0.29.30)] on darwin\nType \"help\", \"copyright\", \"credits\" or \"license\" for more information.\n&gt;&gt;&gt;\nAnd you can perfom math calculations like the following:\n3 + 5 * 4\nOutput:\n23\nBut this is not a great use of Python capabilities, and again it will not allow us to have a reproducible environment. So lets move on to our Jupyter Notebook and lets start running some python code!"
  },
  {
    "objectID": "python_lesson/03-pythonbasics.html#using-python-in-jupyter-notebook",
    "href": "python_lesson/03-pythonbasics.html#using-python-in-jupyter-notebook",
    "title": "Python Basics",
    "section": "Using Python in Jupyter Notebook",
    "text": "Using Python in Jupyter Notebook\n\nTypes, Objects, Values and Variables\nTo do anything useful with data, we need to assign its value to a variable otherwise we’d have to write the whole analysis as one long calculation.\nBut what is a variable? And what is it’s relation to how Python organizes the information you give it?\nThis is all covered by four terms:\n\nTypes – How to interpret data in a memory location (‘object’) and what operations can be performed by it\nObject – Defined area of memory that holds the data (‘values’) associated with a type\nValue – Actual data/bits in memory interpreted by the (‘type’)\nVariable – A flag or name of an area of memory (‘object’)\n\nThis probably seems quite abstract but it can be very useful to know the difference as we progress!\nAnother way of looking at this is in terms of a physical object like a laptop:\n\n\n\nA Generic laptop\n\n\nIn this case, the Object is the physical laptop sitting on the desk, the Type of the object is ‘Laptop’, the Value is the bits and pieces that actually make up the laptop (forming a MacBook in this case) and finally the Variable would be who’s laptop it was, e.g. Fred’s laptop."
  },
  {
    "objectID": "python_lesson/03-pythonbasics.html#assigning-variables",
    "href": "python_lesson/03-pythonbasics.html#assigning-variables",
    "title": "Python Basics",
    "section": "Assigning Variables",
    "text": "Assigning Variables\nIn Python, we can assign (to give a value a name by associating a variable with it) an object or value to a variable (a value that has a name associated with it.), using the equals sign =. For example, to assign value 60 to a variable weight_kg, we would execute:\n\nweight_kg = 60\n\nFrom now on, whenever we use weight_kg, Python will refer back to the Object it points to (in this case an integer with value ‘60’) and effectively substitute it’s value where the variable is.\n\n\n\n\n\n\nPython variable naming conventions: What’s in a name?\n\n\n\nIn Python, variable names:\n\nA variable name can only contain alpha-numeric characters and underscores (A-z, 0-9, and _ )\nare case sensitive\ncan not start with a digit\ncan not include special characters\ncan not include any of the python keywords (and,as,if,else,elif, for, and many others)\n\nThis means that, for example:\n\nweight0 is a valid variable name, whereas 0weight is not\nweight and Weight are different variables\nThe variable age is not the same as AGE or as Age. age, AGE and Age will be three diferent variables.\n\n\n\nWhen you run code to create a variable, Python performs the following actions:\n\ncreate space for the integer object in the computer’s memory\nmark it as being of type ‘Integer’\nassign the value ‘60’ to it\nlabel it with ‘weight_kg’.\n\nThis all happens each time you create a new variable, so if you ran the following code:\n\na = 43\nb = 76.2\nc = \"Hello\"\n\nWhat happens in the computer’s memory can be shown like this:\n\n\n\nSchematic computer memory\n\n\nWhere the dark grey boxes are elements of the computer’s memory, the light grey boxes assigned memory with the values inside, the coloured outline is the type and the flags indicate where each variable points to.\n\nTypes of data\nPython knows various types of data.\nThe four basic ones (not including the collection types) are:\n\ninteger numbers - whole numbers\nfloating point numbers - decimal numbers\nstrings - collections of letters\nbooleans - a binary type that can only have the values True and False\n\nIn the example above, variable weight_kg has an integer value of 60. To create a variable with a floating point value, we can execute:\n\nweight_kg = 60.0\n\nAnd to create a string (as for the variable c in the example above) we simply have to add single or double quotes around some text, for example:\n\nweight_kg_text = \"weight in kilograms:\"\n\n\n\n\n\n\n\nSingle or Double quotes\n\n\n\nTo indicate a string, you need to enclose it in matching single or double quotes. Python will accept both but it’s generally a good idea to use double quotes as if you tried to assign a string with an apostrope in it using single quotes, you will get an error. Give this a try:\n\nmsg = 'All's well'\n\nAs you are much more likely to have apostrope’s in a string than double quotes, it’s best to stick with double quotes for strings.\n\n\n\n\nUsing Variables in Python\nTo display the value of a variable to the screen in Python, we can use the print function as we did before:\n\nprint(weight_kg)\n\n60.0\n\n\nOutput:\n60\nNot that we can display multiple things at once using only one print command:\n\nprint(weight_kg_text, weight_kg)\n\nweight in kilograms: 60.0\n\n\nOutput:\nweight in kilograms: 60\nTo change the value of the weight_kg variable, we have to assign weight_kg a new value using the equals = sign:\n\nweight_kg = 65.0\nprint('weight in kilograms is now:', weight_kg)\n\nweight in kilograms is now: 65.0\n\n\nOutput:\nweight in kilograms is now: 65.0\n\n\n\n\n\n\nThe Difference between Strings and Variables\n\n\n\nWhich of the following would you use to assign the value of the test1 variable to the test2 variable? Note the difference between a string (indicated by quotes) and a variable name (without quotes).\n\ntest2 = \"test1\"\ntest2 = test1\n\"test2\" = test1\n\"test2\" = \"test1\"\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\nNo. This will assign the value \"test1\" to the test2 variable, not the value of the test1 variable\nYes\nNo. This will raise an error as it is trying to change the value of a constant string (\"test2\")\nNo. Same as for 3\n\n\n\n\n\n\n\n\n\n\n\n\nChoosing a Name\n\n\n\nWhich is a better variable name, m, min, or minutes? Why? Hint: think about which code you would rather inherit from someone who is leaving the lab:\n\nts = m * 60 + s\ntot_sec = min * 60 + sec\ntotal_seconds = minutes * 60 + seconds\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nminutes is better because min might mean something like “minimum” (and actually does in Python, but we haven’t seen that yet).\n\n\n\n\n\n\n\nExercise\nHave a go at creating some variables of the three basic types we’ve been looking at: Integer, Floating Point, Boolean and String.\nPrint each out using the print function."
  },
  {
    "objectID": "python_lesson/03-pythonbasics.html#basic-operators",
    "href": "python_lesson/03-pythonbasics.html#basic-operators",
    "title": "Python Basics",
    "section": "Basic Operators",
    "text": "Basic Operators\nWe now know how to create variables to store our data but we don’t know how to manipulate them at the moment. This is done using ‘Operators’.\nOperators are symbols that perform specific operations on one or more objects. A subset of these are the arithmetic operators you’re already familiar with:\n\nMultiplication: a * b\nAddition: a + b\nSubtraction: a - b\nDivision: a / b\n\nFor example, a+b is the addition operator being applied to the objects pointed at by the variables a and b. What operators you can use depends on what the objects you’re applying them to are so some things won’t work - you can’t divide two strings or add a string and a number for example.\n\n\n\n\n\n\nUnder the Hood\n\n\n\nIt’s worth noting that operators in Python are nothing ‘special’ - they can be thought of as basically shorthand for other bits of code. These can range from simple things like numerical addition/subtraction/etc. to concatenation (combining) of two strings or performing the scalar product on matrices.\n\n\n\nOther Operators\nAs well as these basic operators, there are also more language specific ones:\n\nAssignment: a = b\nAddition/Subtraction and assignment: a += b, a -= b\nExponent: a ** b ( e.g. 10**3 = 1000 )\nModulus: % (e.g. 9 % 4 = 1)\nFloor Division: a // b (e.g. 9 // 4 = 2)\nIndexing: []\n\nYou can see that assignment (=) which you’ve already met is just another operator - it will attempt to assign the object or value on the right to the variable on the left. Another of these you will use a lot is the Indexing operator ([]). This is generally used to access elements of collections like getting a single character from a string, e.g.\n\nmy_str = \"TESTING\"\nfirst = my_str[0]\nthird = my_str[2]\n\n\n\nExercises\n\n\n\n\n\n\n\nWhat values do the variables mass and age have after each statement in the following program? Test your answers by executing the commands.\n\n\nmass = 47.5\nage = 122\nmass = mass * 2.0\nage = age - 20\n\n\n\n\n\n\n\n\n\n\n\nIf you assign a = 123, what happens if you try to get the second digit of a via a[1]?\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nNumbers are not stored in the written representation, so they can’t be treated like strings.\na = 123\nprint(a[1])\nOutput:\nTypeError: 'int' object is not subscriptable\nIf you had a string then this would have worked as expected:\n\na = \"123\"\nprint(a[1])\n\n2\n\n\nOutput:\n2\n\n\n\n\n\n\n\n\n\n\n\n\n\nUsing operators in Python Now you know how operators work, try to do the following:\n\n\nCreate two variables, one a float and the other an integer\nPrint the product of these\nWhat happens when you divide a float and an int?\nWhat happens when you divide two ints?\nCreate a string variable and output various letters from it\n\n\n\n\n\n\n\n\n\n\n4 . In-place Operators\nWhat is the value of a and b after the following code is executed? Try it by running this code yourself\n\na = 10\nb = 20\nb += a\nprint(a, b)\n\n10 30\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nOutput:\n10 30\nThe addition and assignment operator (b += a) is shorthand for b = b + a so in this case, the value of a is added to b but a is left unchanged.\n\n\n\n\n\n\n\n\n\n\n\n\nKeypoints:\n\n“Types are how python should interpret data in a memory location (‘object’) and what operations can be performed by it”\n“Objects are defined areas of memory that holds data (‘Values’) associated with a Type”\n“Values are the actual data/bits in memory interpreted by the ‘Type’”\n“Variables are a flag or name for a particular area of memory (‘Object’)”\n“Variable names must only contain letters, numbers and underscores. They are case-sensitive.”\n“You can assign values to a variable using the = operator”\n“The basic (non collection) data types are: integers, floating point numbers, strings and booleans.”\n“Operators are used to perform actions on objects”\n“They have different behavior depending on the objects that are being acted on”\n“There is nothing special about operators - they are just shorthand for running other bits of code”"
  },
  {
    "objectID": "python_lesson/05-listdict.html",
    "href": "python_lesson/05-listdict.html",
    "title": "Data Structures: List and Dictionaries",
    "section": "",
    "text": "We have learn how to store single bits of data in variables but what happens when we have several bits of data that are associated with each other and need to be stored together? For example, a vector, array or list of names? For this we can use the built-in collection types of list and dict (short for dictionary).\nWhat are the Python Data Structures?\nData Structures are a way of organizing data so that it can be accessed more efficiently depending upon the situation. Data Structures are fundamentals of any programming language around which a program is built. For this workshop, we will be learning how to work with two data structures, Lists and Dictionaries. But be advise there are many others such as sets, tuples, string, hashes,and others."
  },
  {
    "objectID": "python_lesson/05-listdict.html#python-basics-lists-and-dictionaries",
    "href": "python_lesson/05-listdict.html#python-basics-lists-and-dictionaries",
    "title": "Data Structures: List and Dictionaries",
    "section": "",
    "text": "We have learn how to store single bits of data in variables but what happens when we have several bits of data that are associated with each other and need to be stored together? For example, a vector, array or list of names? For this we can use the built-in collection types of list and dict (short for dictionary).\nWhat are the Python Data Structures?\nData Structures are a way of organizing data so that it can be accessed more efficiently depending upon the situation. Data Structures are fundamentals of any programming language around which a program is built. For this workshop, we will be learning how to work with two data structures, Lists and Dictionaries. But be advise there are many others such as sets, tuples, string, hashes,and others."
  },
  {
    "objectID": "python_lesson/05-listdict.html#lists",
    "href": "python_lesson/05-listdict.html#lists",
    "title": "Data Structures: List and Dictionaries",
    "section": "Lists",
    "text": "Lists\nWe create a list by putting values inside square brackets and separating the values with commas. Or we can initialize an empty list by using list().\n\n\n\n\n\n\nCode Example:\n\nodds = [1, 3, 5, 7]\nprint('odds are:', odds)\neven = [2, 4, 6, 8]\nprint('even are:', even)\nempty = list()\nprint('empty list:', empty)\n\nodds are: [1, 3, 5, 7]\neven are: [2, 4, 6, 8]\nempty list: []\n\n\n\n\n\n\nIndexing\n\nStarting From Zero\n\n\n\n\n\n\nBase-0 Index\nIt’s very important to remember that Python (like many other languages) indexes it’s collections from zero rather than one. In other words, the first element of list is given by index 0, the second by index 1, etc. Therefore the last element is given by the number of elements in the list minus one, e.g. for the example above, the last element is odds[3].\nProgramming languages like Fortran, MATLAB and R start counting at 1 because that’s what human beings have done for thousands of years. Languages in the C family (including C++, Java, Perl, and Python) count from 0 because it represents an offset from the first value in the array (the second value is offset by one index from the first value). This is closer to the way that computers represent arrays (if you are interested in the historical reasons behind counting indices from zero, you can read Mike Hoye’s blog post).\n\n\n\n\n\n\n\n\n\nCode Example:\n\ndigits=[1,2,3,4,5,6,7,8,9]\nprint(\"digits[0] =\", digits[0])\nprint(\"digits[1] =\", digits[1])\nprint(\"digits[8] =\", digits[8])\n\ndigits[0] = 1\ndigits[1] = 2\ndigits[8] = 9\n\n\n\n\n\n\n\nNegative Indexing\nYou can use negative indices to access elements from the end of the list as well, so the last element would be -1, the penultimate -2, etc.:\n\n\n\n\n\n\nCode Example:\n\ndigits=[1,2,3,4,5,6,7,8,9]\nprint(\"digits[0] =\", digits[0])\nprint(\"digits[-1] =\", digits[-1])\nprint(\"digits[-3] =\", digits[-3])\n\ndigits[0] = 1\ndigits[-1] = 9\ndigits[-3] = 7\n\n\n\n\n\nIt is possible to index strings in a similar way. From the begining using 0 and positive integers or from the end using negative numbers.\n\n\n\n\n\n\nCode Example:\n\nmessage=\"Python uses indexing base zero.\"\nprint(\"message[0] =\", message[0])\nprint(\"message[-1] =\", message[-1])\nprint(\"message[-3] =\", message[-3])\n\nmessage[0] = P\nmessage[-1] = .\nmessage[-3] = r\n\n\n\n\n\n\n\nSlicing Lists\nSubsets of lists and strings can be accessed by specifying ranges of values using a colon to separate the first and last+1 index required in the [] square brackets or indexing operator. This is commonly referred to as “slicing” the list/string.\n\n\n\n\n\n\nCode Example:\n\nbinomial_name = \"Drosophila melanogaster\"\ngroup = binomial_name[0:10]\nprint(\"group:\", group)\n\nspecies = binomial_name[11:24]\nprint(\"species:\", species)\n\nchromosomes = [\"X\", \"Y\", \"2\", \"3\", \"4\"]\nautosomes = chromosomes[2:5]\nprint(\"autosomes:\", autosomes)\n\nlast = chromosomes[-1]\nprint(\"last:\", last)\n\ngroup: Drosophila\nspecies: melanogaster\nautosomes: ['2', '3', '4']\nlast: 4\n\n\n\n\n\n\n\n\nLists are Mutable\nData which can be modified in place is called mutable, while data which cannot be modified is called immutable. Strings and numbers are immutable. This does not mean that variables with string or number values are constants, but when we want to change the value of a string or number variable, we can only replace the old value with a completely new value.\nLists and arrays, on the other hand, are mutable: we can modify them after they have been created. We can change individual elements, append new elements, or reorder the whole list. For some operations, like sorting, we can choose whether to use a function that modifies the data in-place or a function that returns a modified copy and leaves the original unchanged.\n\n\n\n\n\n\nCode Example:\n\nmBros = [\"mario\", \"Luigi\"]\nprint(\"Mario Brothers:\", mBros)\nmBros[0]=\"Mario\"\nprint(\"Mario Brothers(fixed):\", mBros)\n\nMario Brothers: ['mario', 'Luigi']\nMario Brothers(fixed): ['Mario', 'Luigi']\n\n\n\n\n\n\n\n\n\n\n\nTuples: Immutable Lists\n\n\n\nPython offers another one dimentional data structure for multiple values that is immutable, the tuple. Unlike the list that is initialized with [] tuples are initialized using parenthesis (1,2,3) or tuple(1,2,3) for an empty tuple.\n\nmBros = (\"mario\", \"Luigi\")\nprint(\"Mario Brothers:\", mBros)\ntry:\n    mBros[0]=\"Mario\"\nexcept Exception as error:\n    print(\"Error:\", error)\nprint(\"Mario Brothers(not updated):\", mBros)\n\nMario Brothers: ('mario', 'Luigi')\nError: 'tuple' object does not support item assignment\nMario Brothers(not updated): ('mario', 'Luigi')\n\n\n\n\n\n\nHeterogeneous Lists\nLists (and tuples) in Python can contain elements of different types. Example:\n\nsample_ages = [10, 12.5, 'Unknown']\nrow_values = (30, None, True, \"Galileo\")\n\n\n\n\n\n\n\nObject Methods\n\n\n\nThe list, dict and string types are actually more complicated objects than basic numbers. They have certain built-in bits of code that you can run on them. The functions that can be called from the object itself are called object methods. For example:\n\nmy_str = \"Programming is cool\"\nprint(\"What index contains an 'a'?\", my_str.find(\"a\"))\nprint(\"What index contains 'ing'?\", my_str.find(\"ing\"))\n\nWhat index contains an 'a'? 5\nWhat index contains 'ing'? 8\n\n\nThis code asks Python to run the function find on the string object pointed at by the variable my_str.\nThis dotted notation is used everywhere in Python: the object that appears before the dot contains the thing that appears after, a method or an attribute. The str.find method is provided one parameter: the sub-string to look for in the string. This is sent to the code referened by the find method and after this code is run, it return the index of the sub-string (if found) and then continues. You can also have methods where input parameters are optional or not required, for example my_str.split().\n\n\nThere are many ways to change the contents of lists besides assigning new values to individual elements:\n\nodds = [1, 3, 5, 7]\nodds.append(11)\nprint('odds after adding a value:', odds)\n\nodds after adding a value: [1, 3, 5, 7, 11]\n\n\n\ndel odds[0]\nprint('odds after removing the first element:', odds)\n\nodds after removing the first element: [3, 5, 7, 11]\n\n\n\nodds.reverse()\nprint('odds after reversing:', odds)\n\nodds after reversing: [11, 7, 5, 3]\n\n\n\n\n\n\n\n\nObject Refence vs Copy\n\n\n\nWhile modifying in place, it is useful to remember that Python treats lists in a slightly counter-intuitive way.\nIf we make a list and (attempt to) copy it then modify in place, we can cause all sorts of trouble:\n\nodds = [1, 3, 5, 7]\nprimes = odds\nprimes.append(2)\nprint('primes:', primes)\nprint('odds:', odds)\n\nprimes: [1, 3, 5, 7, 2]\nodds: [1, 3, 5, 7, 2]\n\n\nThis is becasue the second variable primes is referencing the same list as odds. To make a copy of the list you can use the copy method:\n\nodds = [1, 3, 5, 7]\nprimes = odds.copy()\nprimes.append(2)\nprint('primes:', primes)\nprint('odds:', odds)\n\nprimes: [1, 3, 5, 7, 2]\nodds: [1, 3, 5, 7]\n\n\nIn this ocasion by using copy we create a new list with the same contents. This however consumes more compute resources and should be avoided when working with big data."
  },
  {
    "objectID": "python_lesson/05-listdict.html#dictionaries",
    "href": "python_lesson/05-listdict.html#dictionaries",
    "title": "Data Structures: List and Dictionaries",
    "section": "Dictionaries",
    "text": "Dictionaries\nIn Python, you can use a type of collection called a Dictionary. Values stored in a dictionary are associated with a key that you can then use to retrieve the value instead of using an index.\nDictionaries are like lists. They both share the following properties:\n\nBoth can be used to store values.\nBoth can be changed in place and can grow and shrink on demand.\nBoth can be nested: a dictionary can contain another dictionary, a list can contain another list, and a list can contain a dictionary and vice versa.\n\nExample of a dictionary:\n\ncat = {'name': 'Tomasina', \n    'age': 5 ,\n    'color': 'white',\n    'breed': 'american shorthair', \n    'diagnosis': 'FIV',}\n\nIn this example the dictionary its called cat. The keys in this dictionary are name, age, breed, color, diagnosis and owner. The value is the object that is mapped to the key, like \"name\":\"Tomasina\"\nIf you need to retrieve the value of a key, you can do the following:\n\ncat['name']\n\n'Tomasina'\n\n\nBy using the key name, you can print out the values of the key.\nYou can use any immutable object as a key (in practice this is generally numbers or strings!) and store any object as the value including lists or other dicts. As with lists, there are several ways to add entries to a dictionary. The easiest of these is to simply reference a new key and assign it a value:\n\ncat['owner'] = 'Leo'\nprint(cat)\n\n{'name': 'Tomasina', 'age': 5, 'color': 'white', 'breed': 'american shorthair', 'diagnosis': 'FIV', 'owner': 'Leo'}\n\n\nThe new key-value pair has been added at the end of the dictionary!\nThe differences between lists and dictionaries is how objects are accessed. A List objects is accessed by position index ([0,1,2…]) while dictionary objects are accessed using keys."
  },
  {
    "objectID": "python_lesson/07-pandasbiopython.html",
    "href": "python_lesson/07-pandasbiopython.html",
    "title": "Python Packages: Pandas and BioPython",
    "section": "",
    "text": "Python has lots of packages that allows you to manipulate data in different ways. For example, Pandas allows you to manipulate dataset with a similar dataframe structure that the language R has.\nPandas is a Python package providing fast, flexible, and expressive data structures designed to make working with “relational” or “labeled” data both easy and intuitive.\nPandas is well suited for many different kinds of data:\n\nTabular data with heterogeneously-typed columns, as in an SQL table or Excel spreadsheet\nOrdered and unordered (not necessarily fixed-frequency) time series data.\nArbitrary matrix data (homogeneously typed or heterogeneous) with row and column labels\nAny other form of observational / statistical data sets. The data need not be labeled at all to be placed into a pandas data structure.\n\nFor today we are going to learn basics commands that will allow us to upload data from a CSV, perform commands that will allow us to get general data from the dataset and filter by column.\n\n\nTo work woth any package in python you have to download it through your package manager (in the case of this workshop would be Conda), and then import it. For this workshop, the conda enviroment already had installed Pandas.\nThe following code will allow you to import the package Pandas to your\n\nimport pandas as pd\n\n\n\n\n\ndf = pd.read_csv('../python_lesson/combined_tidy_vcf.csv')\n\nNote: The directory path were the dataset is located may be in a diferent place than this example.\n\n\n\n\ndf.info()\n\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nRangeIndex: 801 entries, 0 to 800\nData columns (total 29 columns):\n #   Column         Non-Null Count  Dtype  \n---  ------         --------------  -----  \n 0   sample_id      801 non-null    object \n 1   CHROM          801 non-null    object \n 2   POS            801 non-null    int64  \n 3   ID             0 non-null      float64\n 4   REF            801 non-null    object \n 5   ALT            801 non-null    object \n 6   QUAL           801 non-null    float64\n 7   FILTER         0 non-null      float64\n 8   INDEL          801 non-null    bool   \n 9   IDV            101 non-null    float64\n 10  IMF            101 non-null    float64\n 11  DP             801 non-null    int64  \n 12  VDB            801 non-null    float64\n 13  RPB            28 non-null     float64\n 14  MQB            28 non-null     float64\n 15  BQB            28 non-null     float64\n 16  MQSB           753 non-null    float64\n 17  SGB            801 non-null    float64\n 18  MQ0F           801 non-null    float64\n 19  ICB            0 non-null      float64\n 20  HOB            0 non-null      float64\n 21  AC             801 non-null    int64  \n 22  AN             801 non-null    int64  \n 23  DP4            801 non-null    object \n 24  MQ             801 non-null    int64  \n 25  Indiv          801 non-null    object \n 26  gt_PL          801 non-null    object \n 27  gt_GT          801 non-null    int64  \n 28  gt_GT_alleles  801 non-null    object \ndtypes: bool(1), float64(14), int64(6), object(8)\nmemory usage: 176.1+ KB\n\n\n\n\n\n\ndf.head()\n\n\n\n\n\n\n\n\nsample_id\nCHROM\nPOS\nID\nREF\nALT\nQUAL\nFILTER\nINDEL\nIDV\n...\nICB\nHOB\nAC\nAN\nDP4\nMQ\nIndiv\ngt_PL\ngt_GT\ngt_GT_alleles\n\n\n\n\n0\nSRR2584863\nCP000819.1\n9972\nNaN\nT\nG\n91.0\nNaN\nFalse\nNaN\n...\nNaN\nNaN\n1\n1\n0,0,0,4\n60\n/home/dcuser/dc_workshop/results/bam/SRR258486...\n121,0\n1\nG\n\n\n1\nSRR2584863\nCP000819.1\n263235\nNaN\nG\nT\n85.0\nNaN\nFalse\nNaN\n...\nNaN\nNaN\n1\n1\n0,1,0,5\n33\n/home/dcuser/dc_workshop/results/bam/SRR258486...\n112,0\n1\nT\n\n\n2\nSRR2584863\nCP000819.1\n281923\nNaN\nG\nT\n217.0\nNaN\nFalse\nNaN\n...\nNaN\nNaN\n1\n1\n0,0,4,5\n60\n/home/dcuser/dc_workshop/results/bam/SRR258486...\n247,0\n1\nT\n\n\n3\nSRR2584863\nCP000819.1\n433359\nNaN\nCTTTTTTT\nCTTTTTTTT\n64.0\nNaN\nTrue\n12.0\n...\nNaN\nNaN\n1\n1\n0,1,3,8\n60\n/home/dcuser/dc_workshop/results/bam/SRR258486...\n91,0\n1\nCTTTTTTTT\n\n\n4\nSRR2584863\nCP000819.1\n473901\nNaN\nCCGC\nCCGCGC\n228.0\nNaN\nTrue\n9.0\n...\nNaN\nNaN\n1\n1\n1,0,2,7\n60\n/home/dcuser/dc_workshop/results/bam/SRR258486...\n255,0\n1\nCCGCGC\n\n\n\n\n5 rows × 29 columns\n\n\n\n\n\n\n\ndf.tail()\n\n\n\n\n\n\n\n\nsample_id\nCHROM\nPOS\nID\nREF\nALT\nQUAL\nFILTER\nINDEL\nIDV\n...\nICB\nHOB\nAC\nAN\nDP4\nMQ\nIndiv\ngt_PL\ngt_GT\ngt_GT_alleles\n\n\n\n\n796\nSRR2589044\nCP000819.1\n3481820\nNaN\nA\nG\n225.0\nNaN\nFalse\nNaN\n...\nNaN\nNaN\n1\n1\n0,0,4,8\n60\n/home/dcuser/dc_workshop/results/bam/SRR258904...\n255,0\n1\nG\n\n\n797\nSRR2589044\nCP000819.1\n3893550\nNaN\nAG\nAGG\n101.0\nNaN\nTrue\n4.0\n...\nNaN\nNaN\n1\n1\n0,0,3,1\n52\n/home/dcuser/dc_workshop/results/bam/SRR258904...\n131,0\n1\nAGG\n\n\n798\nSRR2589044\nCP000819.1\n3901455\nNaN\nA\nAC\n70.0\nNaN\nTrue\n3.0\n...\nNaN\nNaN\n1\n1\n0,0,3,0\n60\n/home/dcuser/dc_workshop/results/bam/SRR258904...\n100,0\n1\nAC\n\n\n799\nSRR2589044\nCP000819.1\n4100183\nNaN\nA\nG\n177.0\nNaN\nFalse\nNaN\n...\nNaN\nNaN\n1\n1\n0,0,3,5\n60\n/home/dcuser/dc_workshop/results/bam/SRR258904...\n207,0\n1\nG\n\n\n800\nSRR2589044\nCP000819.1\n4431393\nNaN\nTGG\nT\n225.0\nNaN\nTrue\n10.0\n...\nNaN\nNaN\n1\n1\n0,0,4,6\n60\n/home/dcuser/dc_workshop/results/bam/SRR258904...\n255,0\n1\nT\n\n\n\n\n5 rows × 29 columns\n\n\n\n\n\n\n\ndf.columns\n\nIndex(['sample_id', 'CHROM', 'POS', 'ID', 'REF', 'ALT', 'QUAL', 'FILTER',\n       'INDEL', 'IDV', 'IMF', 'DP', 'VDB', 'RPB', 'MQB', 'BQB', 'MQSB', 'SGB',\n       'MQ0F', 'ICB', 'HOB', 'AC', 'AN', 'DP4', 'MQ', 'Indiv', 'gt_PL',\n       'gt_GT', 'gt_GT_alleles'],\n      dtype='object')\n\n\n\n\n\n\ndf.isnull()\n\n\n\n\n\n\n\n\nsample_id\nCHROM\nPOS\nID\nREF\nALT\nQUAL\nFILTER\nINDEL\nIDV\n...\nICB\nHOB\nAC\nAN\nDP4\nMQ\nIndiv\ngt_PL\ngt_GT\ngt_GT_alleles\n\n\n\n\n0\nFalse\nFalse\nFalse\nTrue\nFalse\nFalse\nFalse\nTrue\nFalse\nTrue\n...\nTrue\nTrue\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\n\n\n1\nFalse\nFalse\nFalse\nTrue\nFalse\nFalse\nFalse\nTrue\nFalse\nTrue\n...\nTrue\nTrue\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\n\n\n2\nFalse\nFalse\nFalse\nTrue\nFalse\nFalse\nFalse\nTrue\nFalse\nTrue\n...\nTrue\nTrue\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\n\n\n3\nFalse\nFalse\nFalse\nTrue\nFalse\nFalse\nFalse\nTrue\nFalse\nFalse\n...\nTrue\nTrue\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\n\n\n4\nFalse\nFalse\nFalse\nTrue\nFalse\nFalse\nFalse\nTrue\nFalse\nFalse\n...\nTrue\nTrue\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n796\nFalse\nFalse\nFalse\nTrue\nFalse\nFalse\nFalse\nTrue\nFalse\nTrue\n...\nTrue\nTrue\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\n\n\n797\nFalse\nFalse\nFalse\nTrue\nFalse\nFalse\nFalse\nTrue\nFalse\nFalse\n...\nTrue\nTrue\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\n\n\n798\nFalse\nFalse\nFalse\nTrue\nFalse\nFalse\nFalse\nTrue\nFalse\nFalse\n...\nTrue\nTrue\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\n\n\n799\nFalse\nFalse\nFalse\nTrue\nFalse\nFalse\nFalse\nTrue\nFalse\nTrue\n...\nTrue\nTrue\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\n\n\n800\nFalse\nFalse\nFalse\nTrue\nFalse\nFalse\nFalse\nTrue\nFalse\nFalse\n...\nTrue\nTrue\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\n\n\n\n\n801 rows × 29 columns\n\n\n\n\n\n\n\ndf.isnull().sum()\n\nsample_id          0\nCHROM              0\nPOS                0\nID               801\nREF                0\nALT                0\nQUAL               0\nFILTER           801\nINDEL              0\nIDV              700\nIMF              700\nDP                 0\nVDB                0\nRPB              773\nMQB              773\nBQB              773\nMQSB              48\nSGB                0\nMQ0F               0\nICB              801\nHOB              801\nAC                 0\nAN                 0\nDP4                0\nMQ                 0\nIndiv              0\ngt_PL              0\ngt_GT              0\ngt_GT_alleles      0\ndtype: int64\n\n\n\n\n\n\ndf.loc[df['ALT'].apply(len) &gt;= 5]\n\n\n\n\n\n\n\n\nsample_id\nCHROM\nPOS\nID\nREF\nALT\nQUAL\nFILTER\nINDEL\nIDV\n...\nICB\nHOB\nAC\nAN\nDP4\nMQ\nIndiv\ngt_PL\ngt_GT\ngt_GT_alleles\n\n\n\n\n3\nSRR2584863\nCP000819.1\n433359\nNaN\nCTTTTTTT\nCTTTTTTTT\n64.0000\nNaN\nTrue\n12.0\n...\nNaN\nNaN\n1\n1\n0,1,3,8\n60\n/home/dcuser/dc_workshop/results/bam/SRR258486...\n91,0\n1\nCTTTTTTTT\n\n\n4\nSRR2584863\nCP000819.1\n473901\nNaN\nCCGC\nCCGCGC\n228.0000\nNaN\nTrue\n9.0\n...\nNaN\nNaN\n1\n1\n1,0,2,7\n60\n/home/dcuser/dc_workshop/results/bam/SRR258486...\n255,0\n1\nCCGCGC\n\n\n8\nSRR2584863\nCP000819.1\n2103887\nNaN\nACAGCCAGCCAGCCAGCCAGCCAGCCAGCCAG\nACAGCCAGCCAGCCAGCCAGCCAGCCAGCCAGCCAGCCAGCCAGCC...\n56.0000\nNaN\nTrue\n2.0\n...\nNaN\nNaN\n1\n1\n0,1,1,1\n60\n/home/dcuser/dc_workshop/results/bam/SRR258486...\n111,28\n1\nACAGCCAGCCAGCCAGCCAGCCAGCCAGCCAGCCAGCCAGCCAGCC...\n\n\n49\nSRR2584866\nCP000819.1\n148134\nNaN\nAGGGG\nAGGGGG\n122.0000\nNaN\nTrue\n8.0\n...\nNaN\nNaN\n1\n1\n0,0,3,5\n60\n/home/dcuser/dc_workshop/results/bam/SRR258486...\n152,0\n1\nAGGGGG\n\n\n50\nSRR2584866\nCP000819.1\n157998\nNaN\nGTTTTTTTTT\nGTTTTTTTT\n19.4636\nNaN\nTrue\n6.0\n...\nNaN\nNaN\n1\n1\n0,0,1,5\n60\n/home/dcuser/dc_workshop/results/bam/SRR258486...\n49,0\n1\nGTTTTTTTT\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n722\nSRR2584866\nCP000819.1\n4022380\nNaN\nGTTTTTTTT\nGTTTTTTTTT\n11.1284\nNaN\nTrue\n9.0\n...\nNaN\nNaN\n1\n1\n2,2,3,4\n60\n/home/dcuser/dc_workshop/results/bam/SRR258486...\n39,1\n1\nGTTTTTTTTT\n\n\n723\nSRR2584866\nCP000819.1\n4038529\nNaN\nGTTTTTTTTT\nGTTTTTTTT\n15.0048\nNaN\nTrue\n20.0\n...\nNaN\nNaN\n1\n1\n1,6,8,6\n60\n/home/dcuser/dc_workshop/results/bam/SRR258486...\n42,0\n1\nGTTTTTTTT\n\n\n753\nSRR2584866\nCP000819.1\n4349281\nNaN\nATTTTTTTT\nATTTTTTT\n44.2229\nNaN\nTrue\n9.0\n...\nNaN\nNaN\n1\n1\n0,1,3,7\n60\n/home/dcuser/dc_workshop/results/bam/SRR258486...\n71,0\n1\nATTTTTTT\n\n\n761\nSRR2584866\nCP000819.1\n4392683\nNaN\nACCCC\nACCCCC\n155.0000\nNaN\nTrue\n16.0\n...\nNaN\nNaN\n1\n1\n0,3,8,7\n60\n/home/dcuser/dc_workshop/results/bam/SRR258486...\n182,0\n1\nACCCCC\n\n\n794\nSRR2589044\nCP000819.1\n2103887\nNaN\nACAGCCAGCCAGCCAGCCAGCCAGCCAGCCAG\nACAGCCAGCCAGCCAGCCAGCCAGCCAGCCAGCCAG\n225.0000\nNaN\nTrue\n10.0\n...\nNaN\nNaN\n1\n1\n0,0,1,9\n60\n/home/dcuser/dc_workshop/results/bam/SRR258904...\n255,0\n1\nACAGCCAGCCAGCCAGCCAGCCAGCCAGCCAGCCAG\n\n\n\n\n82 rows × 29 columns"
  },
  {
    "objectID": "python_lesson/07-pandasbiopython.html#pandas",
    "href": "python_lesson/07-pandasbiopython.html#pandas",
    "title": "Python Packages: Pandas and BioPython",
    "section": "",
    "text": "Python has lots of packages that allows you to manipulate data in different ways. For example, Pandas allows you to manipulate dataset with a similar dataframe structure that the language R has.\nPandas is a Python package providing fast, flexible, and expressive data structures designed to make working with “relational” or “labeled” data both easy and intuitive.\nPandas is well suited for many different kinds of data:\n\nTabular data with heterogeneously-typed columns, as in an SQL table or Excel spreadsheet\nOrdered and unordered (not necessarily fixed-frequency) time series data.\nArbitrary matrix data (homogeneously typed or heterogeneous) with row and column labels\nAny other form of observational / statistical data sets. The data need not be labeled at all to be placed into a pandas data structure.\n\nFor today we are going to learn basics commands that will allow us to upload data from a CSV, perform commands that will allow us to get general data from the dataset and filter by column.\n\n\nTo work woth any package in python you have to download it through your package manager (in the case of this workshop would be Conda), and then import it. For this workshop, the conda enviroment already had installed Pandas.\nThe following code will allow you to import the package Pandas to your\n\nimport pandas as pd\n\n\n\n\n\ndf = pd.read_csv('../python_lesson/combined_tidy_vcf.csv')\n\nNote: The directory path were the dataset is located may be in a diferent place than this example.\n\n\n\n\ndf.info()\n\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nRangeIndex: 801 entries, 0 to 800\nData columns (total 29 columns):\n #   Column         Non-Null Count  Dtype  \n---  ------         --------------  -----  \n 0   sample_id      801 non-null    object \n 1   CHROM          801 non-null    object \n 2   POS            801 non-null    int64  \n 3   ID             0 non-null      float64\n 4   REF            801 non-null    object \n 5   ALT            801 non-null    object \n 6   QUAL           801 non-null    float64\n 7   FILTER         0 non-null      float64\n 8   INDEL          801 non-null    bool   \n 9   IDV            101 non-null    float64\n 10  IMF            101 non-null    float64\n 11  DP             801 non-null    int64  \n 12  VDB            801 non-null    float64\n 13  RPB            28 non-null     float64\n 14  MQB            28 non-null     float64\n 15  BQB            28 non-null     float64\n 16  MQSB           753 non-null    float64\n 17  SGB            801 non-null    float64\n 18  MQ0F           801 non-null    float64\n 19  ICB            0 non-null      float64\n 20  HOB            0 non-null      float64\n 21  AC             801 non-null    int64  \n 22  AN             801 non-null    int64  \n 23  DP4            801 non-null    object \n 24  MQ             801 non-null    int64  \n 25  Indiv          801 non-null    object \n 26  gt_PL          801 non-null    object \n 27  gt_GT          801 non-null    int64  \n 28  gt_GT_alleles  801 non-null    object \ndtypes: bool(1), float64(14), int64(6), object(8)\nmemory usage: 176.1+ KB\n\n\n\n\n\n\ndf.head()\n\n\n\n\n\n\n\n\nsample_id\nCHROM\nPOS\nID\nREF\nALT\nQUAL\nFILTER\nINDEL\nIDV\n...\nICB\nHOB\nAC\nAN\nDP4\nMQ\nIndiv\ngt_PL\ngt_GT\ngt_GT_alleles\n\n\n\n\n0\nSRR2584863\nCP000819.1\n9972\nNaN\nT\nG\n91.0\nNaN\nFalse\nNaN\n...\nNaN\nNaN\n1\n1\n0,0,0,4\n60\n/home/dcuser/dc_workshop/results/bam/SRR258486...\n121,0\n1\nG\n\n\n1\nSRR2584863\nCP000819.1\n263235\nNaN\nG\nT\n85.0\nNaN\nFalse\nNaN\n...\nNaN\nNaN\n1\n1\n0,1,0,5\n33\n/home/dcuser/dc_workshop/results/bam/SRR258486...\n112,0\n1\nT\n\n\n2\nSRR2584863\nCP000819.1\n281923\nNaN\nG\nT\n217.0\nNaN\nFalse\nNaN\n...\nNaN\nNaN\n1\n1\n0,0,4,5\n60\n/home/dcuser/dc_workshop/results/bam/SRR258486...\n247,0\n1\nT\n\n\n3\nSRR2584863\nCP000819.1\n433359\nNaN\nCTTTTTTT\nCTTTTTTTT\n64.0\nNaN\nTrue\n12.0\n...\nNaN\nNaN\n1\n1\n0,1,3,8\n60\n/home/dcuser/dc_workshop/results/bam/SRR258486...\n91,0\n1\nCTTTTTTTT\n\n\n4\nSRR2584863\nCP000819.1\n473901\nNaN\nCCGC\nCCGCGC\n228.0\nNaN\nTrue\n9.0\n...\nNaN\nNaN\n1\n1\n1,0,2,7\n60\n/home/dcuser/dc_workshop/results/bam/SRR258486...\n255,0\n1\nCCGCGC\n\n\n\n\n5 rows × 29 columns\n\n\n\n\n\n\n\ndf.tail()\n\n\n\n\n\n\n\n\nsample_id\nCHROM\nPOS\nID\nREF\nALT\nQUAL\nFILTER\nINDEL\nIDV\n...\nICB\nHOB\nAC\nAN\nDP4\nMQ\nIndiv\ngt_PL\ngt_GT\ngt_GT_alleles\n\n\n\n\n796\nSRR2589044\nCP000819.1\n3481820\nNaN\nA\nG\n225.0\nNaN\nFalse\nNaN\n...\nNaN\nNaN\n1\n1\n0,0,4,8\n60\n/home/dcuser/dc_workshop/results/bam/SRR258904...\n255,0\n1\nG\n\n\n797\nSRR2589044\nCP000819.1\n3893550\nNaN\nAG\nAGG\n101.0\nNaN\nTrue\n4.0\n...\nNaN\nNaN\n1\n1\n0,0,3,1\n52\n/home/dcuser/dc_workshop/results/bam/SRR258904...\n131,0\n1\nAGG\n\n\n798\nSRR2589044\nCP000819.1\n3901455\nNaN\nA\nAC\n70.0\nNaN\nTrue\n3.0\n...\nNaN\nNaN\n1\n1\n0,0,3,0\n60\n/home/dcuser/dc_workshop/results/bam/SRR258904...\n100,0\n1\nAC\n\n\n799\nSRR2589044\nCP000819.1\n4100183\nNaN\nA\nG\n177.0\nNaN\nFalse\nNaN\n...\nNaN\nNaN\n1\n1\n0,0,3,5\n60\n/home/dcuser/dc_workshop/results/bam/SRR258904...\n207,0\n1\nG\n\n\n800\nSRR2589044\nCP000819.1\n4431393\nNaN\nTGG\nT\n225.0\nNaN\nTrue\n10.0\n...\nNaN\nNaN\n1\n1\n0,0,4,6\n60\n/home/dcuser/dc_workshop/results/bam/SRR258904...\n255,0\n1\nT\n\n\n\n\n5 rows × 29 columns\n\n\n\n\n\n\n\ndf.columns\n\nIndex(['sample_id', 'CHROM', 'POS', 'ID', 'REF', 'ALT', 'QUAL', 'FILTER',\n       'INDEL', 'IDV', 'IMF', 'DP', 'VDB', 'RPB', 'MQB', 'BQB', 'MQSB', 'SGB',\n       'MQ0F', 'ICB', 'HOB', 'AC', 'AN', 'DP4', 'MQ', 'Indiv', 'gt_PL',\n       'gt_GT', 'gt_GT_alleles'],\n      dtype='object')\n\n\n\n\n\n\ndf.isnull()\n\n\n\n\n\n\n\n\nsample_id\nCHROM\nPOS\nID\nREF\nALT\nQUAL\nFILTER\nINDEL\nIDV\n...\nICB\nHOB\nAC\nAN\nDP4\nMQ\nIndiv\ngt_PL\ngt_GT\ngt_GT_alleles\n\n\n\n\n0\nFalse\nFalse\nFalse\nTrue\nFalse\nFalse\nFalse\nTrue\nFalse\nTrue\n...\nTrue\nTrue\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\n\n\n1\nFalse\nFalse\nFalse\nTrue\nFalse\nFalse\nFalse\nTrue\nFalse\nTrue\n...\nTrue\nTrue\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\n\n\n2\nFalse\nFalse\nFalse\nTrue\nFalse\nFalse\nFalse\nTrue\nFalse\nTrue\n...\nTrue\nTrue\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\n\n\n3\nFalse\nFalse\nFalse\nTrue\nFalse\nFalse\nFalse\nTrue\nFalse\nFalse\n...\nTrue\nTrue\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\n\n\n4\nFalse\nFalse\nFalse\nTrue\nFalse\nFalse\nFalse\nTrue\nFalse\nFalse\n...\nTrue\nTrue\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n796\nFalse\nFalse\nFalse\nTrue\nFalse\nFalse\nFalse\nTrue\nFalse\nTrue\n...\nTrue\nTrue\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\n\n\n797\nFalse\nFalse\nFalse\nTrue\nFalse\nFalse\nFalse\nTrue\nFalse\nFalse\n...\nTrue\nTrue\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\n\n\n798\nFalse\nFalse\nFalse\nTrue\nFalse\nFalse\nFalse\nTrue\nFalse\nFalse\n...\nTrue\nTrue\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\n\n\n799\nFalse\nFalse\nFalse\nTrue\nFalse\nFalse\nFalse\nTrue\nFalse\nTrue\n...\nTrue\nTrue\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\n\n\n800\nFalse\nFalse\nFalse\nTrue\nFalse\nFalse\nFalse\nTrue\nFalse\nFalse\n...\nTrue\nTrue\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\n\n\n\n\n801 rows × 29 columns\n\n\n\n\n\n\n\ndf.isnull().sum()\n\nsample_id          0\nCHROM              0\nPOS                0\nID               801\nREF                0\nALT                0\nQUAL               0\nFILTER           801\nINDEL              0\nIDV              700\nIMF              700\nDP                 0\nVDB                0\nRPB              773\nMQB              773\nBQB              773\nMQSB              48\nSGB                0\nMQ0F               0\nICB              801\nHOB              801\nAC                 0\nAN                 0\nDP4                0\nMQ                 0\nIndiv              0\ngt_PL              0\ngt_GT              0\ngt_GT_alleles      0\ndtype: int64\n\n\n\n\n\n\ndf.loc[df['ALT'].apply(len) &gt;= 5]\n\n\n\n\n\n\n\n\nsample_id\nCHROM\nPOS\nID\nREF\nALT\nQUAL\nFILTER\nINDEL\nIDV\n...\nICB\nHOB\nAC\nAN\nDP4\nMQ\nIndiv\ngt_PL\ngt_GT\ngt_GT_alleles\n\n\n\n\n3\nSRR2584863\nCP000819.1\n433359\nNaN\nCTTTTTTT\nCTTTTTTTT\n64.0000\nNaN\nTrue\n12.0\n...\nNaN\nNaN\n1\n1\n0,1,3,8\n60\n/home/dcuser/dc_workshop/results/bam/SRR258486...\n91,0\n1\nCTTTTTTTT\n\n\n4\nSRR2584863\nCP000819.1\n473901\nNaN\nCCGC\nCCGCGC\n228.0000\nNaN\nTrue\n9.0\n...\nNaN\nNaN\n1\n1\n1,0,2,7\n60\n/home/dcuser/dc_workshop/results/bam/SRR258486...\n255,0\n1\nCCGCGC\n\n\n8\nSRR2584863\nCP000819.1\n2103887\nNaN\nACAGCCAGCCAGCCAGCCAGCCAGCCAGCCAG\nACAGCCAGCCAGCCAGCCAGCCAGCCAGCCAGCCAGCCAGCCAGCC...\n56.0000\nNaN\nTrue\n2.0\n...\nNaN\nNaN\n1\n1\n0,1,1,1\n60\n/home/dcuser/dc_workshop/results/bam/SRR258486...\n111,28\n1\nACAGCCAGCCAGCCAGCCAGCCAGCCAGCCAGCCAGCCAGCCAGCC...\n\n\n49\nSRR2584866\nCP000819.1\n148134\nNaN\nAGGGG\nAGGGGG\n122.0000\nNaN\nTrue\n8.0\n...\nNaN\nNaN\n1\n1\n0,0,3,5\n60\n/home/dcuser/dc_workshop/results/bam/SRR258486...\n152,0\n1\nAGGGGG\n\n\n50\nSRR2584866\nCP000819.1\n157998\nNaN\nGTTTTTTTTT\nGTTTTTTTT\n19.4636\nNaN\nTrue\n6.0\n...\nNaN\nNaN\n1\n1\n0,0,1,5\n60\n/home/dcuser/dc_workshop/results/bam/SRR258486...\n49,0\n1\nGTTTTTTTT\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n722\nSRR2584866\nCP000819.1\n4022380\nNaN\nGTTTTTTTT\nGTTTTTTTTT\n11.1284\nNaN\nTrue\n9.0\n...\nNaN\nNaN\n1\n1\n2,2,3,4\n60\n/home/dcuser/dc_workshop/results/bam/SRR258486...\n39,1\n1\nGTTTTTTTTT\n\n\n723\nSRR2584866\nCP000819.1\n4038529\nNaN\nGTTTTTTTTT\nGTTTTTTTT\n15.0048\nNaN\nTrue\n20.0\n...\nNaN\nNaN\n1\n1\n1,6,8,6\n60\n/home/dcuser/dc_workshop/results/bam/SRR258486...\n42,0\n1\nGTTTTTTTT\n\n\n753\nSRR2584866\nCP000819.1\n4349281\nNaN\nATTTTTTTT\nATTTTTTT\n44.2229\nNaN\nTrue\n9.0\n...\nNaN\nNaN\n1\n1\n0,1,3,7\n60\n/home/dcuser/dc_workshop/results/bam/SRR258486...\n71,0\n1\nATTTTTTT\n\n\n761\nSRR2584866\nCP000819.1\n4392683\nNaN\nACCCC\nACCCCC\n155.0000\nNaN\nTrue\n16.0\n...\nNaN\nNaN\n1\n1\n0,3,8,7\n60\n/home/dcuser/dc_workshop/results/bam/SRR258486...\n182,0\n1\nACCCCC\n\n\n794\nSRR2589044\nCP000819.1\n2103887\nNaN\nACAGCCAGCCAGCCAGCCAGCCAGCCAGCCAG\nACAGCCAGCCAGCCAGCCAGCCAGCCAGCCAGCCAG\n225.0000\nNaN\nTrue\n10.0\n...\nNaN\nNaN\n1\n1\n0,0,1,9\n60\n/home/dcuser/dc_workshop/results/bam/SRR258904...\n255,0\n1\nACAGCCAGCCAGCCAGCCAGCCAGCCAGCCAGCCAG\n\n\n\n\n82 rows × 29 columns"
  },
  {
    "objectID": "python_lesson/07-pandasbiopython.html#biopython",
    "href": "python_lesson/07-pandasbiopython.html#biopython",
    "title": "Python Packages: Pandas and BioPython",
    "section": "BioPython",
    "text": "BioPython\nBioPython is another packages that Python includes.\nIt features include parsers for various Bioinformatics file formats (BLAST, Clustalw, FASTA, Genbank,…), access to online services (NCBI, Expasy,…), interfaces to common and not-so-common programs (Clustalw, DSSP, MSMS…), a standard sequence class, various clustering modules, a KD tree data structure etc. and even documentation.\n\nTo import BioPython Package\n\nfrom Bio import Seq, pairwise2\n\n\n\nGatehring sequences from the dataset we uploaded to pandas\n\nref = df.loc[8]['REF']\nalt = df.loc[8]['ALT']\n\nprint(ref)\nprint(alt)\n\nACAGCCAGCCAGCCAGCCAGCCAGCCAGCCAG\nACAGCCAGCCAGCCAGCCAGCCAGCCAGCCAGCCAGCCAGCCAGCCAGCCAGCCAG\n\n\n\n\nAuto Generate Alignments between the reference and the altered sequence\n\nalignments = pairwise2.align.globalxx(ref,alt)\n\nfor alignment in alignments:\n    print(pairwise2.format_alignment(*alignment))\n\nACAGCCAGCCAGCCAGCCAGCCAGCCAGCCAG------------------------\n||||||||||||||||||||||||||||||||                        \nACAGCCAGCCAGCCAGCCAGCCAGCCAGCCAGCCAGCCAGCCAGCCAGCCAGCCAG\n  Score=32\n\nACAGCCAGCCAGCCAGCCAGCCAGCCAGCCA----G--------------------\n|||||||||||||||||||||||||||||||    |                    \nACAGCCAGCCAGCCAGCCAGCCAGCCAGCCAGCCAGCCAGCCAGCCAGCCAGCCAG\n  Score=32\n\nACAGCCAGCCAGCCAGCCAGCCAGCCAGCC----AG--------------------\n||||||||||||||||||||||||||||||    ||                    \nACAGCCAGCCAGCCAGCCAGCCAGCCAGCCAGCCAGCCAGCCAGCCAGCCAGCCAG\n  Score=32\n\nACAGCCAGCCAGCCAGCCAGCCAGCCAGC---C-AG--------------------\n|||||||||||||||||||||||||||||   | ||                    \nACAGCCAGCCAGCCAGCCAGCCAGCCAGCCAGCCAGCCAGCCAGCCAGCCAGCCAG\n  Score=32\n\nACAGCCAGCCAGCCAGCCAGCCAGCCAG-C--C-AG--------------------\n|||||||||||||||||||||||||||| |  | ||                    \nACAGCCAGCCAGCCAGCCAGCCAGCCAGCCAGCCAGCCAGCCAGCCAGCCAGCCAG\n  Score=32\n\nACAGCCAGCCAGCCAGCCAGCCAGCCAGC----CAG--------------------\n|||||||||||||||||||||||||||||    |||                    \nACAGCCAGCCAGCCAGCCAGCCAGCCAGCCAGCCAGCCAGCCAGCCAGCCAGCCAG\n  Score=32\n\nACAGCCAGCCAGCCAGCCAGCCAGCCAG-C---CAG--------------------\n|||||||||||||||||||||||||||| |   |||                    \nACAGCCAGCCAGCCAGCCAGCCAGCCAGCCAGCCAGCCAGCCAGCCAGCCAGCCAG\n  Score=32\n\nACAGCCAGCCAGCCAGCCAGCCAGCCAG----CCAG--------------------\n||||||||||||||||||||||||||||    ||||                    \nACAGCCAGCCAGCCAGCCAGCCAGCCAGCCAGCCAGCCAGCCAGCCAGCCAGCCAG\n  Score=32\n\nACAGCCAGCCAGCCAGCCAGCCAGCCA----GCCAG--------------------\n|||||||||||||||||||||||||||    |||||                    \nACAGCCAGCCAGCCAGCCAGCCAGCCAGCCAGCCAGCCAGCCAGCCAGCCAGCCAG\n  Score=32\n\nACAGCCAGCCAGCCAGCCAGCCAGCC----AGCCAG--------------------\n||||||||||||||||||||||||||    ||||||                    \nACAGCCAGCCAGCCAGCCAGCCAGCCAGCCAGCCAGCCAGCCAGCCAGCCAGCCAG\n  Score=32\n\nACAGCCAGCCAGCCAGCCAGCCAGC---C-AGCCAG--------------------\n|||||||||||||||||||||||||   | ||||||                    \nACAGCCAGCCAGCCAGCCAGCCAGCCAGCCAGCCAGCCAGCCAGCCAGCCAGCCAG\n  Score=32\n\nACAGCCAGCCAGCCAGCCAGCCAG-C--C-AGCCAG--------------------\n|||||||||||||||||||||||| |  | ||||||                    \nACAGCCAGCCAGCCAGCCAGCCAGCCAGCCAGCCAGCCAGCCAGCCAGCCAGCCAG\n  Score=32\n\nACAGCCAGCCAGCCAGCCAGCCAGC----CAGCCAG--------------------\n|||||||||||||||||||||||||    |||||||                    \nACAGCCAGCCAGCCAGCCAGCCAGCCAGCCAGCCAGCCAGCCAGCCAGCCAGCCAG\n  Score=32\n\nACAGCCAGCCAGCCAGCCAGCCAG-C---CAGCCAG--------------------\n|||||||||||||||||||||||| |   |||||||                    \nACAGCCAGCCAGCCAGCCAGCCAGCCAGCCAGCCAGCCAGCCAGCCAGCCAGCCAG\n  Score=32\n\nACAGCCAGCCAGCCAGCCAGCCAG----CCAGCCAG--------------------\n||||||||||||||||||||||||    ||||||||                    \nACAGCCAGCCAGCCAGCCAGCCAGCCAGCCAGCCAGCCAGCCAGCCAGCCAGCCAG\n  Score=32\n\nACAGCCAGCCAGCCAGCCAGCCA----GCCAGCCAG--------------------\n|||||||||||||||||||||||    |||||||||                    \nACAGCCAGCCAGCCAGCCAGCCAGCCAGCCAGCCAGCCAGCCAGCCAGCCAGCCAG\n  Score=32\n\nACAGCCAGCCAGCCAGCCAGCC----AGCCAGCCAG--------------------\n||||||||||||||||||||||    ||||||||||                    \nACAGCCAGCCAGCCAGCCAGCCAGCCAGCCAGCCAGCCAGCCAGCCAGCCAGCCAG\n  Score=32\n\nACAGCCAGCCAGCCAGCCAGC---C-AGCCAGCCAG--------------------\n|||||||||||||||||||||   | ||||||||||                    \nACAGCCAGCCAGCCAGCCAGCCAGCCAGCCAGCCAGCCAGCCAGCCAGCCAGCCAG\n  Score=32\n\nACAGCCAGCCAGCCAGCCAG-C--C-AGCCAGCCAG--------------------\n|||||||||||||||||||| |  | ||||||||||                    \nACAGCCAGCCAGCCAGCCAGCCAGCCAGCCAGCCAGCCAGCCAGCCAGCCAGCCAG\n  Score=32\n\nACAGCCAGCCAGCCAGCCAGC----CAGCCAGCCAG--------------------\n|||||||||||||||||||||    |||||||||||                    \nACAGCCAGCCAGCCAGCCAGCCAGCCAGCCAGCCAGCCAGCCAGCCAGCCAGCCAG\n  Score=32\n\nACAGCCAGCCAGCCAGCCAG-C---CAGCCAGCCAG--------------------\n|||||||||||||||||||| |   |||||||||||                    \nACAGCCAGCCAGCCAGCCAGCCAGCCAGCCAGCCAGCCAGCCAGCCAGCCAGCCAG\n  Score=32\n\nACAGCCAGCCAGCCAGCCAG----CCAGCCAGCCAG--------------------\n||||||||||||||||||||    ||||||||||||                    \nACAGCCAGCCAGCCAGCCAGCCAGCCAGCCAGCCAGCCAGCCAGCCAGCCAGCCAG\n  Score=32\n\nACAGCCAGCCAGCCAGCCA----GCCAGCCAGCCAG--------------------\n|||||||||||||||||||    |||||||||||||                    \nACAGCCAGCCAGCCAGCCAGCCAGCCAGCCAGCCAGCCAGCCAGCCAGCCAGCCAG\n  Score=32\n\nACAGCCAGCCAGCCAGCC----AGCCAGCCAGCCAG--------------------\n||||||||||||||||||    ||||||||||||||                    \nACAGCCAGCCAGCCAGCCAGCCAGCCAGCCAGCCAGCCAGCCAGCCAGCCAGCCAG\n  Score=32\n\nACAGCCAGCCAGCCAGC---C-AGCCAGCCAGCCAG--------------------\n|||||||||||||||||   | ||||||||||||||                    \nACAGCCAGCCAGCCAGCCAGCCAGCCAGCCAGCCAGCCAGCCAGCCAGCCAGCCAG\n  Score=32\n\nACAGCCAGCCAGCCAG-C--C-AGCCAGCCAGCCAG--------------------\n|||||||||||||||| |  | ||||||||||||||                    \nACAGCCAGCCAGCCAGCCAGCCAGCCAGCCAGCCAGCCAGCCAGCCAGCCAGCCAG\n  Score=32\n\nACAGCCAGCCAGCCAGC----CAGCCAGCCAGCCAG--------------------\n|||||||||||||||||    |||||||||||||||                    \nACAGCCAGCCAGCCAGCCAGCCAGCCAGCCAGCCAGCCAGCCAGCCAGCCAGCCAG\n  Score=32\n\nACAGCCAGCCAGCCAG-C---CAGCCAGCCAGCCAG--------------------\n|||||||||||||||| |   |||||||||||||||                    \nACAGCCAGCCAGCCAGCCAGCCAGCCAGCCAGCCAGCCAGCCAGCCAGCCAGCCAG\n  Score=32\n\nACAGCCAGCCAGCCAG----CCAGCCAGCCAGCCAG--------------------\n||||||||||||||||    ||||||||||||||||                    \nACAGCCAGCCAGCCAGCCAGCCAGCCAGCCAGCCAGCCAGCCAGCCAGCCAGCCAG\n  Score=32\n\nACAGCCAGCCAGCCA----GCCAGCCAGCCAGCCAG--------------------\n|||||||||||||||    |||||||||||||||||                    \nACAGCCAGCCAGCCAGCCAGCCAGCCAGCCAGCCAGCCAGCCAGCCAGCCAGCCAG\n  Score=32\n\nACAGCCAGCCAGCC----AGCCAGCCAGCCAGCCAG--------------------\n||||||||||||||    ||||||||||||||||||                    \nACAGCCAGCCAGCCAGCCAGCCAGCCAGCCAGCCAGCCAGCCAGCCAGCCAGCCAG\n  Score=32\n\nACAGCCAGCCAGC---C-AGCCAGCCAGCCAGCCAG--------------------\n|||||||||||||   | ||||||||||||||||||                    \nACAGCCAGCCAGCCAGCCAGCCAGCCAGCCAGCCAGCCAGCCAGCCAGCCAGCCAG\n  Score=32\n\nACAGCCAGCCAG-C--C-AGCCAGCCAGCCAGCCAG--------------------\n|||||||||||| |  | ||||||||||||||||||                    \nACAGCCAGCCAGCCAGCCAGCCAGCCAGCCAGCCAGCCAGCCAGCCAGCCAGCCAG\n  Score=32\n\nACAGCCAGCCAGC----CAGCCAGCCAGCCAGCCAG--------------------\n|||||||||||||    |||||||||||||||||||                    \nACAGCCAGCCAGCCAGCCAGCCAGCCAGCCAGCCAGCCAGCCAGCCAGCCAGCCAG\n  Score=32\n\nACAGCCAGCCAG-C---CAGCCAGCCAGCCAGCCAG--------------------\n|||||||||||| |   |||||||||||||||||||                    \nACAGCCAGCCAGCCAGCCAGCCAGCCAGCCAGCCAGCCAGCCAGCCAGCCAGCCAG\n  Score=32\n\nACAGCCAGCCAG----CCAGCCAGCCAGCCAGCCAG--------------------\n||||||||||||    ||||||||||||||||||||                    \nACAGCCAGCCAGCCAGCCAGCCAGCCAGCCAGCCAGCCAGCCAGCCAGCCAGCCAG\n  Score=32\n\nACAGCCAGCCA----GCCAGCCAGCCAGCCAGCCAG--------------------\n|||||||||||    |||||||||||||||||||||                    \nACAGCCAGCCAGCCAGCCAGCCAGCCAGCCAGCCAGCCAGCCAGCCAGCCAGCCAG\n  Score=32\n\nACAGCCAGCC----AGCCAGCCAGCCAGCCAGCCAG--------------------\n||||||||||    ||||||||||||||||||||||                    \nACAGCCAGCCAGCCAGCCAGCCAGCCAGCCAGCCAGCCAGCCAGCCAGCCAGCCAG\n  Score=32\n\nACAGCCAGC---C-AGCCAGCCAGCCAGCCAGCCAG--------------------\n|||||||||   | ||||||||||||||||||||||                    \nACAGCCAGCCAGCCAGCCAGCCAGCCAGCCAGCCAGCCAGCCAGCCAGCCAGCCAG\n  Score=32\n\nACAGCCAG-C--C-AGCCAGCCAGCCAGCCAGCCAG--------------------\n|||||||| |  | ||||||||||||||||||||||                    \nACAGCCAGCCAGCCAGCCAGCCAGCCAGCCAGCCAGCCAGCCAGCCAGCCAGCCAG\n  Score=32\n\nACAGCCAGC----CAGCCAGCCAGCCAGCCAGCCAG--------------------\n|||||||||    |||||||||||||||||||||||                    \nACAGCCAGCCAGCCAGCCAGCCAGCCAGCCAGCCAGCCAGCCAGCCAGCCAGCCAG\n  Score=32\n\nACAGCCAG-C---CAGCCAGCCAGCCAGCCAGCCAG--------------------\n|||||||| |   |||||||||||||||||||||||                    \nACAGCCAGCCAGCCAGCCAGCCAGCCAGCCAGCCAGCCAGCCAGCCAGCCAGCCAG\n  Score=32\n\nACAGCCAG----CCAGCCAGCCAGCCAGCCAGCCAG--------------------\n||||||||    ||||||||||||||||||||||||                    \nACAGCCAGCCAGCCAGCCAGCCAGCCAGCCAGCCAGCCAGCCAGCCAGCCAGCCAG\n  Score=32\n\nACAGCCA----GCCAGCCAGCCAGCCAGCCAGCCAG--------------------\n|||||||    |||||||||||||||||||||||||                    \nACAGCCAGCCAGCCAGCCAGCCAGCCAGCCAGCCAGCCAGCCAGCCAGCCAGCCAG\n  Score=32\n\nACAGCC----AGCCAGCCAGCCAGCCAGCCAGCCAG--------------------\n||||||    ||||||||||||||||||||||||||                    \nACAGCCAGCCAGCCAGCCAGCCAGCCAGCCAGCCAGCCAGCCAGCCAGCCAGCCAG\n  Score=32\n\nACAGC---C-AGCCAGCCAGCCAGCCAGCCAGCCAG--------------------\n|||||   | ||||||||||||||||||||||||||                    \nACAGCCAGCCAGCCAGCCAGCCAGCCAGCCAGCCAGCCAGCCAGCCAGCCAGCCAG\n  Score=32\n\nACAG-C--C-AGCCAGCCAGCCAGCCAGCCAGCCAG--------------------\n|||| |  | ||||||||||||||||||||||||||                    \nACAGCCAGCCAGCCAGCCAGCCAGCCAGCCAGCCAGCCAGCCAGCCAGCCAGCCAG\n  Score=32\n\nACAGC----CAGCCAGCCAGCCAGCCAGCCAGCCAG--------------------\n|||||    |||||||||||||||||||||||||||                    \nACAGCCAGCCAGCCAGCCAGCCAGCCAGCCAGCCAGCCAGCCAGCCAGCCAGCCAG\n  Score=32\n\nACAG-C---CAGCCAGCCAGCCAGCCAGCCAGCCAG--------------------\n|||| |   |||||||||||||||||||||||||||                    \nACAGCCAGCCAGCCAGCCAGCCAGCCAGCCAGCCAGCCAGCCAGCCAGCCAGCCAG\n  Score=32\n\nACAG----CCAGCCAGCCAGCCAGCCAGCCAGCCAG--------------------\n||||    ||||||||||||||||||||||||||||                    \nACAGCCAGCCAGCCAGCCAGCCAGCCAGCCAGCCAGCCAGCCAGCCAGCCAGCCAG\n  Score=32\n\nACA----GCCAGCCAGCCAGCCAGCCAGCCAGCCAG--------------------\n|||    |||||||||||||||||||||||||||||                    \nACAGCCAGCCAGCCAGCCAGCCAGCCAGCCAGCCAGCCAGCCAGCCAGCCAGCCAG\n  Score=32\n\nAC----AGCCAGCCAGCCAGCCAGCCAGCCAGCCAG--------------------\n||    ||||||||||||||||||||||||||||||                    \nACAGCCAGCCAGCCAGCCAGCCAGCCAGCCAGCCAGCCAGCCAGCCAGCCAGCCAG\n  Score=32\n\nA---C-AGCCAGCCAGCCAGCCAGCCAGCCAGCCAG--------------------\n|   | ||||||||||||||||||||||||||||||                    \nACAGCCAGCCAGCCAGCCAGCCAGCCAGCCAGCCAGCCAGCCAGCCAGCCAGCCAG\n  Score=32\n\n--A-C-AGCCAGCCAGCCAGCCAGCCAGCCAGCCAG--------------------\n  | | ||||||||||||||||||||||||||||||                    \nACAGCCAGCCAGCCAGCCAGCCAGCCAGCCAGCCAGCCAGCCAGCCAGCCAGCCAG\n  Score=32\n\nA----CAGCCAGCCAGCCAGCCAGCCAGCCAGCCAG--------------------\n|    |||||||||||||||||||||||||||||||                    \nACAGCCAGCCAGCCAGCCAGCCAGCCAGCCAGCCAGCCAGCCAGCCAGCCAGCCAG\n  Score=32\n\n--A--CAGCCAGCCAGCCAGCCAGCCAGCCAGCCAG--------------------\n  |  |||||||||||||||||||||||||||||||                    \nACAGCCAGCCAGCCAGCCAGCCAGCCAGCCAGCCAGCCAGCCAGCCAGCCAGCCAG\n  Score=32"
  },
  {
    "objectID": "r_lesson/01-r-basics.html",
    "href": "r_lesson/01-r-basics.html",
    "title": "R Basics I - objects, functions, vectors",
    "section": "",
    "text": "The console is an interactive environment for RStudio, click on the “Console” pane, type 3 + 3 and press enter. R displays the result of the calculation.\n\n3 + 3\n\n[1] 6\n\n\n+ is called an operator. R has the operators you would expect for for basic mathematics:\nArithmetic operators\n\n\n\noperator\nmeaning\n\n\n\n\n+\nplus\n\n\n-\nminus\n\n\n*\ntimes\n\n\n/\ndivided by\n\n\n^\nexponent\n\n\n\nLogical Operators\n\n\n\noperator\nmeaning\n\n\n\n\n==\nexactly equal\n\n\n!=\nnot equal to\n\n\n&lt;\nless than\n\n\n&lt;=\nless than or equal to\n\n\n&gt;\ngreater than\n\n\n&gt;=\ngreater than or equal to\n\n\nx|y\nx or y\n\n\nx&y\nx and y\n\n\n!x\nnot x\n\n\n\nSpaces can be used to make code easier to read, but are not required.\n\n2 * 2 == 4\n\n[1] TRUE"
  },
  {
    "objectID": "r_lesson/01-r-basics.html#working-in-the-console",
    "href": "r_lesson/01-r-basics.html#working-in-the-console",
    "title": "R Basics I - objects, functions, vectors",
    "section": "",
    "text": "The console is an interactive environment for RStudio, click on the “Console” pane, type 3 + 3 and press enter. R displays the result of the calculation.\n\n3 + 3\n\n[1] 6\n\n\n+ is called an operator. R has the operators you would expect for for basic mathematics:\nArithmetic operators\n\n\n\noperator\nmeaning\n\n\n\n\n+\nplus\n\n\n-\nminus\n\n\n*\ntimes\n\n\n/\ndivided by\n\n\n^\nexponent\n\n\n\nLogical Operators\n\n\n\noperator\nmeaning\n\n\n\n\n==\nexactly equal\n\n\n!=\nnot equal to\n\n\n&lt;\nless than\n\n\n&lt;=\nless than or equal to\n\n\n&gt;\ngreater than\n\n\n&gt;=\ngreater than or equal to\n\n\nx|y\nx or y\n\n\nx&y\nx and y\n\n\n!x\nnot x\n\n\n\nSpaces can be used to make code easier to read, but are not required.\n\n2 * 2 == 4\n\n[1] TRUE"
  },
  {
    "objectID": "r_lesson/01-r-basics.html#objects",
    "href": "r_lesson/01-r-basics.html#objects",
    "title": "R Basics I - objects, functions, vectors",
    "section": "Objects",
    "text": "Objects\n\nCreating Objects\nWhen you have certain values, data, plots, etc that you want to work with You can create objects (make assignments) in R with the assignment operator &lt;-:\nAll R statements where you create objects, assignment statements, have the same form:\nobject_name &lt;- value\nWhen reading that code say “object name gets value” in your head.\n\nx &lt;- 3 * 4\n\nx\n\n[1] 12\n\n\nOnce you have an object you can do other calculations with it.\n\nx * x\n\n[1] 144\n\n\n\n\n\n\n\n\nNote\n\n\n\nObjects vs. Variables What are known as objects in R are known as variables in many other programming languages. Depending on the context, object and variable can have drastically different meanings. However, in this lesson, the two words are used synonymously. For more information see: https://cran.r-project.org/doc/manuals/r-release/R-lang.html#Objects\n\n\nWe can store all kinds of information as objects. For example:\n\nhuman_chr_number &lt;- 23\ngene_name &lt;- 'pten'\nhuman_diploid_chr_num &lt;-  2 * human_chr_number\n\nOnce an object has a value, you can change that value by overwriting it. R will not give you a warning or error if you overwrite an object, which may or may not be a good thing depending on how you look at it.\n\n# gene_name has the value 'pten'\n# We will now assign the new value 'tp53'\ngene_name &lt;- 'tp53'\n\nYou can see the value assigned to an object in the RStudio environment pane, or you can run a line of code that has only an object name, and R will normally display the contents of that object in the console\nYou can also remove an object from R’s memory entirely with the rm() function.\n\n# delete the object 'gene_name'\nrm(gene_name)\n\nNow, if we try to print that object we are told the object no longer exists.\nYou will make lots of assignments and &lt;- is a pain to type. Avoid the temptation to use =: it will work, but it will cause confusion later. Instead, use RStudio’s keyboard shortcut: Alt + - (the minus sign).\nNotice that RStudio automagically surrounds &lt;- with spaces, which is a good code formatting practice. Code is miserable to read on a good day, so giveyoureyesabreak and use spaces.\n\n\n\n\n\n\nNaming Objects\n\n\n\nThe name for objects must start with a letter, and can only contain letters, numbers, underscores (_)and periods (.). The name of the object should describe what is being assigned so they typically will be multiple words. One convention used is snake_case where lowercase words are separated with _. Another popular style is camelCase where compound words or phrases are written so that each word or abbreviation in the middle of the phrase begins with a capital letter, with no intervening spaces or punctuation and the first letter is lowercase.\nthisIsCamelCase\nsome_use_snake_case\nothers.use.periods                  #avoid\nOthers_pRefer.to_RENOUNCEconvention #avoid"
  },
  {
    "objectID": "r_lesson/01-r-basics.html#functions-and-their-arguments",
    "href": "r_lesson/01-r-basics.html#functions-and-their-arguments",
    "title": "R Basics I - objects, functions, vectors",
    "section": "Functions and their arguments",
    "text": "Functions and their arguments\nFunctions are “canned scripts” that automate more complicated sets of commands. Many functions are predefined, or can be made available by importing R packages (more on that later). A function usually gets one or more inputs called arguments. Functions often (but not always) return a value.\nA typical example would be the function round(). The input (the argument) must be a number, and the return value (in fact, the output) is that number rounded to the nearest whole number. Executing a function (‘running it’) is called calling the function. You can save the output of a function to an object. The format would look like:\n\nb &lt;- round(a)\n\nHere, the value of a is given to the round() function, the round() function rounds the number, and returns the value which is then assigned to the object b.\nThe return ‘value’ of a function need not be numerical (like that of sqrt()), and it also does not need to be a single item: it can be a set of things, or even a dataset. We’ll see that when we read data files into R.\nArguments can be anything, not only numbers or filenames, but also other objects. Exactly what each argument means differs per function, and must be looked up in the documentation (see below). Some functions take arguments which may either be specified by the user, or, if left out, take on a default value: these are called options. Options are typically used to alter the way the function operates, such as whether it ignores ‘bad values’, or what symbol to use in a plot. However, if you want something specific, you can specify a value of your choice which will be used instead of the default.\nround() only needs one argument, a number, or object that is storing a numerical value.\n\nround(3.14159)\n\n[1] 3\n\n\nor\n\npi &lt;- 3.14159\n\nround(pi)\n\n[1] 3\n\n\nThe default action of the function is to round to the nearest whole number. If we want more digits we can see how to do that by getting information about the round function. We can use args(round) or look at the help for this function using ?round.\n\nargs(round)\n\nfunction (x, digits = 0) \nNULL\n\n\nWe see that if we want a different number of digits, we can type digits=2 or however many we want.\n\nround(pi, digits = 2)\n\n[1] 3.14\n\n\nIf you provide the arguments in the exact same order as they are defined you don’t have to name them:\n\nround(pi, 2)\n\n[1] 3.14\n\n\nAnd if you do name the arguments, you can switch their order:\n\nround(digits = 2, x = pi)\n\n[1] 3.14\n\n\nIt’s good practice to put the non-optional arguments (like the number you’re rounding) first in your function call, and to specify the names of all optional arguments. If you don’t, someone reading your code might have to look up the definition of a function with unfamiliar arguments to understand what you’re doing.\n\nGetting Help\nIn the previous example we looked up the arguments to round() using args(round) alternatively we could’ve looked at the help page for round() to find this out with ?round. To get help about a particular package or function you can access the help pane in RStudio and type its name in the search box.\n\n\n\n\n\n\n\n\n\nThe help() function and ? help operator in R provide access to the documentation pages for R functions, data sets, and other objects, both for packages in the standard R distribution and for contributed packages. To do so type as follows\nhelp({function})\nhelp(package = {package name})\n\n?{function}\n?\"{package name}\"\n\n\n\n\n\n\nExercise\n\n\n\nLook at the documentation for the seq function. What does seq do? Give an example of using seq with either the by or length.out argument."
  },
  {
    "objectID": "r_lesson/01-r-basics.html#packages",
    "href": "r_lesson/01-r-basics.html#packages",
    "title": "R Basics I - objects, functions, vectors",
    "section": "Packages",
    "text": "Packages\nWhile you can write your own functions, most functions you use will be part of a package. In R, the fundamental unit of shareable code is the package. A package bundles together code, data, documentation, and tests, and is easy to share with others. As of July 2018, there were over 14,000 packages available on the Comprehensive R Archive Network, or CRAN, the public clearing house for R packages. This huge variety of packages is one of the reasons that R is so successful.\nInstalling a package using RStudio requires selecting the Install Packages Button in the Files, Plots, Packages Pane\n\n\n\n\n\n\n\n\n\nIn the pop up box that results simply type the name of the package and check “install dependencies” and click Install\n\n\n\n\n\n\n\n\n\nIts also possible for you to install and load packages from the console. Always make sure to put the package name in quotes when installing and setting dependencies = True\n\ninstall.packages(\"tidyverse\", dependencies = TRUE)    \nlibrary(tidyverse)\n\nYou only need to install a package once, but you need to reload it every time you start a new session."
  },
  {
    "objectID": "r_lesson/01-r-basics.html#vectors",
    "href": "r_lesson/01-r-basics.html#vectors",
    "title": "R Basics I - objects, functions, vectors",
    "section": "Vectors",
    "text": "Vectors\nVectors are probably the most used commonly used object type in R. “Vector” means different things in different fields (mathematics, geometry, biology), but in R a vector is a collection of values that are all of the same type (numbers, characters, etc.).\n\n\n\n\n\n\nData Types\n\n\n\nThere are numerous data types. Some of the other most common data types you will encounter are numeric data, character data and logical data. Vectors of one data type only are called atomic vectors. Read more about vectors and data types in the book R for Data Science\n\n\nOne of the most common ways to create a vector is to use the c() function - the “concatenate” or “combine” function. Inside the function you may enter one or more values; for multiple values, separate each value with a comma:\n\n# Create the SNP gene name vector\n\nsnp_genes &lt;- c(\"OXTR\", \"ACTN3\", \"AR\", \"OPRM1\")\n\nVectors always have a mode and a length. You can check these with the mode() and length() functions respectively. Another useful function that gives both of these pieces of information is the str() (structure) function.\n\n# Check the mode, length, and structure of 'snp_genes'\nmode(snp_genes)\n\n[1] \"character\"\n\nlength(snp_genes)\n\n[1] 4\n\nstr(snp_genes)\n\n chr [1:4] \"OXTR\" \"ACTN3\" \"AR\" \"OPRM1\"\n\n\nVectors are quite important in R. Another data type that we will work with later in this lesson, data frames, are collections of vectors. What we learn here about vectors will pay off even more when we start working with data frames."
  },
  {
    "objectID": "r_lesson/01-r-basics.html#creating-and-subsetting-vectors",
    "href": "r_lesson/01-r-basics.html#creating-and-subsetting-vectors",
    "title": "R Basics I - objects, functions, vectors",
    "section": "Creating and subsetting vectors",
    "text": "Creating and subsetting vectors\nLet’s create a few more vectors to play around with:\n\n# Some interesting human SNPs\n# while accuracy is important, typos in the data won't hurt you here\n\nsnps &lt;- c(\"rs53576\", \"rs1815739\", \"rs6152\", \"rs1799971\")\nsnp_chromosomes &lt;- c(\"3\", \"11\", \"X\", \"6\")\nsnp_positions &lt;- c(8762685, 66560624, 67545785, 154039662)\n\nOnce we have vectors, one thing we may want to do is specifically retrieve one or more values from our vector. To do so, we use bracket notation. We type the name of the vector followed by square brackets. In those square brackets we place the index (e.g. a number) in that bracket as follows:\n\n# get the 3rd value in the snp vector\nsnps[3]\n\n[1] \"rs6152\"\n\n\nIn R, every item your vector is indexed, starting from the first item (1) through to the final number of items in your vector. You can also retrieve a range of numbers:\n\n# get the 1st through 3rd value in the snp vector\n\nsnps[1:3]\n\n[1] \"rs53576\"   \"rs1815739\" \"rs6152\"   \n\n\nIf you want to retrieve several (but not necessarily sequential) items from a vector, you pass a vector of indices; a vector that has the numbered positions you wish to retrieve.\n\n# get the 1st, 3rd, and 4th value in the snp vector\n\nsnps[c(1, 3, 4)]\n\n[1] \"rs53576\"   \"rs6152\"    \"rs1799971\"\n\n\nThere are additional (and perhaps less commonly used) ways of subsetting a vector (see these examples.\nAlso, several of these subsetting expressions can be combined:\n\n# get the 1st through the 3rd value, and 4th value in the snp vector\n# yes, this is a little silly in a vector of only 4 values.\nsnps[c(1:3,4)]\n\n[1] \"rs53576\"   \"rs1815739\" \"rs6152\"    \"rs1799971\""
  },
  {
    "objectID": "r_lesson/01-r-basics.html#adding-to-removing-or-replacing-values-in-existing-vectors",
    "href": "r_lesson/01-r-basics.html#adding-to-removing-or-replacing-values-in-existing-vectors",
    "title": "R Basics I - objects, functions, vectors",
    "section": "Adding to, removing, or replacing values in existing vectors",
    "text": "Adding to, removing, or replacing values in existing vectors\nOnce you have an existing vector, you may want to add a new item to it. To do so, you can use the c() function again to add your new value:\n\n# add the gene \"CYP1A1\" and \"APOA5\" to our list of snp genes\n# this overwrites our existing vector\nsnp_genes &lt;- c(snp_genes, \"CYP1A1\", \"APOA5\")\n\nWe can verify that “snp_genes” contains the new gene entry\n\nsnp_genes\n\n[1] \"OXTR\"   \"ACTN3\"  \"AR\"     \"OPRM1\"  \"CYP1A1\" \"APOA5\" \n\n\nUsing a negative index will return a version of a vector with that index’s value removed:\n\nsnp_genes[-6]\n\n[1] \"OXTR\"   \"ACTN3\"  \"AR\"     \"OPRM1\"  \"CYP1A1\"\n\n\nWe can remove that value from our vector by overwriting it with this expression:\n\nsnp_genes &lt;- snp_genes[-6]\nsnp_genes\n\n[1] \"OXTR\"   \"ACTN3\"  \"AR\"     \"OPRM1\"  \"CYP1A1\"\n\n\nWe can also explicitly rename or add a value to our index using double bracket notation:\n\nsnp_genes[6]&lt;- \"APOA5\"\nsnp_genes\n\n[1] \"OXTR\"   \"ACTN3\"  \"AR\"     \"OPRM1\"  \"CYP1A1\" \"APOA5\" \n\n\n\n\n\n\n\n\nExercise: Examining and subsetting vectors\n\n\n\nAnswer the following questions to test your knowledge of vectors\nWhich of the following are true of vectors in R? A) All vectors have a mode or a length\nB) All vectors have a mode and a length\nC) Vectors may have different lengths\nD) Items within a vector may be of different modes\nE) You can use the c() to add one or more items to an existing vector\nF) You can use the c() to add a vector to an existing vector\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\nFalse - Vectors have both of these properties\n\nTrue\n\nTrue\n\nFalse - Vectors have only one mode (e.g. numeric, character); all items in\na vector must be of this mode.\nTrue\n\nTrue"
  },
  {
    "objectID": "r_lesson/01-r-basics.html#logical-subsetting",
    "href": "r_lesson/01-r-basics.html#logical-subsetting",
    "title": "R Basics I - objects, functions, vectors",
    "section": "Logical Subsetting",
    "text": "Logical Subsetting\nThere is one last set of cool subsetting capabilities we want to introduce. It is possible within R to retrieve items in a vector based on a logical evaluation or numerical comparison. For example, let’s say we wanted get all of the SNPs in our vector of SNP positions that were greater than 100,000,000. We could index using the ‘&gt;’ (greater than) logical operator:\n\nsnp_positions[snp_positions &gt; 100000000]\n\n[1] 154039662\n\n\nIn the square brackets you place the name of the vector followed by the comparison operator and (in this case) a numeric value. Some of the most common logical operators you will use in R are:\n\n\n\nOperator\nDescription\n\n\n\n\n&lt;\nless than\n\n\n&lt;=\nless than or equal to\n\n\n&gt;\ngreater than\n\n\n&gt;=\ngreater than or equal to\n\n\n==\nexactly equal to\n\n\n!=\nnot equal to\n\n\n!x\nnot x\n\n\na\nb\n\n\na & b\na and b\n\n\n\n\n\n\n\n\n\nThe magic of programming\n\n\n\nThe reason why the expression snp_positions[snp_positions &gt; 100000000] works can be better understood if you examine what the expression “snp_positions &gt; 100000000” evaluates to:\n\nsnp_positions &gt; 100000000\n\n[1] FALSE FALSE FALSE  TRUE\n\n\nThe output above is a logical vector, the 4th element of which is TRUE. When you pass a logical vector as an index, R will return the true values:\n\nsnp_positions[c(FALSE, FALSE, FALSE, TRUE)]\n\n[1] 154039662\n\n\nIf you have never coded before, this type of situation starts to expose the “magic” of programming. We mentioned before that in the bracket notation you take your named vector followed by brackets which contain an index: named_vector[index]. The “magic” is that the index needs to evaluate to a number. So, even if it does not appear to be an integer (e.g. 1, 2, 3), as long as R can evaluate it, we will get a result. That our expression snp_positions[snp_positions &gt; 100000000] evaluates to a number can be seen in the following situation. If you wanted to know which index (1, 2, 3, or 4) in our vector of SNP positions was the one that was greater than 100,000,000?\nWe can use the which() function to return the indices of any item that evaluates as TRUE in our comparison:\n\nwhich(snp_positions &gt; 100000000)\n\n[1] 4\n\n\nWhy this is important\nOften in programming we will not know what inputs and values will be used when our code is executed. Rather than put in a pre-determined value (e.g 100000000) we can use an object that can take on whatever value we need. So for example:\n\nsnp_marker_cutoff &lt;- 100000000\nsnp_positions[snp_positions &gt; snp_marker_cutoff]\n\n[1] 154039662\n\n\nUltimately, it’s putting together flexible, reusable code like this that gets at the “magic” of programming!"
  },
  {
    "objectID": "r_lesson/01-r-basics.html#a-few-final-vector-tricks",
    "href": "r_lesson/01-r-basics.html#a-few-final-vector-tricks",
    "title": "R Basics I - objects, functions, vectors",
    "section": "A few final vector tricks",
    "text": "A few final vector tricks\nFinally, there are a few other common retrieve or replace operations you may want to know about. First, you can check to see if any of the values of your vector are missing (i.e. are NA, that stands for not avaliable). Missing data will get a more detailed treatment later, but the is.NA() function will return a logical vector, with TRUE for any NA value:\n\nsnp_genes &lt;- c(\"OXTR\", \"ACTN3\", \"AR\", \"OPRM1\", \"CYP1A1\", NA, \"APOA5\")\n\nis.na(snp_genes)\n\n[1] FALSE FALSE FALSE FALSE FALSE  TRUE FALSE\n\nsum(is.na(snp_genes))\n\n[1] 1\n\n\nSometimes, you may wish to find out if a specific value (or several values) is present a vector. You can do this using the comparison operator %in%, which will return TRUE for any value in your collection that is in the vector you are searching:\n\n# current value of 'snp_genes':\n# chr [1:7] \"OXTR\" \"ACTN3\" \"AR\" \"OPRM1\" \"CYP1A1\" NA \"APOA5\"\n\n# test to see if \"ACTN3\" or \"APO5A\" is in the snp_genes vector\n# if you are looking for more than one value, you must pass this as a vector\n\nsnp_genes %in% c(\"ACTN3\",\"APOA5\")\n\n[1] FALSE  TRUE FALSE FALSE FALSE FALSE  TRUE\n\n\n\n\n\n\n\n\nExercise 1\n\n\n\nWhat data modes are the following vectors? a. snps\nb. snp_chromosomes\nc. snp_positions\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\nmode(snps)\n\n[1] \"character\"\n\nmode(snp_chromosomes)\n\n[1] \"character\"\n\nmode(snp_positions)\n\n[1] \"numeric\"\n\n\n\n\n\n\n\n\n\n\n\n\n\nExercise 2\n\n\n\nAdd the following values to the specified vectors: a. To the snps vector add: “rs662799”\nb. To the snp_chromosomes vector add: 11\nc. To the snp_positions vector add: 116792991\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\nsnps &lt;- c(snps, \"rs662799\")\nsnps\n\n[1] \"rs53576\"   \"rs1815739\" \"rs6152\"    \"rs1799971\" \"rs662799\" \n\nsnp_chromosomes &lt;- c(snp_chromosomes, \"11\") # did you use quotes?\nsnp_chromosomes\n\n[1] \"3\"  \"11\" \"X\"  \"6\"  \"11\"\n\nsnp_positions &lt;- c(snp_positions, 116792991)\nsnp_positions\n\n[1]   8762685  66560624  67545785 154039662 116792991\n\n\n\n\n\n\n\n\n\n\n\n\n\nExercise 3\n\n\n\nMake the following change to the snp_genes vector:\nHint: Your vector should look like this in ‘Environment’: chr [1:7] \"OXTR\" \"ACTN3\" \"AR\" \"OPRM1\" \"CYP1A1\" NA \"APOA5\". If not recreate the vector by running this expression: snp_genes &lt;- c(\"OXTR\", \"ACTN3\", \"AR\", \"OPRM1\", \"CYP1A1\", NA, \"APOA5\")\n\nCreate a new version of snp_genes that does not contain CYP1A1 and then\n\nAdd 2 NA values to the end of snp_genes\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\nsnp_genes &lt;- snp_genes[-5]\nsnp_genes &lt;- c(snp_genes, NA, NA)\nsnp_genes\n\n[1] \"OXTR\"  \"ACTN3\" \"AR\"    \"OPRM1\" NA      \"APOA5\" NA      NA     \n\n\n\n\n\n\n\n\n\n\n\n\n\nExercise 4\n\n\n\nUsing indexing, create a new vector named combined that contains:\n\nThe the 1st value in snp_genes\nThe 1st value in snps\nThe 1st value in snp_chromosomes\nThe 1st value in snp_positions\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\ncombined &lt;- c(snp_genes[1], snps[1], snp_chromosomes[1], snp_positions[1])\ncombined\n\n[1] \"OXTR\"    \"rs53576\" \"3\"       \"8762685\"\n\n\n\n\n\n\n\n\n\n\n\n\n\nExercise 5\n\n\n\nWhat type of data is combined?\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\ntypeof(combined)\n\n[1] \"character\"\n\n\n\n\n\n\n\n\n\n\n\n\n\nKey points\n\n\n\n\nEffectively using R is a journey of months or years. Still you don’t have to be an expert to use R and you can start using and analyzing your data with with about a day’s worth of training\nIt is important to understand how data are organized by R in a given object type and how the mode of that type (e.g. numeric, character, logical, etc.) will determine how R will operate on that data.\nWorking with vectors effectively prepares you for understanding how data are organized in R."
  },
  {
    "objectID": "r_lesson/03-basics-factors-dataframes.html",
    "href": "r_lesson/03-basics-factors-dataframes.html",
    "title": "R Basics II - factors and data frames",
    "section": "",
    "text": "Objectives\n\n\n\n\nExplain the basic principle of tidy datasets\nBe able to load a tabular dataset into the R environment.\nBe able to determine the structure of a data frame including its dimensions and the datatypes of variables\nBe able to subset/retrieve values from a data frame\nBe able to import data from Excel"
  },
  {
    "objectID": "r_lesson/03-basics-factors-dataframes.html#working-with-spreadsheets-tabular-data",
    "href": "r_lesson/03-basics-factors-dataframes.html#working-with-spreadsheets-tabular-data",
    "title": "R Basics II - factors and data frames",
    "section": "Working with spreadsheets (tabular data)",
    "text": "Working with spreadsheets (tabular data)\nA substantial amount of the data we work with in genomics will be tabular data, this is data arranged in rows and columns - also known as spreadsheets. For more on how to work with spreadsheets effectively (check out this lesson). For our purposes, we want to remind you of a few principles before we work with our first set of example data:\n1) Keep raw data separate from analyzed data\nThis is principle number one because if you can’t tell which files are the original raw data, you risk making some serious mistakes (e.g. drawing conclusion from data which have been manipulated in some unknown way).\n2) Keep spreadsheet data Tidy\nThe simplest principle of Tidy data is that we have one row in our spreadsheet for each observation or sample, and one column for every variable that we measure or report on.\n\n\n\n\n\n\n\n\n\nAs simple as this sounds, it’s very easily violated. Most data scientists agree that significant amounts of their time is spent tidying data for analysis. Read more about data organization in this lesson and in this paper.\n3) Trust but verify\nFinally, while you don’t need to be paranoid about data, you should have a plan for how you will prepare it for analysis. This a focus of this lesson. You probably already have a lot of intuition, expectations, assumptions about your data - the range of values you expect, how many values should have been recorded, etc. Of course, as the data get larger our human ability to keep track will start to fail (and yes, it can fail for small data sets too). R will help you to examine your data so that you can have greater confidence in your analysis, and its reproducibility.\n\n\n\n\n\n\nTip: Keeping your raw data separate\n\n\n\nWhen you work with data in R, you are not changing the original file you loaded that data from. This is different than (for example) working with a spreadsheet program where changing the value of the cell leaves you one “save”-click away from overwriting the original file. You have to purposely use a writing function (e.g. write_csv()) to save data loaded into R. In that case, be sure to save the manipulated data into a new file. More on this later in the lesson.\n\n\nTo practice good data management, let’s create two new folders (we can do this in our Files pane) - raw_data - output_data\nThen we can move our two data files into the raw_data folder."
  },
  {
    "objectID": "r_lesson/03-basics-factors-dataframes.html#importing-tabular-data-into-r",
    "href": "r_lesson/03-basics-factors-dataframes.html#importing-tabular-data-into-r",
    "title": "R Basics II - factors and data frames",
    "section": "Importing tabular data into R",
    "text": "Importing tabular data into R\nThere are several ways to import data into R. Here, we will see how to import data through the RStudio interface, and with code. Either way, we will use a function called read_csv(), which is part of the tidyverse package, readr.\nNow, let’s read in the file combined_tidy_vcf.csv which will be located in r_lesson/raw_data. In the Files pane of RStudio, click on the name of file we want to read in, and select Import Dataset. This will open up the import widget.\n\n\n\n\n\n\n\n\n\nIn this widget you can see a preview of the data and make adjustments to data types, separators, header rows, etc. For now, we’ll see change the name to variants. This will be the object name once the file is imported. By default, the file name will be used as the object name, but it may often be preferable to change this to something shorter, but still descriptive.\nAlso note that, you can see the code that is generated underlying the widget. We can add that code to a script for better reproducibility of our process.\n\n\n\n\n\n\n\n\n\nNow, you can copy the code from the code preview window, or look in your history pane, select the lines of code that were generated, and send them To source, i.e. to our script.\n\n## read in a CSV file and save it as 'variants'\n\nlibrary(readr)\nvariants &lt;- read_csv(\"r_lesson/raw_data/combined_tidy_vcf.csv\")\n\nLet’s take a closer look at what the code is doing.\n\nloading the library readr. As mentioned earlier, this is part of the tidyverse family of packages. (R has a built in function similarly named read.csv(), they work similarly, but since we will be working with the tidyverse, we’ll choose the readr.)\ncreating a new object called variants\nassigning to that object the output of the read_csv() function.\ncalling the function on our combined_tidy_vcf.csv file. That is, the file name is given as the argument of our function. Note that the file path must be in quotes. You can also supply URLs as file paths if your data is online.\n\n\n\n\n\n\n\nTip\n\n\n\nIf you press the TAB key inside the quotes, RStudio will help you autocomplete the file name. Use this to avoid typos!\n\n\nOne of the first things you should notice now that our data is loaded is that in the Environment window, you have the variants object, listed as 801 obs. (observations/rows) of 29 variables (columns). Double-clicking on the name of the object will open a view of the data in a new tab.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nWhat about Excel (and other) files?\n\n\n\nYou can use the same process described above to import an Excel file, like Ecoli_metadata.xlsx in our raw_data folder. The main difference is that we use the library readxl to do the import. The options allow you to do things like select a specific worksheet if your workbook has more than one. It is also possible to import data from other systems like SPSS, STATA, and SAS with the haven package."
  },
  {
    "objectID": "r_lesson/03-basics-factors-dataframes.html#working-with-data-frames",
    "href": "r_lesson/03-basics-factors-dataframes.html#working-with-data-frames",
    "title": "R Basics II - factors and data frames",
    "section": "Working with data frames",
    "text": "Working with data frames\nA data frame is the standard way in R to store tabular data. A data fame could also be thought of as a collection of vectors, all of which have the same length. While each column is one data type, the data frame over all can have multiple data types.\n\n\n\n\n\n\n\n\n\nUsing only two functions, we can learn a lot about out data frame including some summary statistics as well as well as the “structure” of the data frame. Let’s examine what each of these functions can tell us:\n\n## get summary statistics on a data frame\n\nsummary(variants)\n\n  sample_id            CHROM                POS             ID         \n Length:801         Length:801         Min.   :   1521   Mode:logical  \n Class :character   Class :character   1st Qu.:1115970   NA's:801      \n Mode  :character   Mode  :character   Median :2290361                 \n                                       Mean   :2243682                 \n                                       3rd Qu.:3317082                 \n                                       Max.   :4629225                 \n                                                                       \n     REF                ALT                 QUAL          FILTER       \n Length:801         Length:801         Min.   :  4.385   Mode:logical  \n Class :character   Class :character   1st Qu.:139.000   NA's:801      \n Mode  :character   Mode  :character   Median :195.000                 \n                                       Mean   :172.276                 \n                                       3rd Qu.:225.000                 \n                                       Max.   :228.000                 \n                                                                       \n   INDEL              IDV              IMF               DP       \n Mode :logical   Min.   : 2.000   Min.   :0.5714   Min.   : 2.00  \n FALSE:700       1st Qu.: 7.000   1st Qu.:0.8824   1st Qu.: 7.00  \n TRUE :101       Median : 9.000   Median :1.0000   Median :10.00  \n                 Mean   : 9.396   Mean   :0.9219   Mean   :10.57  \n                 3rd Qu.:11.000   3rd Qu.:1.0000   3rd Qu.:13.00  \n                 Max.   :20.000   Max.   :1.0000   Max.   :79.00  \n                 NA's   :700      NA's   :700                     \n      VDB                 RPB              MQB              BQB        \n Min.   :0.0005387   Min.   :0.0000   Min.   :0.0000   Min.   :0.1153  \n 1st Qu.:0.2180410   1st Qu.:0.3776   1st Qu.:0.1070   1st Qu.:0.6963  \n Median :0.4827410   Median :0.8663   Median :0.2872   Median :0.8615  \n Mean   :0.4926291   Mean   :0.6970   Mean   :0.5330   Mean   :0.7784  \n 3rd Qu.:0.7598940   3rd Qu.:1.0000   3rd Qu.:1.0000   3rd Qu.:1.0000  \n Max.   :0.9997130   Max.   :1.0000   Max.   :1.0000   Max.   :1.0000  \n                     NA's   :773      NA's   :773      NA's   :773     \n      MQSB              SGB               MQ0F           ICB         \n Min.   :0.01348   Min.   :-0.6931   Min.   :0.00000   Mode:logical  \n 1st Qu.:0.95494   1st Qu.:-0.6762   1st Qu.:0.00000   NA's:801      \n Median :1.00000   Median :-0.6620   Median :0.00000                 \n Mean   :0.96428   Mean   :-0.6444   Mean   :0.01127                 \n 3rd Qu.:1.00000   3rd Qu.:-0.6364   3rd Qu.:0.00000                 \n Max.   :1.01283   Max.   :-0.4536   Max.   :0.66667                 \n NA's   :48                                                          \n   HOB                AC          AN        DP4                  MQ       \n Mode:logical   Min.   :1   Min.   :1   Length:801         Min.   :10.00  \n NA's:801       1st Qu.:1   1st Qu.:1   Class :character   1st Qu.:60.00  \n                Median :1   Median :1   Mode  :character   Median :60.00  \n                Mean   :1   Mean   :1                      Mean   :58.19  \n                3rd Qu.:1   3rd Qu.:1                      3rd Qu.:60.00  \n                Max.   :1   Max.   :1                      Max.   :60.00  \n                                                                          \n    Indiv               gt_PL            gt_GT   gt_GT_alleles     \n Length:801         Min.   :   310   Min.   :1   Length:801        \n Class :character   1st Qu.:  1760   1st Qu.:1   Class :character  \n Mode  :character   Median :  2290   Median :1   Mode  :character  \n                    Mean   :  3392   Mean   :1                     \n                    3rd Qu.:  2550   3rd Qu.:1                     \n                    Max.   :255156   Max.   :1                     \n                                                                   \n\n\nOur data frame had 29 variables, so we get 29 fields that summarize the data. The QUAL, IMF, and VDB variables (and several others) are numerical data and so you get summary statistics on the min and max values for these columns, as well as mean, median, and interquartile ranges. Many of the other variables (e.g. sample_id) are treated as characters data (more on this in a bit).\nNow, let’s use the str() (structure) function to look a little more closely at how data frames work:\n\n## get the structure of a data frame\n\nstr(variants)\n\nYou should notice quite a bit of information printing to your console:\n\nthe object type tibble is displayed. A tibble is a tidyverse version of the data frame. It has some properties like printing out nicely to the console, but for our purposes in this class, we will use the terms “data frame” and “tibble” interchangeably.\nAfter the object type is the dimensions, in this case 801 observations (rows) and 29 variables (columns).\nEach variable (column) has a name (e.g. sample_id). This is followed by the object mode (e.g. chr, int, etc.). Notice that before each variable name there is a $ - this will be important later.\nNote that we can find this information in the environment pane also.\n\n\nSubsetting data frames\nNext, we are going to talk about how you can get specific values from data frames.\nThe first thing to remember is that a data frame is two-dimensional (rows and columns). Therefore, to select a specific value we will will once again use [] (bracket) notation, but we will specify more than one value (except in some cases where we are taking a range).\nLet’s say I wanted the first row and first column\n\nvariants[1, 1]\n\n# A tibble: 1 × 1\n  sample_id \n  &lt;chr&gt;     \n1 SRR2584863\n\n\nor I can select the first three rows and first three columns with : to get a range.\n\nvariants[1:3, 1:3]\n\n# A tibble: 3 × 3\n  sample_id  CHROM         POS\n  &lt;chr&gt;      &lt;chr&gt;       &lt;dbl&gt;\n1 SRR2584863 CP000819.1   9972\n2 SRR2584863 CP000819.1 263235\n3 SRR2584863 CP000819.1 281923\n\n\nIf we want to select all rows and one or more columns, we leave the space before the comma blank.\n\nvariants[, 1:5]\n\n# A tibble: 801 × 5\n   sample_id  CHROM          POS ID    REF                             \n   &lt;chr&gt;      &lt;chr&gt;        &lt;dbl&gt; &lt;lgl&gt; &lt;chr&gt;                           \n 1 SRR2584863 CP000819.1    9972 NA    T                               \n 2 SRR2584863 CP000819.1  263235 NA    G                               \n 3 SRR2584863 CP000819.1  281923 NA    G                               \n 4 SRR2584863 CP000819.1  433359 NA    CTTTTTTT                        \n 5 SRR2584863 CP000819.1  473901 NA    CCGC                            \n 6 SRR2584863 CP000819.1  648692 NA    C                               \n 7 SRR2584863 CP000819.1 1331794 NA    C                               \n 8 SRR2584863 CP000819.1 1733343 NA    G                               \n 9 SRR2584863 CP000819.1 2103887 NA    ACAGCCAGCCAGCCAGCCAGCCAGCCAGCCAG\n10 SRR2584863 CP000819.1 2333538 NA    AT                              \n# ℹ 791 more rows\n\n\nor we can leave out the comma entirely\n\nvariants[1:5]\n\n# A tibble: 801 × 5\n   sample_id  CHROM          POS ID    REF                             \n   &lt;chr&gt;      &lt;chr&gt;        &lt;dbl&gt; &lt;lgl&gt; &lt;chr&gt;                           \n 1 SRR2584863 CP000819.1    9972 NA    T                               \n 2 SRR2584863 CP000819.1  263235 NA    G                               \n 3 SRR2584863 CP000819.1  281923 NA    G                               \n 4 SRR2584863 CP000819.1  433359 NA    CTTTTTTT                        \n 5 SRR2584863 CP000819.1  473901 NA    CCGC                            \n 6 SRR2584863 CP000819.1  648692 NA    C                               \n 7 SRR2584863 CP000819.1 1331794 NA    C                               \n 8 SRR2584863 CP000819.1 1733343 NA    G                               \n 9 SRR2584863 CP000819.1 2103887 NA    ACAGCCAGCCAGCCAGCCAGCCAGCCAGCCAG\n10 SRR2584863 CP000819.1 2333538 NA    AT                              \n# ℹ 791 more rows\n\n\nAlternatively, if we want all columns and just one or more rows, we leave the space after the comma blank\n\nvariants[1, ]\n\n# A tibble: 1 × 29\n  sample_id  CHROM    POS ID    REF   ALT    QUAL FILTER INDEL   IDV   IMF    DP\n  &lt;chr&gt;      &lt;chr&gt;  &lt;dbl&gt; &lt;lgl&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;lgl&gt;  &lt;lgl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1 SRR2584863 CP000…  9972 NA    T     G        91 NA     FALSE    NA    NA     4\n# ℹ 17 more variables: VDB &lt;dbl&gt;, RPB &lt;dbl&gt;, MQB &lt;dbl&gt;, BQB &lt;dbl&gt;, MQSB &lt;dbl&gt;,\n#   SGB &lt;dbl&gt;, MQ0F &lt;dbl&gt;, ICB &lt;lgl&gt;, HOB &lt;lgl&gt;, AC &lt;dbl&gt;, AN &lt;dbl&gt;, DP4 &lt;chr&gt;,\n#   MQ &lt;dbl&gt;, Indiv &lt;chr&gt;, gt_PL &lt;dbl&gt;, gt_GT &lt;dbl&gt;, gt_GT_alleles &lt;chr&gt;\n\n\nTo select non-consecutive columns, use c(). You can always save these results to a new object.\n\n## put the first three columns of variants into a new data frame called subset\n\nvariants_subset &lt;- variants[,c(1:3,6)]\n\n\n\n\n\n\n\nSubsetting vectors vs data frames\n\n\n\nThe subsetting notation is very similar to what we learned for vectors. The key differences include:\n\nTypically provide two values separated by commas: data.frame[row, column]\nIn cases where you are taking a continuous range of numbers use a colon between the numbers (start:stop, inclusive)\nFor a non continuous set of numbers, pass a vector using c()\nIndex using the name of a column(s) by passing them as vectors using c()\n\n\n\nIt will generally be easier for us to access columns by name, rather than index. We can do this with the $ to access a column.\n\n## extract the \"ALT\" column to a new object\n\nalt_alleles &lt;- variants_subset$ALT\n\nhead(alt_alleles)\n\n[1] \"G\"         \"T\"         \"T\"         \"CTTTTTTTT\" \"CCGCGC\"    \"T\"        \n\n\nLike with vectors, we can use brackets with logical operators to subset based on a condition. We can also use a combination of $ and [] notation. Since we are filtering for just the rows we want, we put the condition before the ,.\nLet’s try some conditional filtering to look for just the rows with the nucleotide ‘A’ in the ALT column.\n\nvariants_subset[variants_subset$ALT == \"A\", ]\n\n# A tibble: 211 × 4\n   sample_id  CHROM          POS ALT  \n   &lt;chr&gt;      &lt;chr&gt;        &lt;dbl&gt; &lt;chr&gt;\n 1 SRR2584863 CP000819.1 1331794 A    \n 2 SRR2584863 CP000819.1 1733343 A    \n 3 SRR2584863 CP000819.1 2999330 A    \n 4 SRR2584863 CP000819.1 3401754 A    \n 5 SRR2584866 CP000819.1   10563 A    \n 6 SRR2584866 CP000819.1   64042 A    \n 7 SRR2584866 CP000819.1   98404 A    \n 8 SRR2584866 CP000819.1  105581 A    \n 9 SRR2584866 CP000819.1  241885 A    \n10 SRR2584866 CP000819.1  241950 A    \n# ℹ 201 more rows\n\n\nor we can look for all the single-nucleotide alleles (SNPs).\nFirst let’s create an object to store the values of our DNA bases.\n\nbases &lt;- c(\"A\", \"C\", \"G\", \"T\")\n\nNext we can use the %in% operator. This is a logical operator which is similar to ==, but can be used to filter on multiple values. Here we are saying to check for each of the four bases we captured in the bases object.\n\nsnps &lt;- variants_subset[variants_subset$ALT %in% bases, ]\n\nhead(snps)\n\n# A tibble: 6 × 4\n  sample_id  CHROM          POS ALT  \n  &lt;chr&gt;      &lt;chr&gt;        &lt;dbl&gt; &lt;chr&gt;\n1 SRR2584863 CP000819.1    9972 G    \n2 SRR2584863 CP000819.1  263235 T    \n3 SRR2584863 CP000819.1  281923 T    \n4 SRR2584863 CP000819.1  648692 T    \n5 SRR2584863 CP000819.1 1331794 A    \n6 SRR2584863 CP000819.1 1733343 A    \n\n\nThis leaves us with a data frame (or tibble) of the 707 rows in which the alternative alleles were single nucleotides.\n\n\n\n\n\n\nExercise: Subsetting a data frame\n\n\n\nTry the following indices and functions and try to figure out what they return\n\nvariants[1,1]\nvariants[2,4]\nvariants[801,29]\nvariants[2, ]\nvariants[-1, ]\nvariants[1:4,1]\nvariants[1:10,c(\"REF\",\"ALT\")]\nvariants[,c(\"sample_id\")]\nhead(variants)\ntail(variants)\nvariants$sample_id\nvariants[variants$REF == \"A\",]\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\n\n\n\nvariants[1,1]\n\n# A tibble: 1 × 1\n  sample_id \n  &lt;chr&gt;     \n1 SRR2584863\n\n\n\n\n\n\nvariants[2,4]\n\n# A tibble: 1 × 1\n  ID   \n  &lt;lgl&gt;\n1 NA   \n\n\n\n\n\n\nvariants[801,29]\n\n# A tibble: 1 × 1\n  gt_GT_alleles\n  &lt;chr&gt;        \n1 T            \n\n\n\n\n\n\nvariants[2, ]\n\n# A tibble: 1 × 29\n  sample_id  CHROM    POS ID    REF   ALT    QUAL FILTER INDEL   IDV   IMF    DP\n  &lt;chr&gt;      &lt;chr&gt;  &lt;dbl&gt; &lt;lgl&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;lgl&gt;  &lt;lgl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1 SRR2584863 CP00… 263235 NA    G     T        85 NA     FALSE    NA    NA     6\n# ℹ 17 more variables: VDB &lt;dbl&gt;, RPB &lt;dbl&gt;, MQB &lt;dbl&gt;, BQB &lt;dbl&gt;, MQSB &lt;dbl&gt;,\n#   SGB &lt;dbl&gt;, MQ0F &lt;dbl&gt;, ICB &lt;lgl&gt;, HOB &lt;lgl&gt;, AC &lt;dbl&gt;, AN &lt;dbl&gt;, DP4 &lt;chr&gt;,\n#   MQ &lt;dbl&gt;, Indiv &lt;chr&gt;, gt_PL &lt;dbl&gt;, gt_GT &lt;dbl&gt;, gt_GT_alleles &lt;chr&gt;\n\n\n\n\n\n\nvariants[-1, ]\n\n\n\n# A tibble: 6 × 29\n  sample_id  CHROM    POS ID    REF   ALT    QUAL FILTER INDEL   IDV   IMF    DP\n  &lt;chr&gt;      &lt;chr&gt;  &lt;dbl&gt; &lt;lgl&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;lgl&gt;  &lt;lgl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1 SRR2584863 CP00… 2.63e5 NA    G     T        85 NA     FALSE    NA  NA       6\n2 SRR2584863 CP00… 2.82e5 NA    G     T       217 NA     FALSE    NA  NA      10\n3 SRR2584863 CP00… 4.33e5 NA    CTTT… CTTT…    64 NA     TRUE     12   1      12\n4 SRR2584863 CP00… 4.74e5 NA    CCGC  CCGC…   228 NA     TRUE      9   0.9    10\n5 SRR2584863 CP00… 6.49e5 NA    C     T       210 NA     FALSE    NA  NA      10\n6 SRR2584863 CP00… 1.33e6 NA    C     A       178 NA     FALSE    NA  NA       8\n# ℹ 17 more variables: VDB &lt;dbl&gt;, RPB &lt;dbl&gt;, MQB &lt;dbl&gt;, BQB &lt;dbl&gt;, MQSB &lt;dbl&gt;,\n#   SGB &lt;dbl&gt;, MQ0F &lt;dbl&gt;, ICB &lt;lgl&gt;, HOB &lt;lgl&gt;, AC &lt;dbl&gt;, AN &lt;dbl&gt;, DP4 &lt;chr&gt;,\n#   MQ &lt;dbl&gt;, Indiv &lt;chr&gt;, gt_PL &lt;dbl&gt;, gt_GT &lt;dbl&gt;, gt_GT_alleles &lt;chr&gt;\n\n\n\n\n\n\nvariants[1:4,1]\n\n# A tibble: 4 × 1\n  sample_id \n  &lt;chr&gt;     \n1 SRR2584863\n2 SRR2584863\n3 SRR2584863\n4 SRR2584863\n\n\n\n\n\n\nvariants[1:10,c(\"REF\",\"ALT\")]\n\n# A tibble: 10 × 2\n   REF                              ALT                                         \n   &lt;chr&gt;                            &lt;chr&gt;                                       \n 1 T                                G                                           \n 2 G                                T                                           \n 3 G                                T                                           \n 4 CTTTTTTT                         CTTTTTTTT                                   \n 5 CCGC                             CCGCGC                                      \n 6 C                                T                                           \n 7 C                                A                                           \n 8 G                                A                                           \n 9 ACAGCCAGCCAGCCAGCCAGCCAGCCAGCCAG ACAGCCAGCCAGCCAGCCAGCCAGCCAGCCAGCCAGCCAGCCA…\n10 AT                               ATT                                         \n\n\n\n\n\n\nvariants[,c(\"sample_id\")]\n\n\n\n# A tibble: 6 × 1\n  sample_id \n  &lt;chr&gt;     \n1 SRR2584863\n2 SRR2584863\n3 SRR2584863\n4 SRR2584863\n5 SRR2584863\n6 SRR2584863\n\n\n\n\n\n\nhead(variants)\n\n# A tibble: 6 × 29\n  sample_id  CHROM    POS ID    REF   ALT    QUAL FILTER INDEL   IDV   IMF    DP\n  &lt;chr&gt;      &lt;chr&gt;  &lt;dbl&gt; &lt;lgl&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;lgl&gt;  &lt;lgl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1 SRR2584863 CP00…   9972 NA    T     G        91 NA     FALSE    NA  NA       4\n2 SRR2584863 CP00… 263235 NA    G     T        85 NA     FALSE    NA  NA       6\n3 SRR2584863 CP00… 281923 NA    G     T       217 NA     FALSE    NA  NA      10\n4 SRR2584863 CP00… 433359 NA    CTTT… CTTT…    64 NA     TRUE     12   1      12\n5 SRR2584863 CP00… 473901 NA    CCGC  CCGC…   228 NA     TRUE      9   0.9    10\n6 SRR2584863 CP00… 648692 NA    C     T       210 NA     FALSE    NA  NA      10\n# ℹ 17 more variables: VDB &lt;dbl&gt;, RPB &lt;dbl&gt;, MQB &lt;dbl&gt;, BQB &lt;dbl&gt;, MQSB &lt;dbl&gt;,\n#   SGB &lt;dbl&gt;, MQ0F &lt;dbl&gt;, ICB &lt;lgl&gt;, HOB &lt;lgl&gt;, AC &lt;dbl&gt;, AN &lt;dbl&gt;, DP4 &lt;chr&gt;,\n#   MQ &lt;dbl&gt;, Indiv &lt;chr&gt;, gt_PL &lt;dbl&gt;, gt_GT &lt;dbl&gt;, gt_GT_alleles &lt;chr&gt;\n\n\n\n\n\n\ntail(variants)\n\n# A tibble: 6 × 29\n  sample_id  CHROM    POS ID    REF   ALT    QUAL FILTER INDEL   IDV   IMF    DP\n  &lt;chr&gt;      &lt;chr&gt;  &lt;dbl&gt; &lt;lgl&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;lgl&gt;  &lt;lgl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1 SRR2589044 CP00… 3.44e6 NA    G     T       184 NA     FALSE    NA    NA     9\n2 SRR2589044 CP00… 3.48e6 NA    A     G       225 NA     FALSE    NA    NA    12\n3 SRR2589044 CP00… 3.89e6 NA    AG    AGG     101 NA     TRUE      4     1     4\n4 SRR2589044 CP00… 3.90e6 NA    A     AC       70 NA     TRUE      3     1     3\n5 SRR2589044 CP00… 4.10e6 NA    A     G       177 NA     FALSE    NA    NA     8\n6 SRR2589044 CP00… 4.43e6 NA    TGG   T       225 NA     TRUE     10     1    10\n# ℹ 17 more variables: VDB &lt;dbl&gt;, RPB &lt;dbl&gt;, MQB &lt;dbl&gt;, BQB &lt;dbl&gt;, MQSB &lt;dbl&gt;,\n#   SGB &lt;dbl&gt;, MQ0F &lt;dbl&gt;, ICB &lt;lgl&gt;, HOB &lt;lgl&gt;, AC &lt;dbl&gt;, AN &lt;dbl&gt;, DP4 &lt;chr&gt;,\n#   MQ &lt;dbl&gt;, Indiv &lt;chr&gt;, gt_PL &lt;dbl&gt;, gt_GT &lt;dbl&gt;, gt_GT_alleles &lt;chr&gt;\n\n\n\n\n\n\nvariants$sample_id\n\n\n\n[1] \"SRR2584863\" \"SRR2584863\" \"SRR2584863\" \"SRR2584863\" \"SRR2584863\"\n[6] \"SRR2584863\"\n\n\n\n\n\n\nvariants[variants$REF == \"A\",]\n\n\n\n# A tibble: 6 × 29\n  sample_id  CHROM    POS ID    REF   ALT    QUAL FILTER INDEL   IDV   IMF    DP\n  &lt;chr&gt;      &lt;chr&gt;  &lt;dbl&gt; &lt;lgl&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;lgl&gt;  &lt;lgl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1 SRR2584863 CP00… 2.41e6 NA    A     C       104 NA     FALSE    NA    NA     9\n2 SRR2584863 CP00… 2.45e6 NA    A     C       225 NA     FALSE    NA    NA    20\n3 SRR2584863 CP00… 2.67e6 NA    A     T       225 NA     FALSE    NA    NA    19\n4 SRR2584863 CP00… 3.34e6 NA    A     C       211 NA     FALSE    NA    NA    10\n5 SRR2584863 CP00… 3.48e6 NA    A     G       200 NA     FALSE    NA    NA     9\n6 SRR2584863 CP00… 3.49e6 NA    A     C       225 NA     FALSE    NA    NA    13\n# ℹ 17 more variables: VDB &lt;dbl&gt;, RPB &lt;dbl&gt;, MQB &lt;dbl&gt;, BQB &lt;dbl&gt;, MQSB &lt;dbl&gt;,\n#   SGB &lt;dbl&gt;, MQ0F &lt;dbl&gt;, ICB &lt;lgl&gt;, HOB &lt;lgl&gt;, AC &lt;dbl&gt;, AN &lt;dbl&gt;, DP4 &lt;chr&gt;,\n#   MQ &lt;dbl&gt;, Indiv &lt;chr&gt;, gt_PL &lt;dbl&gt;, gt_GT &lt;dbl&gt;, gt_GT_alleles &lt;chr&gt;\n\n\n\n\n\n\n\n\n\nSummarizing data frames\nIn addition to summary(), there are other useful base R functions for summarizing your data, or columns in your data.\nUse unique() to find the unique values in a column. For instance, we could double check that our operation on the ALT column worked.\n\nunique(snps$ALT)\n\n[1] \"G\" \"T\" \"A\" \"C\"\n\n\ntable() will give you unique values, plus a count of how often they appear.\n\ntable(snps$ALT)\n\n\n  A   C   G   T \n211 139 154 203 \n\n\n\n\n\n\n\n\nKey points\n\n\n\n\nIt is easy to import data into R from tabular formats including Excel. However, you still need to check that R has imported and interpreted your data correctly\nThere are best practices for organizing your data (keeping it tidy) and R is great for this\nBase R has many useful functions for manipulating your data, but all of R’s capabilities are greatly enhanced by software packages developed by the community"
  },
  {
    "objectID": "r_lesson/05-data-visualization.html",
    "href": "r_lesson/05-data-visualization.html",
    "title": "Data Visualization with ggplot2",
    "section": "",
    "text": "Objectives\n\n\n\n\nDescribe the role of data, aesthetics, and geoms in ggplot2 functions.\nChoose the correct aesthetics and alter the geom parameters for a scatter plot, histogram, or box plot.\nLayer multiple geometries in a single plot.\nCustomize plot scales, titles, themes, and fonts.\nApply a facet to a plot.\nSave a ggplot to a file.\nList several resources for getting help with ggplot.\nList several resources for creating informative scientific plots."
  },
  {
    "objectID": "r_lesson/05-data-visualization.html#introduction-to-ggplot2",
    "href": "r_lesson/05-data-visualization.html#introduction-to-ggplot2",
    "title": "Data Visualization with ggplot2",
    "section": "Introduction to ggplot2",
    "text": "Introduction to ggplot2\n\nggplot2 is a plotting package that makes it simple to create complex plots from data in a data frame. It provides a more programmatic interface for specifying what variables to plot, how they are displayed, and general visual properties. Therefore, we only need minimal changes if the underlying data change or if we decide to change from a bar plot to a scatter plot. This helps in creating publication-quality plots with minimal amounts of adjustments and tweaking.\nThe gg in “ggplot” stands for “Grammar of Graphics,” which is an elegant yet powerful way to describe the making of scientific plots. In short, the grammar of graphics breaks down every plot into a few components, namely, a dataset, a set of geoms (visual marks that represent the data points), and a coordinate system. You can imagine this is a grammar that gives unique names to each component appearing in a plot and conveys specific information about data. With ggplot, graphics are built step by step by adding new elements.\nThe idea of mapping is crucial in ggplot. One familiar example is to map the value of one variable in a dataset to \\(x\\) and the other to \\(y\\). However, we often encounter datasets that include multiple (more than two) variables. In this case, ggplot allows you to map those other variables to visual marks such as color and shape (aesthetics or aes). One thing you may want to remember is the difference between discrete and continuous variables. Some aesthetics, such as the shape of dots, do not accept continuous variables. If forced to do so, R will give an error. This is easy to understand; we cannot create a continuum of shapes for a variable, unlike, say, color.\nTip: when having doubts about whether a variable is continuous or discrete, a quick way to check is to use the summary() function. Continuous variables have descriptive statistics but not the discrete variables.\n\n\n\n\n\n\nInstalling tidyverse\n\n\n\nggplot2 belongs to the tidyverse framework. Therefore, we will start with loading the package tidyverse. If tidyverse is not already installed, then we need to install first. If the tidyverse has been installed and loaded, then we can skip the following steps:\n\ninstall.packages(\"tidyverse\") # Installing tidyverse package, includes ggplot2 and other packages such as dplyr, readr, tidyr\n\nlibrary(tidyverse)\n\nNote that ggplot can also be installed and loaded separately from the rest of the tidyverse.\n\n\nggplot2 functions like data in the long format, i.e., a column for every dimension (variable), and a row for every observation. Well-structured data will save you time when making figures with ggplot2\nggplot2 graphics are built step-by-step by adding new elements. Adding layers in this fashion allows for extensive flexibility and customization of plots, and more equally important the readability of the code.\nTo build a ggplot, we will use the following basic template that can be used for different types of plots:\n\nggplot(data = &lt;DATA&gt;, mapping = aes(&lt;MAPPINGS&gt;)) + &lt;GEOM_FUNCTION&gt;()\n\n**1) use the ggplot() function and bind the plot to a specific data frame using the data argument\n\nggplot(data = variants)\n\n\n\n\nThis activates the Plots tab in RStudio and prepares the canvas.\n**2) define a mapping (using the aesthetic (aes) function), by selecting the variables to be plotted and specifying how to present them in the graph, e.g. as x and y positions or characteristics such as size, shape, color, etc.\n\nggplot(data = variants, aes(x = POS, y = DP))\n\nYou can also use the pipe with ggplot2.\n\nvariants %&gt;% \n  ggplot(aes(x=POS, y=DP))\n\n\n\n\n3) add ‘geoms’ – graphical representations of the data in the plot (points, lines, bars). ggplot2** offers many different geoms; we will use some common ones today, including: - geom_point() for scatter plots, dot plots, etc. - geom_boxplot() for, well, boxplots! - geom_line() for trend lines, time series, etc.\nTo add a geom to the plot use the + operator. Because we have two continuous variables, let’s use geom_point() (i.e., a scatter plot) first:\n\nvariants %&gt;% \n  ggplot(aes(x = POS, y = DP)) +\n  geom_point()\n\n\n\n\nThe + in the ggplot2 package is particularly useful because it allows you to modify existing ggplot objects. This means you can easily set up plot templates and conveniently explore different types of plots, so the above plot can also be generated with code like this:\n\n# Assign plot to a variable\ncoverage_plot &lt;- \n  variants %&gt;% \n  ggplot(aes(x = POS, y = DP))\n\n# Draw the plot\ncoverage_plot +\n    geom_point()\n\n::: {.callout-note}\n\nAnything you put in the ggplot() function can be seen by any geom layers that you add (i.e., these are universal plot settings). This includes the x- and y-axis mapping you set up in aes().\nYou can also specify mappings for a given geom independently of the mappings defined globally in the ggplot() function.\nThe + sign used to add new layers must be placed at the end of the line containing the previous layer. If, instead, the + sign is added at the beginning of the line containing the new layer, ggplot2 will not add the new layer and will return an error message.\n\n\n# This is the correct syntax for adding layers\ncoverage_plot +\n  geom_point()\n\n# This will not add the new layer and will return an error message\ncoverage_plot\n  + geom_point()"
  },
  {
    "objectID": "r_lesson/05-data-visualization.html#building-your-plots-iteratively",
    "href": "r_lesson/05-data-visualization.html#building-your-plots-iteratively",
    "title": "Data Visualization with ggplot2",
    "section": "Building your plots iteratively",
    "text": "Building your plots iteratively\nBuilding plots with ggplot2 is typically an iterative process. We start by defining the dataset we’ll use, lay out the axes, and choose a geom:\n\nggplot(data = variants, aes(x = POS, y = DP)) +\n  geom_point()\n\n\n\n\nThen, we start modifying this plot to extract more information from it. For instance, we can add transparency (alpha) to avoid over-plotting:\n\nvariants %&gt;% \n  ggplot(aes(x = POS, y = DP)) +\n  geom_point(alpha = 0.5)\n\n\n\n\nWe can also add colors for all the points:\n\nvariants %&gt;% \n  ggplot(aes(x = POS, y = DP)) +\n  geom_point(alpha = 0.5, \n             color = \"blue\")\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nHow did we know the color names “blue” and “purple” would work in the code above? R has 657 (!!) built in color names. You can see them by calling the function colors(). You can also specify colors using rgb and hexadecimal codes.\n\n\nOr to color each species in the plot differently, you could use a variable as an input to the argument color. ggplot2 will provide a different color corresponding to different values in the variable. Here is an example where we color with sample_id:\n\nvariants %&gt;% \n  ggplot(aes(x = POS, y = DP, color = sample_id)) +\n  geom_point(alpha = 0.5)\n\n\n\n\n\n\n\n\n\n\nSetting vs mapping aesthetics\n\n\n\nAs the above example illustrates, When working with ggplot2, it’s important to understand the difference between setting aesthetic properties and mapping them. All geoms have certain visual attributes that can be modified like color and fill. Mapping a variable to an aesthetic is especially useful when we have third variable we want to express on our graph."
  },
  {
    "objectID": "r_lesson/05-data-visualization.html#working-with-color-palettes",
    "href": "r_lesson/05-data-visualization.html#working-with-color-palettes",
    "title": "Data Visualization with ggplot2",
    "section": "Working with color palettes",
    "text": "Working with color palettes\nThere are many options for changing the color palette of your plot. You can set your palette manually:\n\nmyPalette &lt;- c(\"#FFCD00\",\"#C8102E\", \"#2C2A29\") #Official UMB colors\n\nvariants %&gt;% \n  ggplot(aes(x = POS, y = DP, color = sample_id)) +\n  geom_point(alpha = 0.5) +\n  scale_color_manual(values = myPalette)\n\n\n\n\nGenerally, it may be preferable to work with one of the built in ggplot2 or R palettes, or to install one of several packages with additional palettes such as:\n\nRColorBrewer\nviridis\nggthemes\nggsci\nwesanderson\n\nLet’s try applying a viridis palette. viridis was designed to be especially robust for many forms of color-blindness. It is also meant to print well in grey scale. As an additional advantage, a lightweight form of the package is included with ggplot2, so there is no need to install additional packages.\n\nvariants %&gt;% \n  ggplot(aes(x = POS, y = DP, color = sample_id)) +\n  geom_point(alpha = 0.5) +\n  scale_color_viridis_d()"
  },
  {
    "objectID": "r_lesson/05-data-visualization.html#adding-titles-and-labels",
    "href": "r_lesson/05-data-visualization.html#adding-titles-and-labels",
    "title": "Data Visualization with ggplot2",
    "section": "Adding titles and labels",
    "text": "Adding titles and labels\nTo make our plot more readable, we can add axis labels:\n\nvariants %&gt;% \n  ggplot(aes(x = POS, y = DP, color = sample_id)) +\n  geom_point(alpha = 0.5) +\n  scale_color_viridis_d() +\n  labs(x = \"Base Pair Position\",\n       y = \"Read Depth (DP)\")\n\n\n\n\nTo add a main title to the plot, we use ggtitle():\n\nvariants %&gt;%\n  ggplot(aes(x = POS, y = DP, color = sample_id)) +\n  geom_point(alpha = 0.5) +\n  scale_color_viridis_d() +\n  labs(x = \"Base Pair Position\",\n       y = \"Read Depth (DP)\") +\n  ggtitle(\"Read Depth vs. Position\")\n\n\n\n\nNow the figure is complete and ready to be exported and saved to a file. This can be achieved easily using ggsave(), which can write, by default, the most recent generated figure into different formats (e.g., jpeg, png, pdf) according to the file extension. So, for example, to create a pdf version of the above figure with a dimension of \\(6\\times4\\) inches:\n\nggsave (\"depth.jpg\", width = 6, height = 4)\n\nIf we check the current working directory, there should be a newly created file called depth.jpg with the above plot.\n\n\n\n\n\n\nExercise\n\n\n\nUse what you just learned to create a scatter plot of mapping quality (MQ) over position (POS) with the samples showing in different colors. Make sure to give your plot relevant axis labels.\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\n ggplot(data = variants, aes(x = POS, y = MQ, color = sample_id)) +\n  geom_point() +\n  labs(x = \"Base Pair Position\",\n       y = \"Mapping Quality (MQ)\")"
  },
  {
    "objectID": "r_lesson/05-data-visualization.html#faceting",
    "href": "r_lesson/05-data-visualization.html#faceting",
    "title": "Data Visualization with ggplot2",
    "section": "Faceting",
    "text": "Faceting\nggplot2 has a special technique called faceting that allows the user to split one plot into multiple plots (panels) based on a factor (variable) included in the dataset. We will use it to split our mapping quality plot into three panels, one for each sample.\n\nvariants %&gt;% \n  ggplot( aes(x = POS, y = DP, color = sample_id)) +\n geom_point() +\n  scale_color_viridis_d() +\n labs(x = \"Base Pair Position\",\n      y = \"Read Depth (DP)\") +\n facet_grid(. ~ sample_id)\n\n\n\n\nThis looks okay, but it would be easier to read if the plot facets were stacked vertically rather than horizontally. The facet_grid geometry allows you to explicitly specify how you want your plots to be arranged via formula notation (rows ~ columns; the dot (.) indicates every other variable in the data i.e., no faceting on that side of the formula).\n\nvariants %&gt;% \n  ggplot(aes(x = POS, y = DP, color = sample_id)) +\n geom_point() +\n  scale_color_viridis_d() +\n labs(x = \"Base Pair Position\",\n      y = \"Read Depth (DP)\") +\n facet_grid(sample_id ~ .)\n\n\n\n\nUsually plots with white background look more readable when printed. We can set the background to white using the function theme_bw(). Additionally, you can remove the grid:\n\nvariants %&gt;% \n  ggplot(aes(x = POS, y = DP, color = sample_id)) +\n  geom_point() +\n  scale_color_viridis_d() +\n  labs(x = \"Base Pair Position\",\n       y = \"Read Depth (DP)\") +\n  facet_grid(sample_id ~ .) +\n  theme_bw() +\n  theme(panel.grid = element_blank())\n\n\n\n\n\n\n\n\n\n\nExercise\n\n\n\nUse what you just learned to create a scatter plot of PHRED scaled quality (QUAL) over position (POS) with the samples showing in different colors. Make sure to give your plot relevant axis labels.\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\n ggplot(data = variants, aes(x = POS, y = QUAL, color = sample_id)) +\n  geom_point() +\n  labs(x = \"Base Pair Position\",\n       y = \"PHRED-sacled Quality (QUAL)\") +\n  facet_grid(sample_id ~ .)"
  },
  {
    "objectID": "r_lesson/05-data-visualization.html#barplots",
    "href": "r_lesson/05-data-visualization.html#barplots",
    "title": "Data Visualization with ggplot2",
    "section": "Barplots",
    "text": "Barplots\nWe can create barplots using the geom_bar geom. Let’s make a barplot showing the number of variants for each sample that are indels.\n\nggplot(data = variants, aes(x = INDEL, fill = sample_id)) +\n  geom_bar() +\n  scale_fill_viridis_d() +\n  facet_grid(sample_id ~ .)"
  },
  {
    "objectID": "r_lesson/05-data-visualization.html#density",
    "href": "r_lesson/05-data-visualization.html#density",
    "title": "Data Visualization with ggplot2",
    "section": "Density",
    "text": "Density\nWe can create density plots using the geom_density geom that shows the distribution of of a variable in the dataset. Let’s plot the distribution of DP\n\nggplot(data = variants, aes(x = DP)) +\n  geom_density()\n\n\n\n\nThis plot tells us that the most of frequent DP (read depth) for the variants is about 10 reads.\n\n\n\n\n\n\nChallenge\n\n\n\nUse geom_density to plot the distribution of DP with a different fill for each sample. Use a white background for the plot.\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\nggplot(data = variants, aes(x = DP, fill = sample_id)) +\n   geom_density(alpha = 0.5) +\n   theme_bw()"
  },
  {
    "objectID": "r_lesson/05-data-visualization.html#ggplot2-themes",
    "href": "r_lesson/05-data-visualization.html#ggplot2-themes",
    "title": "Data Visualization with ggplot2",
    "section": "ggplot2 themes",
    "text": "ggplot2 themes\nIn addition to theme_bw(), which changes the plot background to white, ggplot2 comes with several other themes which can be useful to quickly change the look of your visualization. The complete list of themes is available at https://ggplot2.tidyverse.org/reference/ggtheme.html. theme_minimal() and theme_light() are popular, and theme_void() can be useful as a starting point to create a new hand-crafted theme.\nThe ggthemes package provides a wide variety of options (including Microsoft Excel, old and new). The ggplot2 extensions website provides a list of packages that extend the capabilities of ggplot2, including additional themes.\n\n\n\n\n\n\nExercise\n\n\n\nWith all of this information in hand, please take another five minutes to either improve one of the plots generated in this exercise or create a beautiful graph of your own. Use the RStudio ggplot2 cheat sheet for inspiration. Here are some ideas:\n\nSee if you can change the size or shape of the plotting symbol.\nCan you find a way to change the name of the legend? What about its labels?\nTry using a different color palette (see the Cookbook for R."
  },
  {
    "objectID": "r_lesson/05-data-visualization.html#more-ggplot2-plots",
    "href": "r_lesson/05-data-visualization.html#more-ggplot2-plots",
    "title": "Data Visualization with ggplot2",
    "section": "More ggplot2 Plots",
    "text": "More ggplot2 Plots\nggplot2 offers many more informative and beautiful plots (geoms) of interest for biologists (although not covered in this lesson) that are worth exploring, such as\n\ngeom_tile(), for heatmaps,\ngeom_jitter(), for strip charts, and\ngeom_violin(), for violin plots"
  },
  {
    "objectID": "r_lesson/05-data-visualization.html#resources",
    "href": "r_lesson/05-data-visualization.html#resources",
    "title": "Data Visualization with ggplot2",
    "section": "Resources",
    "text": "Resources\n\nggplot2: Elegant Graphics for Data Analysis (online version)\nThe Grammar of Graphics (Statistics and Computing)\nData Visualization: A Practical Introduction (online version)\nThe R Graph Gallery (the book)\n\n\n\n\n\n\n\nKey points\n\n\n\n\nggplot2 is a powerful tool for high-quality plots\nggplot2 provides a flexable and readable grammar to build plots"
  },
  {
    "objectID": "r_lesson/07-bioconductor-vcfr.html",
    "href": "r_lesson/07-bioconductor-vcfr.html",
    "title": "Using packages from Bioconductor",
    "section": "",
    "text": "Describe what the Bioconductor repository is and what it is used for\nDescribe how Bioconductor differs from CRAN\nSearch Bioconductor for relevant packages\nInstall a package from Bioconductor"
  },
  {
    "objectID": "r_lesson/07-bioconductor-vcfr.html#installing-packages-from-somewhere-else-besides-cran",
    "href": "r_lesson/07-bioconductor-vcfr.html#installing-packages-from-somewhere-else-besides-cran",
    "title": "Using packages from Bioconductor",
    "section": "Installing packages from somewhere else besides CRAN?",
    "text": "Installing packages from somewhere else besides CRAN?\nSo far we have told you about using packages that are included in the base installation of R (this is what comes with R ‘out of the box’), and packages that you can install from CRAN (the Comprehensive R Archive Network), which is the primary place many people look for supplemental R packages to install. However, not all R packages are available on CRAN. For bioinformatics-related packages in particular, there is another repository that has many powerful packages that you can install. It is called Bioconductor and it is a repository specifically focused on bioinformatics packages. Bioconductor has a mission of “promot[ing] the statistical analysis and comprehension of current and emerging high-throughput biological assays.” This means that many if not all of the packages available on Bioconductor are focused on the analysis of biological data, and that it can be a great place to look for tools to help you analyze your -omics datasets!"
  },
  {
    "objectID": "r_lesson/07-bioconductor-vcfr.html#so-how-do-i-use-it",
    "href": "r_lesson/07-bioconductor-vcfr.html#so-how-do-i-use-it",
    "title": "Using packages from Bioconductor",
    "section": "So how do I use it?",
    "text": "So how do I use it?\nSince access to the Bioconductor repository is not built in to base R ‘out of the box’, there are a couple steps needed to install packages from this alternative source. We will work through the steps (only 2!) to install a package to help with the VCF analysis we are working on, but you can use the same approach to install any of the many thousands of available packages."
  },
  {
    "objectID": "r_lesson/07-bioconductor-vcfr.html#first-install-the-biocmanager-package",
    "href": "r_lesson/07-bioconductor-vcfr.html#first-install-the-biocmanager-package",
    "title": "Using packages from Bioconductor",
    "section": "First, install the BiocManager package",
    "text": "First, install the BiocManager package\nThe first step is to install a package that is on CRAN, BiocManager. This package will allow us to use it to install packages from Bioconductor. You can think of Bioconductor kind of like an alternative app store for your phone, except instead of apps you are installing packages, and instead of your phone it’s your local R package library.\n\n# install the BiocManager from CRAN using the base R install.packages() function\ninstall.packages(\"BiocManager\")\n\nTo check if this worked (and also so you can make a note of the version for reproducibility purposes), you can run BiocManager::version() and it should give you the version number.\n\n# to make sure it worked, check the version\nBiocManager::version()"
  },
  {
    "objectID": "r_lesson/07-bioconductor-vcfr.html#second-install-the-vcfr-package-from-bioconductor-using-biocmanager",
    "href": "r_lesson/07-bioconductor-vcfr.html#second-install-the-vcfr-package-from-bioconductor-using-biocmanager",
    "title": "Using packages from Bioconductor",
    "section": "Second, install the vcfR package from Bioconductor using BiocManager",
    "text": "Second, install the vcfR package from Bioconductor using BiocManager\n\n\n\n\n\n\nHead’s Up: Installing vcfR may take a while due to numerous dependencies\n\n\n\nJust be aware that installing packages that have many dependencies can take a while.\n\n\n\n# install the vcfR package from bioconductor using BiocManager::install()\nBiocManager::install(\"vcfR\")\n\nDepending on your particular system, you may need to also allow it to install some dependencies or update installed packages in order to successfully complete the process.\n\n\n\n\n\n\nNote: Installing packages from Bioconductor vs from CRAN\n\n\n\nSome packages begin by being available only on Bioconductor, and then later move to CRAN. vcfR is one such package, which originally was only available from Bioconductor, but is currently available from CRAN. The other thing to know is that BiocManager::install() will also install packages from CRAN (it is a wrapper around install.packages() that adds some extra features). There are other benefits to using BiocManager::install() for Bioconductor packages. In short, Bioconductor packages have a release cycle that is different from CRAN and the install() function is aware of that difference, so it helps to keep package versions in line with one another in a way that doesn’t generally happen with the base R install.packages()."
  },
  {
    "objectID": "r_lesson/07-bioconductor-vcfr.html#search-for-bioconductor-packages-based-on-your-analysis-needs",
    "href": "r_lesson/07-bioconductor-vcfr.html#search-for-bioconductor-packages-based-on-your-analysis-needs",
    "title": "Using packages from Bioconductor",
    "section": "Search for Bioconductor packages based on your analysis needs",
    "text": "Search for Bioconductor packages based on your analysis needs\nWhile we are only focusing in this workshop on VCF analyses, there are hundreds or thousands of different types of data and analyses that bioinformaticians may want to work with. Sometimes you may get a new dataset and not know exactly where to start with analyzing or visualizing it. The Bioconductor package search view can be a great way to browse through the packages that are available.\n\n\n\n\n\n\n\nTip: Searching for packages on the Bioconductor website\n\n\n\nThere are several thousand packages available through the Bioconductor website. It can be a bit of a challenge to find what you want, but one helpful resource is the package search page.\n\n\nIn bioinformatics, there are often many different tools that can be used in a particular instance. The authors of vcfR have compiled some of them. One of those packages that is available from Bioconductor is called VariantAnnotation and may also be of interest to those working with vcf files in R."
  },
  {
    "objectID": "r_lesson/07-bioconductor-vcfr.html#challenge",
    "href": "r_lesson/07-bioconductor-vcfr.html#challenge",
    "title": "Using packages from Bioconductor",
    "section": "Challenge",
    "text": "Challenge\n\nUse the BiocManager::available() function to see what packages are available matching a search term.\nUse the biocViews interface to search for packages of interest.\n\nYou may or may not want to try installing the package, since not all dependencies always install easily. However, this will at least let you see what is available."
  },
  {
    "objectID": "r_lesson/07-bioconductor-vcfr.html#resources",
    "href": "r_lesson/07-bioconductor-vcfr.html#resources",
    "title": "Using packages from Bioconductor",
    "section": "Resources",
    "text": "Resources\n\nBioconductor\nBioconductor package search\nCRAN\n\n\n\nBioconductor is an alternative package repository for bioinformatics packages.\nInstalling packages from Bioconductor requires a new method, since it is not compatible with the install.packages() function used for CRAN.\nCheck Bioconductor to see if there is a package relevant to your analysis before writing code yourself."
  },
  {
    "objectID": "shell_lesson/02-the-filesystem.html",
    "href": "shell_lesson/02-the-filesystem.html",
    "title": "Navigating Files and Directories",
    "section": "",
    "text": "Objectives\n\nUse a single command to navigate multiple steps in your directory structure, including moving backwards (one level up).\nPerform operations on files in directories outside your working directory.\nWork with hidden directories and hidden files.\nInterconvert between absolute and relative paths.\nEmploy navigational shortcuts to move around your file system.\n\nQuestions to be answered in this lesson\n\nHow can I perform operations on files outside of my working directory?\nWhat are some navigational shortcuts I can use to make my work more efficient?"
  },
  {
    "objectID": "shell_lesson/02-the-filesystem.html#moving-around-the-file-system",
    "href": "shell_lesson/02-the-filesystem.html#moving-around-the-file-system",
    "title": "Navigating Files and Directories",
    "section": "Moving around the file system",
    "text": "Moving around the file system\nWe’ve learned how to use pwd to find our current location within our file system. We’ve also learned how to use cd to change locations and ls to list the contents of a directory. Now we’re going to learn some additional commands for moving around within our file system.\nUse the commands we’ve learned so far to navigate to the shell_data/untrimmed_fastq directory, if you’re not already there.\n$ cd\n$ cd Desktop\n$ cd unix_lesson\n$ cd shell_data\n$ cd untrimmed_fastq\nWhat if we want to move back up and out of this directory and to our top level directory? Can we type cd shell_data? Try it and see what happens.\nCommand:\n$ cd shell_data\nOutput: Note: This is an example\n$ cd cd: shell_data: No such file or directory\nYour computer looked for a directory or file called shell_data within the directory you were already in. It didn’t know you wanted to look at a directory level above the one you were located in.\nWe have a special command to tell the computer to move us back or up one directory level.\n$ cd ..\nNow we can use pwd to make sure that we are in the directory we intended to navigate to, and ls to check that the contents of the directory are correct.\nCommand:\n$ pwd\nCommand:\n$ ls\nOutput:\nsra_metadata  untrimmed_fastq\nFrom this output, we can see that .. did indeed take us back one level in our file system.\nCommand:\n$ ls ../../"
  },
  {
    "objectID": "shell_lesson/02-the-filesystem.html#exercise",
    "href": "shell_lesson/02-the-filesystem.html#exercise",
    "title": "Navigating Files and Directories",
    "section": "Exercise",
    "text": "Exercise\nFinding hidden directories\nFirst navigate to the shell_data directory. There is a hidden directory within this directory. Explore the options for ls to find out how to see hidden directories. List the contents of the directory and identify the name of the text file in that directory.\nHint: hidden files and folders in Unix start with ., for example .my_hidden_directory\nFirst use the --help command to look at the options for ls.\n$ --help ls\n\n\n\n\n\n\nSolution\n\n\n\n\n\nThe -a option is short for all and says that it causes ls to “not ignore entries starting with .” This is the option we want.\nCommand:\n$ ls -a\nOutput:\n.  ..  .hidden  sra_metadata  untrimmed_fastq\n\n\n\nThe name of the hidden directory is .hidden. We can navigate to that directory using cd.\n$ cd .hidden\nAnd then list the contents of the directory using ls.\nCommand:\n$ ls\nOutput:\nyoufoundit.txt\nThe name of the text file is youfoundit.txt.\nIn most commands the flags can be combined together in no particular order to obtain the desired results/output.\n$ ls -Fa\n$ ls -laF"
  },
  {
    "objectID": "shell_lesson/02-the-filesystem.html#examining-the-contents-of-other-directories",
    "href": "shell_lesson/02-the-filesystem.html#examining-the-contents-of-other-directories",
    "title": "Navigating Files and Directories",
    "section": "Examining the contents of other directories",
    "text": "Examining the contents of other directories\nBy default, the ls commands lists the contents of the working directory (i.e. the directory you are in). You can always find the directory you are in using the pwd command. However, you can also give ls the names of other directories to view Navigate to your home directory if you are not already there.\n$ cd\nThen enter the command:\n$ ls shell_data\nOutput:\nsra_metadata  untrimmed_fastq\nThis will list the contents of the shell_data directory without you needing to navigate there. The cd command works in a similar way.\nTry entering:\n$ cd\n$ cd shell_data/untrimmed_fastq\nThis will take you to the untrimmed_fastq directory without having to go through the intermediate directory."
  },
  {
    "objectID": "shell_lesson/02-the-filesystem.html#exercice",
    "href": "shell_lesson/02-the-filesystem.html#exercice",
    "title": "Navigating Files and Directories",
    "section": "Exercice",
    "text": "Exercice\nNavigating practice\nNavigate to your home directory. From there, list the contents of the untrimmed_fastq directory.\n\n\n\n\n\n\nSolution\n\n\n\n\n\nCommand:\n$ cd\n$ ls shell_data/untrimmed_fastq/\nOutput:\nSRR097977.fastq  SRR098026.fastq"
  },
  {
    "objectID": "shell_lesson/02-the-filesystem.html#full-vs.-relative-paths",
    "href": "shell_lesson/02-the-filesystem.html#full-vs.-relative-paths",
    "title": "Navigating Files and Directories",
    "section": "Full vs. Relative Paths",
    "text": "Full vs. Relative Paths\nThe cd command takes an argument which is a directory name. Directories can be specified using either a relative path or a full absolute path. The directories on the computer are arranged into a hierarchy.\nThe full path tells you where a directory is in that hierarchy.\nNavigate to the home directory, then enter the pwd command.\nCommand:\n$ cd ~\n$ pwd  \nOutput: Note: This is an example\n$ /usr/home/⟨username⟩\nThis command will display the full name of your home directory. The very top of the hierarchy is a directory called / which is usually referred to as the root directory .\nNow lets navigate directly to the .hidden folder using the full path.\n$ cd /usr/home/⟨username⟩/Desktop/unix_lesson/shell_data/.hidden\nThis jumps forward multiple levels to the .hidden directory. Now go back to the home directory.\n$ cd \nYou can also navigate to the .hidden directory using:\n$ cd Desktop/unix_lesson/shell_data/.hidden\nThese two commands have the same effect, they both take us to the .hidden directory. The first uses the absolute path, giving the full address from the home directory. The second uses a relative path, giving only the address from the working directory. A full path always starts with a /. A relative path does not.\nA relative path is like getting directions from someone on the street. They tell you to “go right at the stop sign, and then turn left on Main Street”. That works great if you’re standing there together, but not so well if you’re trying to tell someone how to get there from another country. A full path is like GPS coordinates. It tells you exactly where something is no matter where you are right now.\nYou can usually use either a full path or a relative path depending on what is most convenient. If we are in the home directory, it is more convenient to enter the full path. If we are in the working directory, it is more convenient to enter the relative path since it involves less typing.\nOver time, it will become easier for you to keep a mental note of the structure of the directories that you are using and how to quickly navigate amongst them."
  },
  {
    "objectID": "shell_lesson/02-the-filesystem.html#navigational-shortcuts",
    "href": "shell_lesson/02-the-filesystem.html#navigational-shortcuts",
    "title": "Navigating Files and Directories",
    "section": "Navigational Shortcuts",
    "text": "Navigational Shortcuts\nThe root directory is the highest level directory in your file system and contains files that are important for your computer to perform its daily work. While you will be using the root (/) at the beginning of your absolute paths, it is important that you avoid working with data in these higher-level directories, as your commands can permanently alter files that the operating system needs to function. Dealing with the home directory is very common. The tilde character, ~, is a shortcut for your home directory.\nNow Navigate to the shell_data directory:\n$ cd ..\nThen enter the command:\n$ ls ~\nThis prints the contents of your home directory, without you needing to type the full path.\nThe commands cd, and cd ~ are very useful for quickly navigating back to your home directory.\nLesson Keypoints\n\nThe /, ~, and .. characters represent important navigational shortcuts.\nHidden files and directories start with . and can be viewed using ls -a.\nRelative paths specify a location starting from the current location, while absolute paths specify a location from the root of the file system."
  },
  {
    "objectID": "shell_lesson/04-working-with-files-part02.html",
    "href": "shell_lesson/04-working-with-files-part02.html",
    "title": "Working with Files and Directories II",
    "section": "",
    "text": "Objectives\n\n\n\n\nView, search within, copy, move, and rename files. Create new directories\nMake a file read only."
  },
  {
    "objectID": "shell_lesson/04-working-with-files-part02.html#details-on-the-fastq-format",
    "href": "shell_lesson/04-working-with-files-part02.html#details-on-the-fastq-format",
    "title": "Working with Files and Directories II",
    "section": "Details on the FASTQ format",
    "text": "Details on the FASTQ format\nAlthough it looks complicated (and it is), it’s easy to understand the fastq format with a little decoding. Some rules about the format include…\n\n\n\n\n\n\n\nLine\nDescription\n\n\n\n\n1\nAlways begins with ‘@’ and then information about the read\n\n\n2\nThe actual DNA sequence\n\n\n3\nAlways begins with a ‘+’ and sometimes the same info in line 1\n\n\n4\nHas a string of characters which represent the quality scores; must have same number of characters as line 2\n\n\n\nWe can view the first complete read in one of the files in our dataset by using head to look at the first four lines.\n$ head -n 4 SRR098026.fastq\n@SRR098026.1 HWUSI-EAS1599_1:2:1:0:968 length=35\nNNNNNNNNNNNNNNNNCNNNNNNNNNNNNNNNNNN\n+SRR098026.1 HWUSI-EAS1599_1:2:1:0:968 length=35\n!!!!!!!!!!!!!!!!#!!!!!!!!!!!!!!!!!!\nAll but one of the nucleotides in this read are unknown (N). This is a pretty bad read!\nLine 4 shows the quality for each nucleotide in the read. Quality is interpreted as the probability of an incorrect base call (e.g. 1 in 10) or, equivalently, the base call accuracy (e.g. 90%). To make it possible to line up each individual nucleotide with its quality score, the numerical score is converted into a code where each individual character represents the numerical quality score for an individual nucleotide. For example, in the line above, the quality score line is:\n!!!!!!!!!!!!!!!!#!!!!!!!!!!!!!!!!!!\nThe # character and each of the ! characters represent the encoded quality for an individual nucleotide. The numerical value assigned to each of these characters depends on the sequencing platform that generated the reads. The sequencing machine used to generate our data uses the standard Sanger quality PHRED score encoding, Illumina version 1.8 onwards. Each character is assigned a quality score between 0 and 42 as shown in the chart below.\nQuality encoding: !\"#$%&'()*+,-./0123456789:;&lt;=&gt;?@ABCDEFGHIJK\n                  |         |         |         |         |\nQuality score:    0........10........20........30........40..                          \nEach quality score represents the probability that the corresponding nucleotide call is incorrect. This quality score is logarithmically based, so a quality score of 10 reflects a base call accuracy of 90%, but a quality score of 20 reflects a base call accuracy of 99%. These probability values are the results from the base calling algorithm and dependent on how much signal was captured for the base incorporation.\nLooking back at our read:\n@SRR098026.1 HWUSI-EAS1599_1:2:1:0:968 length=35\nNNNNNNNNNNNNNNNNCNNNNNNNNNNNNNNNNNN\n+SRR098026.1 HWUSI-EAS1599_1:2:1:0:968 length=35\n!!!!!!!!!!!!!!!!#!!!!!!!!!!!!!!!!!!\nwe can now see that the quality of each of the Ns is 0 and the quality of the only nucleotide call (C) is also very poor (# = a quality score of 2). This is indeed a very bad read."
  },
  {
    "objectID": "shell_lesson/04-working-with-files-part02.html#creating-moving-copying-and-removing",
    "href": "shell_lesson/04-working-with-files-part02.html#creating-moving-copying-and-removing",
    "title": "Working with Files and Directories II",
    "section": "Creating, moving, copying, and removing",
    "text": "Creating, moving, copying, and removing\nNow we can move around in the file structure, look at files, and search files. But what if we want to copy files or move them around or get rid of them? Most of the time, you can do these sorts of file manipulations without the command line, but there will be some cases (like when you’re working with a remote computer like we are for this lesson) where it will be impossible. You’ll also find that you may be working with hundreds of files and want to do similar manipulations to all of those files. In cases like this, it’s much faster to do these operations at the command line.\n\nCopying Files\nWhen working with computational data, it’s important to keep a safe copy of that data that can’t be accidentally overwritten or deleted. For this lesson, our raw data is our FASTQ files. We don’t want to accidentally change the original files, so we’ll make a copy of them and change the file permissions so that we can read from, but not write to, the files.\nFirst, let’s make a copy of one of our FASTQ files using the cp command.\nNavigate to the shell_data/untrimmed_fastq directory and enter:\n$ cp SRR098026.fastq SRR098026-copy.fastq\n$ ls\nSRR097977.fastq  SRR098026-copy.fastq  SRR098026.fastq\nWe now have two copies of the SRR098026.fastq file, one of them named SRR098026-copy.fastq. We’ll move this file to a new directory called backup where we’ll store our backup data files.\n\n\nCreating Directories\nThe mkdir command is used to make a directory. Enter mkdir followed by a space, then the directory name you want to create:\n$ mkdir backup\n\n\nMoving / Renaming\nWe can now move our backup file to this directory. We can move files around using the command mv:\n$ mv SRR098026-copy.fastq backup\n$ ls backup\nSRR098026-copy.fastq\nThe mv command is also how you rename files. Let’s rename this file to make it clear that this is a backup:\n$ cd backup\n$ mv SRR098026-copy.fastq SRR098026-backup.fastq\n$ ls\nSRR098026-backup.fastq\n\n\nFile Permissions\nWe’ve now made a backup copy of our file, but just because we have two copies, it doesn’t make us safe. We can still accidentally delete or overwrite both copies. To make sure we can’t accidentally mess up this backup file, we’re going to change the permissions on the file so that we’re only allowed to read (i.e. view) the file, not write to it (i.e. make new changes).\nView the current permissions on a file using the -l (long) flag for the ls command:\n$ ls -l\n-rw-r--r-- 1 &lt;username&gt; 43332 &lt;last modified date time&gt; SRR098026-backup.fastq\nThe first part of the output for the -l flag gives you information about the file’s current permissions. There are ten slots in the permissions list. The first character in this list is related to file type, not permissions, so we’ll ignore it for now. The next three characters relate to the permissions that the file owner has, the next three relate to the permissions for group members, and the final three characters specify what other users outside of your group can do with the file. We’re going to concentrate on the three positions that deal with your permissions (as the file owner).\n\nHere the three positions that relate to the file owner are rw-. The r means that you have permission to read the file, the w indicates that you have permission to write to (i.e. make changes to) the file, and the third position is a -, indicating that you don’t have permission to carry out the ability encoded by that space (this is the space where x or executable ability is stored. This controls your ability to run files that are programs or cd into a directory).\nOur goal for now is to change permissions on this file so that you no longer have w or write permissions. We can do this using the chmod (change mode) command and subtracting (-) the write permission -w.\n$ chmod -w SRR098026-backup.fastq\n$ ls -l \n-r--r--r-- 1 &lt;username&gt; 43332 &lt;last modified date time&gt; SRR098026-backup.fastq\n\n\nRemoving\nTo prove to ourselves that you no longer have the ability to modify this file, try deleting it with the rm command:\n$ rm SRR098026-backup.fastq\nYou’ll be asked if you want to override your file permissions:\nrm: remove write-protected regular file ‘SRR098026-backup.fastq'? \nYou should enter n for no. If you enter n (for no), the file will not be deleted. If you enter y, you will delete the file. This gives us an extra measure of security, as there is one more step between us and deleting our data files.\nImportant: The rm command permanently removes the file. Be careful with this command. It doesn’t just nicely put the files in the Trash. They’re really gone.\nBy default, rm will not delete directories. You can tell rm to delete a directory using the -r (recursive) option. Let’s delete the backup directory we just made.\nEnter the following command:\n$ cd ..\n$ rm -r backup\nThis will delete not only the directory, but all files within the directory. If you have write-protected files in the directory, you will be asked whether you want to override your permission settings.\n\n\n\n\n\n\nExercise\n\n\n\nStarting in the shell_data/untrimmed_fastq/ directory, do the following:\n\nMake sure that you have deleted your backup directory and all files it contains.\nCreate a backup of each of your FASTQ files using cp. (Note: You’ll need to do this individually for each of the two FASTQ files. We haven’t learned yet how to do this with a wildcard.)\nUse a wildcard to move all of your backup files to a new backup directory.\nChange the permissions on all of your backup files to be write-protected.\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\nrm -r backup\ncp SRR098026.fastq SRR098026-backup.fastq and cp SRR097977.fastq SRR097977-backup.fastq\nmkdir backup and mv *-backup.fastq backup\nchmod -w backup/*-backup.fastq\nIt’s always a good idea to check your work with ls -l backup. You should see something like:\n\n-r--r--r-- 1 &lt;username&gt; 47552 &lt;modified date time&gt; SRR097977-backup.fastq\n-r--r--r-- 1 &lt;username&gt; 43332 &lt;username&gt; SRR098026-backup.fastq\n\n\n\n\n\n\n\n\n\n\n\nKey points\n\n\n\n\nThe commands cp, mv, and mkdir are useful for manipulating existing files and creating new directories.\nYou can view file permissions using ls -l and change permissions using chmod."
  },
  {
    "objectID": "shell_lesson/06-writing-scripts.html",
    "href": "shell_lesson/06-writing-scripts.html",
    "title": "Writing Scripts and Working with Data",
    "section": "",
    "text": "Objectives\n\n\n\n\nUse the nano text editor to modify text files.\nWrite a basic shell script.\nUse the bash command to execute a shell script.\nUse chmod to make a script an executable program."
  },
  {
    "objectID": "shell_lesson/06-writing-scripts.html#writing-files",
    "href": "shell_lesson/06-writing-scripts.html#writing-files",
    "title": "Writing Scripts and Working with Data",
    "section": "Writing files",
    "text": "Writing files\nWe’ve been able to do a lot of work with files that already exist, but what if we want to write our own files? We’re not going to type in a FASTA file, but we’ll see as we go through other tutorials, there are a lot of reasons we’ll want to write a file, or edit an existing file.\nTo add text to files, we’re going to use a text editor called Nano. We’re going to create a file to take notes about what we’ve been doing with the data files in ~/shell_data/untrimmed_fastq.\nThis is good practice when working in bioinformatics. We can create a file called README.txt that describes the data files in the directory or documents how the files in that directory were generated. As the name suggests, it’s a file that we or others should read to understand the information in that directory.\nLet’s make sure our working directory is /shell_data/untrimmed_fastq using cd to get to the right spot if necessary, then run nano to create a file called README.txt:\n$ cd shell_data/untrimmed_fastq\n$ nano README.txt\nThe text at the bottom of the screen shows the keyboard shortcuts for performing various tasks in nano. We will talk more about how to interpret this information soon.\n\n\n\n\n\n\nWhich Editor?\n\n\n\n\n\nWhen we say, “nano is a text editor,” we really do mean “text”: nano can only work with plain character data, not tables, images, or any other human-friendly media. We use nano in examples because it is one of the least complex text editors. However, because of this trait, nano may not be powerful enough or flexible enough for the work you need to do after this workshop. On Unix systems (such as Linux and Mac OS X), many programmers use Emacs or Vim (both of which require more time to learn), or a graphical editor such as Gedit. On Windows, you may wish to use Notepad++. Windows also has a built-in editor called notepad that can be run from the command line in the same way as nano for the purposes of this lesson.\nNo matter what editor you use, you will need to know the default location where it searches for files and where files are saved. If you start an editor from the shell, it will (probably) use your current working directory as its default location. If you use your computer’s start menu, the editor may want to save files in your desktop or documents directory instead. You can change this by navigating to another directory the first time you “Save As…”\n\n\n\nLet’s type in a few lines of text. Describe what the files in this directory are or what you’ve been doing with them. Once we’re happy with our text, we can press Ctrl-O (press the Ctrl or Control key and, while holding it down, press the O key) to write our data to disk. You’ll be asked what file we want to save this to: press Return to accept the suggested default of README.txt.\nOnce our file is saved, we can use Ctrl-X to quit the nano editor and return to the shell.\n\n\n\n\n\n\nControl, Ctrl, or ^ Key\n\n\n\nThe Control key is also called the “Ctrl” key. There are various ways in which using the Control key may be described. For example, you may see an instruction to press the Ctrl key and, while holding it down, press the X key, described as any of:\n\nControl-X\nControl+X\nCtrl-X\nCtrl+X\n^X\nC-x\n\nIn nano, along the bottom of the screen you’ll see ^G Get Help ^O WriteOut. This means that you can use Ctrl+G to get help and Ctrl+O to save your file.\n\n\nNow you’ve written a file. You can take a look at it with less or cat, or open it up again and edit it with nano.\n\n\n\n\n\n\nExercise\n\n\n\nOpen README.txt and add the date to the top of the file and save the file.\n\n\n\n\n\n\nSolution\n\n\n\n\n\nUse nano README.txt to open the file.\nAdd today’s date and then use Ctrl+X followed by y and Enter to save."
  },
  {
    "objectID": "shell_lesson/06-writing-scripts.html#writing-scripts",
    "href": "shell_lesson/06-writing-scripts.html#writing-scripts",
    "title": "Writing Scripts and Working with Data",
    "section": "Writing scripts",
    "text": "Writing scripts\nA really powerful thing about the command line is that you can write scripts. Scripts let you save commands to run them and also lets you put multiple commands together. Though writing scripts may require an additional time investment initially, this can save you time as you run them repeatedly. Scripts can also address the challenge of reproducibility: if you need to repeat an analysis, you retain a record of your command history within the script.\nOne thing we will commonly want to do with sequencing results is pull out bad reads and write them to a file to see if we can figure out what’s going on with them. We’re going to look for reads with long sequences of N’s like we did before, but now we’re going to write a script, so we can run it each time we get new sequences, rather than type the code in by hand each time.\nWe’re going to create a new file to put this command in. We’ll call it bad-reads-script.sh. The sh isn’t required, but using that extension tells us that it’s a shell script.\n$ nano bad-reads-script.sh\nBad reads have a lot of N’s, so we’re going to look for N{10} with grep. We want the whole FASTQ record, so we’re also going to get the one line above the sequence and the two lines below. We also want to look in all the files that end with .fastq, so we’re going to use the * wildcard.\ngrep -B1 -A2 -E \"N{10}\" *.fastq &gt; scripted_bad_reads.txt\nType your grep command into the file and save it as before. Be careful that you did not add the $ at the beginning of the line.\nNow comes the neat part. We can run this script. Type:\n$ bash bad-reads-script.sh\nIt will look like nothing happened, but now if you look at scripted_bad_reads.txt, you can see that there are now reads in the file.\n\n\n\n\n\n\nExercise\n\n\n\nWe want the script to tell us when it’s done.\n\nOpen bad-reads-script.sh and add the line echo \"Script finished!\" after the grep command and save the file.\nRun the updated script.\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n$ bash bad-reads-script.sh\nScript finished!\n\n\n\n\n\n\n\n\n\n\n\nKey Points\n\n\n\n\nScripts are a collection of commands executed together."
  }
]